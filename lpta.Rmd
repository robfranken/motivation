---
title: "Latent Profile Transition Analysis"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 3
    code_folding: show
    code_download: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```


<br>

*Last edited: January 25, 2021*

<br>

In the following, we will explore motivational profiles in the context of longitudinal data, using SDT as a theoretical framework. We will explore movement between motivational profiles over time.

<br>

## Approach

First, we obtain weighted factor-scores for each SMS-subscale with CFA using MLE, as input for our subsequent LPA. Then, we use a three-step approach (see [this article](https://www.tandfonline.com/doi/pdf/10.1080/10705511.2014.915181); or the paper by [Emm-Collison and colleagues](https://www.sciencedirect.com/science/article/pii/S1469029219303851) who used the same procedure).


---

# Preliminary steps

## 1. Data

Let's get our 'cleaned' SMS-data, for each wave.

```{r, warning=FALSE, message=FALSE}
library(sjlabelled)
library(dplyr)
library(tidyverse)
library(careless)
library(psych)

load("data_abs_public_v2.RData") # load data
data_abs_public <- unlabel(data_abs_public, verbose=F) # unlabel

data_abs_public$id <- 1:nrow(data_abs_public) # add identifier for subsequent LPTA

# subset sms data in each wave
sms_w1 <- data_abs_public %>% select(W1_M1_1, W1_M1_2, W1_M1_3, W1_M1_4, W1_M1_5, W1_M1_6, W1_M1_7, W1_M1_8, W1_M2_1, W1_M2_2, W1_M2_3, W1_M2_4, W1_M2_5, W1_M2_6, W1_M2_7, W1_M2_8, W1_M3_1, W1_M3_2, W1_M3_3, W1_M3_4, W1_M3_5, W1_M3_6, W1_M3_7, W1_M3_8, id)

sms_w2 <- data_abs_public %>% select(W2_M1_1, W2_M1_2, W2_M1_3, W2_M1_4, W2_M1_5, W2_M1_6, W2_M1_7, W2_M1_8, W2_M2_1, W2_M2_2, W2_M2_3, W2_M2_4, W2_M2_5, W2_M2_6, W2_M2_7, W2_M2_8, W2_M3_1, W2_M3_2, W2_M3_3, W2_M3_4, W2_M3_5, W2_M3_6, W2_M3_7, W2_M3_8, id) 

sms_w3 <- data_abs_public %>% select(W3_M1_1, W3_M1_2, W3_M1_3, W3_M1_4, W3_M1_5, W3_M1_6, W3_M1_7, W3_M1_8, W3_M2_1, W3_M2_2, W3_M2_3, W3_M2_4, W3_M2_5, W3_M2_6, W3_M2_7, W3_M2_8, W3_M3_1, W3_M3_2, W3_M3_3, W3_M3_4, W3_M3_5, W3_M3_6, W3_M3_7, W3_M3_8, id)

# make a 'string' variable 
sms_w1 <- sms_w1 %>%
  mutate(string_w1 = longstring(.)) %>%
  mutate(md_w1 = outlier(., plot = FALSE))

sms_w2 <- sms_w2 %>%
  mutate(string_w2 = longstring(.)) %>%
  mutate(md_w2 = outlier(., plot = FALSE)) 

sms_w3 <- sms_w3 %>%
  mutate(string_w3 = longstring(.)) %>%
  mutate(md_w3 = outlier(., plot = FALSE)) 

# cap string responding and use MD
cutoff_w1 <- (qchisq(p = 1 - .001, df = (ncol(sms_w1) - 1)))
sms_w1 <- sms_w1 %>%
  filter(string_w1 <= 10,
         md_w1 < cutoff_w1) %>%
  select(-string_w1, -md_w1)

  cutoff_w2 <- (qchisq(p = 1 - .001, df = (ncol(sms_w2) - 1)))
sms_w2 <- sms_w2 %>%
  filter(string_w2 <= 10,
         md_w2 < cutoff_w2) %>%
  select(-string_w2, -md_w2)

cutoff_w3 <- (qchisq(p = 1 - .001, df = (ncol(sms_w3) - 1)))
sms_w3 <- sms_w3 %>%
  filter(string_w3 <= 10,
         md_w3 < cutoff_w3) %>%
  select(-string_w3, -md_w3)
```

Next, we are going to make a long file of the SMS data.

```{r}
# first, make a wide format
sms_wide <- merge(sms_w1, sms_w2, by = "id") # first wave 1 and 2
sms_wide <- merge(sms_wide, sms_w3, by = "id") # add wave 3

# then transform into long shape
library(reshape2)
sms_long <- reshape(sms_wide,
                    direction = "long",
                    varying = c(list(names(sms_wide)[c(2, 26, 50)]),
                                     list(names(sms_wide)[c(3, 27, 51)]),
                                     list(names(sms_wide)[c(4, 28, 52)]),
                                     list(names(sms_wide)[c(5, 29, 53)]),
                                     list(names(sms_wide)[c(6, 30, 54)]),
                                     list(names(sms_wide)[c(7, 31, 55)]),
                                     list(names(sms_wide)[c(8, 32, 56)]),
                                     list(names(sms_wide)[c(9, 33, 57)]),
                                     list(names(sms_wide)[c(10, 34, 58)]),
                                     list(names(sms_wide)[c(11, 35, 59)]),
                                     list(names(sms_wide)[c(12, 36, 60)]),
                                     list(names(sms_wide)[c(13, 37, 61)]),
                                     list(names(sms_wide)[c(14, 38, 62)]),
                                     list(names(sms_wide)[c(15, 39, 63)]),
                                     list(names(sms_wide)[c(16, 40, 64)]),
                                     list(names(sms_wide)[c(17, 41, 65)]),
                                     list(names(sms_wide)[c(18, 42, 66)]),
                                     list(names(sms_wide)[c(19, 43, 67)]),
                                     list(names(sms_wide)[c(20, 44, 68)]),
                                     list(names(sms_wide)[c(21, 45, 69)]),
                                     list(names(sms_wide)[c(22, 46, 70)]),
                                     list(names(sms_wide)[c(23, 47, 71)]),
                                     list(names(sms_wide)[c(24, 48, 72)]),
                                     list(names(sms_wide)[c(25, 49, 73)])),
                    v.names = c("M1_1", "M1_2", "M1_3","M1_4", "M1_5", "M1_6", "M1_7", "M1_8", "M2_1", "M2_2", "M2_3","M2_4", "M2_5", "M2_6", "M2_7", "M2_8", "M3_1", "M3_2", "M3_3","M3_4", "M3_5", "M3_6", "M3_7", "M3_8"),
                    idvar = "id",
                    timevar = "Timepoint",
                    times = 1:3)
# Reorder
sms_long  <- sms_long [(order(sms_long$id)), ]
# fix(sms_long) to check data structure

sms_long_nm <- sms_long %>%
  na.omit() # listwise deletion
```

<br>

----

## 2. CFA

First, confirmatory factor analysis using maximum likelihood estimation was conducted to obtain weighted factor scores for each SMS subscale. We first conduct CFA on the stacked data (hence assuming observations to be independent of each other). We will assess model fit using multiple indices. Afterwards, we will assess longitudinal invariance of the measurement model via a series of increasingly constraining models, indicating invariance by a change of CFI of â‰¤0.01.

### Lavaan

Tell Lavaan the confirmatory structure.

```{r}
library(lavaan)

motivation_model <- "
amotivation =~ M1_5 + M2_4 + M3_1 + M3_6
external    =~ M1_4 + M2_3 + M3_3 + M3_8
introjected =~ M1_7 + M2_2 + M2_8 + M3_7
identified  =~ M1_3 + M1_8 + M2_7 + M3_4
integrated  =~ M1_2 + M2_1 + M2_5 + M3_5
intrinsic   =~ M1_1 + M1_6 + M2_6 + M3_2
"
```

Now let's inspect the model. We will get the fit of the model, the (standardized) factor loadings, item averages (intercepts), error variances, and R-square scores. We will also make a table of the various fit indices. 
 
```{r}
# examine overall fit
overall.fit <- cfa(model = motivation_model, data = sms_long_nm,
           meanstructure = TRUE,  # gives us the means
           std.lv = TRUE) 

summary(overall.fit, standardized = TRUE, rsquare = TRUE, fit.measure = TRUE)

# make table of fit indices
table_fit <- matrix(NA, nrow = 11, ncol = 6)
colnames(table_fit) <- c("Model", "X2", "df", "CFI", "RMSEA", "SRMR")
table_fit[1, ] <- c("Overall Model", round(fitmeasures(overall.fit, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

```

<br>

To check the confirmatory structure of our model, we will also create a picture of the standardized solution (quick and dirty; it can be edited...). The triangles depict the (standardized) intercepts, the arrows depic the variance (i.e. the loops) and (standardized) factor loadings. 

```{r}
library(semPlot)
semPaths(overall.fit, whatLabels = "std", layout = "tree")
```

### Longitudinal invariance {.tabset .tabset-fade}

Since we are dealing with panel data, and we want to explore movement over time in motivations, we should investigate to what extent our CFA solution is invariant over time (because we don't want to compare apples with oranges).
We will compare the SMS data of W1-W3 and compare them in CFA for configural, metric, scalar, and strict residual invariance (see e.g., [Cheung & Rensvold 2002](https://www.tandfonline.com/doi/pdf/10.1207/S15328007SEM0902_5?casa_token=scyVPZRkncQAAAAA:PDDawXxC0BMvLu-kjcvtaFcHseZnO3rkwX4nJGtd8OrK-nuTq4B1Mk571ajpjaq3JQhasVHnyXtofdg)).

We will use a new package for this. Apparently, this package only allows for multi-group equivalence testing for two groups (in Lavaan multiple groups can be compared); therefore, I will run the same procedure for each pair (i.e., W1 vs. W2, W2 vs. W3, and W1 vs. W3).

First, we will subset dataframes that only include two groups (i.e. waves) for comparison, for subsequent equivalence tests. 
```{r}
W1_2 <- ifelse(sms_long_nm$Timepoint == 1, 0, ifelse(sms_long_nm$Timepoint == 2, 1, NA))
sms12 <- sms_long_nm[!is.na(W1_2), ] # compare w1 and w2

W2_3 <- ifelse(sms_long_nm$Timepoint == 2, 0, ifelse(sms_long_nm$Timepoint == 3, 1, NA))
sms23 <- sms_long_nm[!is.na(W2_3), ] # compare w2 and w3

W1_3 <- ifelse(sms_long_nm$Timepoint == 1, 0, ifelse(sms_long_nm$Timepoint == 3, 1, NA))
sms13 <- sms_long_nm[!is.na(W1_3), ] # compare w1 and w3
```

<br>

#### Comparing Wave 1 and Wave 2 

```{r}
library(equaltestMI) #install package

# estimate the multi-group model
MG.model <- eqMI.main(model = motivation_model, 
                      data = sms12, 
                      group = "Timepoint", #comparing wave 1 and wave 2
                      meanstructure = TRUE, #include the means
                      output = "both", #means, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, #test equality of latent factor means (even when equality of intercepts does not hold)
                      bootstrap = FALSE,
                      quiet = TRUE)
```

Now we will summarize the results of the multi-group model, and add them to our previously made kable-table.

```{r}
table_fit[2, ] <- c("W1 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g1, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 1: Wave 1
table_fit[3, ] <- c("W2 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g2, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 2: Wave 2

```

And to test for configural invariance - is the 'picture'/structure of the model the same for both groups (i.e. waves), we stack the groups together.

```{r}
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

table_fit[4, ] <- c("Configural Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.combine.groups, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:4, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

This is the model against which we will test the next model. So, we will conduct a sequential testing analysis. Next, we will assess metric invariance, by constraining the factor loadings to be equal across the waves. In the configural model, factor loadings were "freely" estimated in both waves; now, only 1 loading gets estimated for both groups. Let's see what happens to the model. 

```{r}
table_fit[5, ] <- c("Metric Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.metric, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:5, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

The metric model seems to be invariant in comparison to the configural model: the CFI difference is smaller than .01, hence assuming invariance (same holds for RMSEA/SRMR). Conclusion: the metric model holds: the loadings are equal (or close enough). 

<br>

We have constrained our model to contain the same structure, the same loadings; now let's test for scalar invariance, to see if the intercepts are the same across waves. 

```{r}
table_fit[6, ] <- c("Scalar Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.scalar, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:6, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```


The intercepts are equal on the scale between the waves. 

<br>

Last, we constrain the model to the strict model, to check for strict residual invariance. It will inform whether the variance around items is the same across time.

```{r}
table_fit[7, ] <- c("Strict Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:7, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

From here it goes downwards... CFI dropped more than 0.01, suggesting that the residuals vary between the waves. We could estimate partial invariance, to investigate where the problem is and subsequently update the model to fix it. We are going to do so by freeing the variances of item residuals, one at a time, to figure out which equality constaint(s) is/are causing the problem. We will use the following loop for this. 

```{r}
# write out partial codes
partial_syntax <- paste(colnames(sms12)[3:26], #all sms columns
                        "~~", #residuals
                        colnames(sms12)[3:26]) #all columns again

CFI_list <- 1:length(partial_syntax)
names(CFI_list) <- partial_syntax 

for (i in 1:length(partial_syntax)){
  
  temp <- cfa(model = motivation_model,
              data = sms12,
              meanstructure = TRUE,
              group = "Timepoint",
              group.equal = c("loadings", "intercepts", "residuals"),
              group.partial = partial_syntax[i])
  
  CFI_list[i] <- fitmeasures(temp, "cfi")
}


# now figure out which parameters to "free"
options(scipen = 999)
sort(CFI_list - fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, "cfi", decreasing = T))
```

Let's free up those parameters. Starting with the one that increases CFI to the greatest extent. We will re-run the whole model for this

```{r}
MG.model_2 <- eqMI.main(model = motivation_model, 
                      data = sms12, 
                      group = "Timepoint", #comparing wave 1 and wave 2
                      meanstructure = TRUE,
                      group.partial = c("M1_6~~M1_6"), #free this parameter
                      output = "both", #mean, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, 
                      bootstrap = FALSE,
                      quiet = TRUE)

# check summary to see if the equality constraint is gone.
# summary(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals,
#        standardized = TRUE, rsquare = TRUE, fit.measure = TRUE)


table_fit[8, ] <- c("Strict Model M1_6", round(fitmeasures(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:8, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

CFI improved, but the difference with the baseline scalar model is still greater than .01. Thus, we still need to free (at least) one more, to achieve "partial" invariance. 

```{r}
MG.model_3 <- eqMI.main(model = motivation_model, 
                        data = sms12, 
                        group = "Timepoint", #comparing wave 1 and wave 2
                        meanstructure = TRUE,
                        group.partial = c("M1_6~~M1_6", "M1_7~~M1_7"), #free these parameters
                        output = "both", #mean, covariance, both
                        equivalence.test = FALSE, 
                        adjRMSEA = TRUE,
                        projection = TRUE, 
                        bootstrap = FALSE,
                        quiet = TRUE)

table_fit[9, ] <- c("Strict Model M1_6 + M1_7", round(fitmeasures(MG.model_3$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:9, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```


#### Comparing Wave 2 and Wave 3

```{r}
library(equaltestMI) #install package

# estimate the multi-group model
MG.model <- eqMI.main(model = motivation_model, 
                      data = sms23, 
                      group = "Timepoint", #comparing wave 2 and wave 3
                      meanstructure = TRUE, #include the means
                      output = "both", #means, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, #test equality of latent factor means (even when equality of intercepts does not hold)
                      bootstrap = FALSE,
                      quiet = TRUE)
```

Now we will summarize the results of the multi-group model, and add them to our previously made kable-table.

```{r}
table_fit[2, ] <- c("W2 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g1, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 1: Wave 2
table_fit[3, ] <- c("W3 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g2, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 2: Wave 3

```

And to test for configural invariance - is the 'picture'/structure of the model the same for both groups (i.e. waves), we stack the groups together.

```{r}
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

table_fit[4, ] <- c("Configural Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.combine.groups, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:4, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

This is the model against which we will test the next model. So, we will conduct a sequential testing analysis. Next, we will assess metric invariance, by constraining the factor loadings to be equal across the waves. In the configural model, factor loadings were "freely" estimated in both waves; now, only 1 loading gets estimated for both groups. Let's see what happens to the model. 

```{r}
table_fit[5, ] <- c("Metric Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.metric, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:5, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

The metric model seems to be invariant in comparison to the configural model: the CFI difference is smaller than .01, hence assuming invariance (same holds for RMSEA/SRMR). Conclusion: the metric model holds: the loadings are equal (or close enough). 

<br>

We have constrained our model to contain the same structure, the same loadings; now let's test for scalar invariance, to see if the intercepts are the same across waves. 

```{r}
table_fit[6, ] <- c("Scalar Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.scalar, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:6, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

The intercepts are equal on the scale between the waves. 

<br>

Last, we constrain the model to the strict model, to check for strict residual invariance. It will inform whether the variance around items is the same across time.

```{r}
table_fit[7, ] <- c("Strict Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:7, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

#### Comparing Wave 1 and Wave 3

```{r}
library(equaltestMI) #install package

# estimate the multi-group model
MG.model <- eqMI.main(model = motivation_model, 
                      data = sms13, 
                      group = "Timepoint", #comparing wave 1 and wave 3
                      meanstructure = TRUE, #include the means
                      output = "both", #means, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, #test equality of latent factor means (even when equality of intercepts does not hold)
                      bootstrap = FALSE,
                      quiet = TRUE)
```

Now we will summarize the results of the multi-group model, and add them to our previously made kable-table.

```{r}
table_fit[2, ] <- c("W1 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g1, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 1: Wave 1
table_fit[3, ] <- c("W3 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g2, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 2: Wave 3

```

And to test for configural invariance - is the 'picture'/structure of the model the same for both groups (i.e. waves), we stack the groups together.

```{r}
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

table_fit[4, ] <- c("Configural Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.combine.groups, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:4, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

This is the model against which we will test the next model. So, we will conduct a sequential testing analysis. Next, we will assess metric invariance, by constraining the factor loadings to be equal across the waves. In the configural model, factor loadings were "freely" estimated in both waves; now, only 1 loading gets estimated for both groups. Let's see what happens to the model. 

```{r}
table_fit[5, ] <- c("Metric Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.metric, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:5, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

The metric model seems to be invariant in comparison to the configural model: the CFI difference is smaller than .01, hence assuming invariance (same holds for RMSEA/SRMR). Conclusion: the metric model holds: the loadings are equal (or close enough). 

<br>

We have constrained our model to contain the same structure, the same loadings; now let's test for scalar invariance, to see if the intercepts are the same across waves. 

```{r}
table_fit[6, ] <- c("Scalar Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.scalar, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:6, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```


The intercepts are equal on the scale between the waves. 

<br>

Last, we constrain the model to the strict model, to check for strict residual invariance. It will inform whether the variance around items is the same across time.

```{r}
table_fit[7, ] <- c("Strict Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:7, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

From here it goes downwards... CFI dropped more than 0.01, suggesting that the residuals vary between the waves. We could estimate partial invariance, to investigate where the problem is and subsequently update the model to fix it. We are going to do so by freeing the variances of item residuals, one at a time, to figure out which equality constaint(s) is/are causing the problem. We will use the following loop for this. 

```{r}
# write out partial codes
partial_syntax <- paste(colnames(sms12)[3:26], #all sms columns
                        "~~", #residuals
                        colnames(sms12)[3:26]) #all columns again

CFI_list <- 1:length(partial_syntax)
names(CFI_list) <- partial_syntax 

for (i in 1:length(partial_syntax)){
  
  temp <- cfa(model = motivation_model,
              data = sms13,
              meanstructure = TRUE,
              group = "Timepoint",
              group.equal = c("loadings", "intercepts", "residuals"),
              group.partial = partial_syntax[i])
  
  CFI_list[i] <- fitmeasures(temp, "cfi")
}


# now figure out which parameters to "free"
options(scipen = 999)
sort(CFI_list - fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, "cfi", decreasing = T))
```

Let's free up those parameters. Starting with the one that increases CFI to the greatest extent. We will re-run the whole model for this

```{r}
MG.model_2 <- eqMI.main(model = motivation_model, 
                      data = sms13, 
                      group = "Timepoint", #comparing wave 1 and wave 3
                      meanstructure = TRUE,
                      group.partial = c("M1_7~~M1_7"), #free this parameter
                      output = "both", #mean, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, 
                      bootstrap = FALSE,
                      quiet = TRUE)

# check summary to see if the equality constraint is gone.
# summary(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals,
#        standardized = TRUE, rsquare = TRUE, fit.measure = TRUE)


table_fit[8, ] <- c("Strict Model M1_7", round(fitmeasures(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:8, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

CFI improved, but the difference with the baseline scalar model is still greater than .01. Thus, we still need to free (at least) one more, to achieve "partial" invariance. 

```{r}
MG.model_3 <- eqMI.main(model = motivation_model, 
                        data = sms13, 
                        group = "Timepoint", #comparing wave 1 and wave 3
                        meanstructure = TRUE,
                        group.partial = c("M1_7~~M1_7", "M3_5~~M3_5"), #free these parameters
                        output = "both", #mean, covariance, both
                        equivalence.test = FALSE, 
                        adjRMSEA = TRUE,
                        projection = TRUE, 
                        bootstrap = FALSE,
                        quiet = TRUE)

table_fit[9, ] <- c("Strict Model M1_7 + M3_5", round(fitmeasures(MG.model_3$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

Ditto

```{r}
MG.model_4 <- eqMI.main(model = motivation_model, 
                        data = sms13, 
                        group = "Timepoint", #comparing wave 1 and wave 3
                        meanstructure = TRUE,
                        group.partial = c("M1_7~~M1_7", "M3_5~~M3_5", "M1_5~~M1_5"), #free these parameters
                        output = "both", #mean, covariance, both
                        equivalence.test = FALSE, 
                        adjRMSEA = TRUE,
                        projection = TRUE, 
                        bootstrap = FALSE,
                        quiet = TRUE)

table_fit[9, ] <- c("Strict Model M1_7 + M3_5 + M1_5", round(fitmeasures(MG.model_4$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```



<br>

### Conclusion

We can conclude that the SMS is mostly invariant - the structure, factor loadings, intercepts, and most of the error variances were equal across time.

<br>

### Weighted factor-scores
Now we use the invariant measurement model to generate (weighted) factor scores as input variables for the subsequent LPA. Weighted factor scores are computed by multiplying the factor loading of each item to the scaled score for each item before summing (see [DiStefano et al. (2009)](https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1226&context=pare)). 

We will first fit the CFA, fixing the loading of the first variable of each variable to 1. Then we will extract the loadings, and calculate the weighted sum scores. 

**Note**: we now assumed strict measurement invariance (instead of strong), so we may want to free some parameters...

```{r}
fit <- cfa(model = motivation_model, data = sms_long_nm,
           std.lv = FALSE) # default: not standardized but fixing the first loading on each latent variable to 1.
 
loading <- parameterEstimates(fit)$est[1:24] # extract factor loadings

# calculate weighted sum scores
sms_long_nm$amotivation <- rowMeans(cbind((sms_long_nm$M1_5*loading[1]), (sms_long_nm$M2_4*loading[2]), (sms_long_nm$M3_1*loading[3]), (sms_long_nm$M3_6*loading[4])))

sms_long_nm$external <- rowMeans(cbind((sms_long_nm$M1_4*loading[5]), (sms_long_nm$M2_3*loading[6]), (sms_long_nm$M3_3*loading[7]),   (sms_long_nm$M3_8*loading[8])))

sms_long_nm$introjected <- rowMeans(cbind((sms_long_nm$M1_7*loading[9]), (sms_long_nm$M2_2*loading[10]), (sms_long_nm$M2_8*loading[11]), (sms_long_nm$M3_7*loading[12])))

sms_long_nm$identified <- rowMeans(cbind((sms_long_nm$M1_3*loading[13]), (sms_long_nm$M1_8*loading[14]), (sms_long_nm$M2_7*loading[15]), (sms_long_nm$M3_4*loading[16])))

sms_long_nm$integrated <- rowMeans(cbind((sms_long_nm$M1_2*loading[17]), (sms_long_nm$M2_1*loading[18]), (sms_long_nm$M2_5*loading[19]), (sms_long_nm$M3_5*loading[20])))

sms_long_nm$intrinsic <- rowMeans(cbind((sms_long_nm$M1_1*loading[21]), (sms_long_nm$M1_6*loading[22]), (sms_long_nm$M2_6*loading[23]), (sms_long_nm$M3_2*loading[24])))
```

<br>

----

## 3. Descriptives

Let's describe our weighted factor scores over time. 

```{r}
library(crosstable)

input <- sms_long_nm %>% #get factor scores and timepoint as grouping variable
  select(27:32, 2)

crosstable(input, by=Timepoint,
           funs=c("Mean" = mean, "Std. dev." = sd, "Min" = min, "Max" = max), funs_arg=list(digits=3)) %>%
  as_flextable(by_header = "Wave")
```

And let's see how many respondents we have in each wave (**note-to-self**: integrate in previous table...).

```{r}
knitr::kable(table(sms_long_nm$Timepoint), "html", caption="Number of respondents in each wave", col.names = c("Wave", "N"), align = 'l' ) %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

At face value, respondents seem to be pretty high in all types of motivation (e.g., compared with the sample of [Emm-Collison and colleagues](https://www.sciencedirect.com/science/article/pii/S1469029219303851) - though these were sum scores).


<br>

----

# LPA  

## Step 1 

### {.tabset .tabset-fade}

As a first step for the LPA, we carefully select a measurement model that accurately captures the construct of motivational profile. We will fit a series of measurement models for each wave to determine which model provides the best fit at each wave (following recommendations of [Nylund et al. (2007)](https://srcd.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-8624.2007.01097.x?casa_token=0wyzjh9Ozk0AAAAA:iasgTYid_gJ5kGH42Jyys61DsBhEDl0zxVrukoJdaeX2e2MGOlm1nfyooEUc1v5SaB3lFYyX1wqVLGNOvQ) and similar to the article by [Martinent & Decret (2015)](https://www.tandfonline.com/doi/pdf/10.1080/10413200.2014.993485?casa_token=CsBgfG9lbtgAAAAA:CMEXxc96xNC-rF6Sowi7X2X0qvXlxI9MuODWtQ1Db92UyZUeLZcWJem1jhhympbi8dBboyrA282A5Ns)).

<br>

#### Wave 1

We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).

```{r}
sms_w1 <- sms_long_nm[sms_long_nm$Timepoint==1, ] %>%
  select(-Timepoint, -id) %>% # subset W1
  select(25:30) %>% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
```

We then compute the model-based clustering, and ask for a summary.
```{r}
library(mclust)
mc <- Mclust(sms_w1)
summary(mc)                 
```

For this wave, Mclust selected a model with 9 (!) profiles; the optimal selected model is EEV, i.e., the profiles are ellipsoidal with equal volume, shape and varying orientation (see [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/)). However, note that VEV, 9 is only slightly behind, and that for all solutions with fewer clusters, the VEV model fitted better.

Now we will access to the results and visualize the model. To visualize, we will use a new package (*factoextra*), to create nicer plots based on ggplot2.

```{r}
library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, "BIC", palette = "jco")
```

#### Wave 2

We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).

```{r}
sms_w2 <- sms_long_nm[sms_long_nm$Timepoint==2, ] %>%
  select(-Timepoint, -id) %>% # subset W2
  select(25:30) %>% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
```

We then compute the model-based clustering, and ask for a summary.
```{r}
library(mclust)
mc <- Mclust(sms_w2)
summary(mc)                 
```

For this wave, Mclust selected a model with 7 (!) profiles; the optimal selected model is VEV, i.e., the profiles are ellipsoidal with equal shape (see [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/)). 

Now we will access to the results and visualize the model. To visualize, we will use a new package (*factoextra*), to create nicer plots based on ggplot2.

```{r}
library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, "BIC", palette = "jco")
```

#### Wave 3

We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).

```{r}
sms_w3 <- sms_long_nm[sms_long_nm$Timepoint==3, ] %>%
  select(-Timepoint, -id) %>% # subset W1
  select(25:30) %>% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
```

We then compute the model-based clustering, and ask for a summary.
```{r}
library(mclust)
mc <- Mclust(sms_w3)
summary(mc)                 
```

For this wave, Mclust selected a model with 9 (!) profiles; the optimal selected model is VEV, i.e., the profiles are ellipsoidal with equal shape (see [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/)). 

```{r}
library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, "BIC", palette = "jco")
```

### {.tabset .tabset-fade}

We will examine a sequence of models, with an increasing number of profiles from 2 to ..., to ascertain whether more complex (i.e. more profiles) or parsimonious (i.e. fewer profiles) models provided the best description of the data. We will use the VEV model (varying volume, equal shape, varying orientation).

We will plot the profile means, the clustering and the clustering uncertainty. If the data contain more than two variables (which is the case in our data), the *fviz_mclust()*-function will use PCA to reduce the dimensionality of the data. The first two principal components are used to produce a scatter plot of the data. If we want to plot the data using only two variables (e.g., *external regulation* and *intrinsic motivation*), we can specify that in the function using the argument *choose.vars = c("external", "intrinsic")*. Note that, in the uncertainty plot, larger symbols indicate the more uncertain observations.

<br>

#### Wave 1

##### {.tabset .tabset-fade}

###### 2 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1) 
m2 <- Mclust(sms_w1, modelNames = "VEV", G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m2, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m2, "uncertainty", palette = "jco")
```

###### 3 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1) 
m3 <- Mclust(sms_w1, modelNames = "VEV", G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m3, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m3, "uncertainty", palette = "jco")
```

###### 4 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1) 
m4 <- Mclust(sms_w1, modelNames = "VEV", G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m4, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m4, "uncertainty", palette = "jco")
```

###### 5 profiles
```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1) 
m5 <- Mclust(sms_w1, modelNames = "VEV", G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m5, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m5, "uncertainty", palette = "jco")
```

#### Wave 2

##### {.tabset .tabset-fade}

###### 2 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2) 
m2 <- Mclust(sms_w2, modelNames = "VEV", G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m2, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m2, "uncertainty", palette = "jco")
```

###### 3 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2) 
m3 <- Mclust(sms_w2, modelNames = "VEV", G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m3, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m3, "uncertainty", palette = "jco")
```

###### 4 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2) 
m4 <- Mclust(sms_w2, modelNames = "VEV", G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m4, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m4, "uncertainty", palette = "jco")
```

###### 5 profiles
```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2) 
m5 <- Mclust(sms_w2, modelNames = "VEV", G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m5, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m5, "uncertainty", palette = "jco")
```





#### Wave 3

##### {.tabset .tabset-fade}

###### 2 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3) 
m2 <- Mclust(sms_w3, modelNames = "VEV", G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m2, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m2, "uncertainty", palette = "jco")
```

###### 3 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3) 
m3 <- Mclust(sms_w3, modelNames = "VEV", G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m3, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m3, "uncertainty", palette = "jco")
```

###### 4 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3) 
m4 <- Mclust(sms_w3, modelNames = "VEV", G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m4, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m4, "uncertainty", palette = "jco")
```

###### 5 profiles
```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3) 
m5 <- Mclust(sms_w3, modelNames = "VEV", G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m5, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m5, "uncertainty", palette = "jco")
```
