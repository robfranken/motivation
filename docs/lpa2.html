<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Latent Profile Analysis using Mclust</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
#rmd-source-code {
  display: none;
}
</style>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Motivation</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="lpa1.html">Exploring LPA</a>
</li>
<li>
  <a href="lpa2.html">CFA input</a>
</li>
<li>
  <a href="lpa3.html">Weighted sum scores</a>
</li>
<li>
  <a href="lpta.html">LPTA</a>
</li>
<li>
  <a href="site.html">Sources</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
<li role="separator" class="divider"></li>
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Latent Profile Analysis using Mclust</h1>

</div>


<p><br></p>
<div id="part-2" class="section level2">
<h2>PART 2</h2>
<p><em>Last edited: January 20, 2021</em></p>
<p><br></p>
<p>Let’s now estimate the LPA model with as input the CFA factor-scores. Again, the idea is that this would provide subscale estimates that consider the unique contribution of each item (instead of averaging over all items), resulting in “true” motivational configurations (see <a href="https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1226&amp;context=pare">this article</a>).</p>
<p>We are going to use the <a href="http://www.understandingdata.net/2017/03/22/cfa-in-lavaan/"><em>Lavaan</em></a>-package for CFA.</p>
<hr />
</div>
<div id="data" class="section level1">
<h1>1. Data</h1>
<p>Let’s call our ‘cleaned’ SMS-data again.</p>
<pre class="r"><code>library(sjlabelled)
library(dplyr)
library(tidyverse)
library(careless)
library(psych)

load(&quot;data_abs_public_v2.RData&quot;) # load data
data_abs_public &lt;- unlabel(data_abs_public, verbose=F)

sms &lt;- data_abs_public %&gt;% select(W1_M1_1, W1_M1_2, W1_M1_3, W1_M1_4, W1_M1_5, W1_M1_6, W1_M1_7, W1_M1_8, W1_M2_1, W1_M2_2, W1_M2_3, W1_M2_4, W1_M2_5, W1_M2_6, W1_M2_7, W1_M2_8, W1_M3_1, W1_M3_2, W1_M3_3, W1_M3_4, W1_M3_5, W1_M3_6, W1_M3_7, W1_M3_8) # subset W1

sms$id &lt;- 1:length(sms[, 1]) # add identifier

sms &lt;- sms %&gt;%
  mutate(string = longstring(.)) %&gt;%
  mutate(md = outlier(., plot = FALSE)) # make string variable

cutoff &lt;- (qchisq(p = 1 - .001, df = ncol(sms)))
sms_clean &lt;- sms %&gt;%
  filter(string &lt;= 10,
         md &lt; cutoff) %&gt;%
  select(-string, -md) # cap string responding and use MD</code></pre>
<p><br></p>
<hr />
</div>
<div id="cfa" class="section level1">
<h1>2. CFA</h1>
<p>Now we are going to perform confirmatory factor analysis using Lavaan. First, tell Lavaan the confirmatory structure.</p>
<pre class="r"><code>library(lavaan)

motivation_model &lt;- &quot;
amotivation =~ W1_M1_5 + W1_M2_4 + W1_M3_1 + W1_M3_6
external    =~ W1_M1_4 + W1_M2_3 + W1_M3_3 + W1_M3_8
introjected =~ W1_M1_7 + W1_M2_2 + W1_M2_8 + W1_M3_7
identified  =~ W1_M1_3 + W1_M1_8 + W1_M2_7 + W1_M3_4
integrated  =~ W1_M1_2 + W1_M2_1 + W1_M2_5 + W1_M3_5
intrinsic   =~ W1_M1_1 + W1_M1_6 + W1_M2_6 + W1_M3_2
id ~~ id&quot;</code></pre>
<p>When performing CFA (or any latent variable modeling) the question remains what scale to assign to the latent variable. Many statistical programs (including Lavaan) fix the loading of the first variable for a given latent variable to 1, which assigns the scale of that manifest indicator to the latent variable. We will use a standardized scale for the latent variable (i.e. mean = 0, sd = 1): the loading of the first variable is then freely estimated.</p>
<p>The default treatment of missing data is listwise deletion; perhaps not what we want. Later on we can try full information maximum likelihood (FIML), which will generally result in estimates similar to what you would get with multiple impution, but with the added advantage that it’s all done in one step.</p>
<pre class="r"><code>fit &lt;- cfa(motivation_model, data=sms_clean, # use the &#39;clean&#39; data
            std.lv=T # this tells lavaan to use a standardized scale for the latent variables.
)</code></pre>
<p>Let’s call the CFA output with the <em>knitr</em>-package.</p>
<pre class="r"><code>library(knitr)

options(knitr.kable.NA = &#39;&#39;) # this will hide missing values in the kable table

parameterEstimates(fit, standardized=TRUE) %&gt;% 
  filter(op == &quot;=~&quot;) %&gt;% 
  mutate(stars = ifelse(pvalue &lt; .001, &quot;***&quot;, ifelse(pvalue &lt; .01, &quot;**&quot;, ifelse(pvalue &lt; .05, &quot;*&quot;, &quot;&quot;)))) %&gt;%
  select(&#39;Latent Factor&#39;=lhs, 
         Indicator=rhs, 
         B=est, 
         SE=se, Z=z, 
         Beta=std.all, 
         sig=stars) %&gt;% 
  kable(digits = 3, format=&quot;pandoc&quot;, caption=&quot;Table 1. Latent Factor Loadings&quot;
  )</code></pre>
<table>
<caption>Table 1. Latent Factor Loadings</caption>
<thead>
<tr class="header">
<th align="left">Latent Factor</th>
<th align="left">Indicator</th>
<th align="right">B</th>
<th align="right">SE</th>
<th align="right">Z</th>
<th align="right">Beta</th>
<th align="left">sig</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">amotivation</td>
<td align="left">W1_M1_5</td>
<td align="right">0.367</td>
<td align="right">0.022</td>
<td align="right">16.873</td>
<td align="right">0.691</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">amotivation</td>
<td align="left">W1_M2_4</td>
<td align="right">0.444</td>
<td align="right">0.032</td>
<td align="right">13.921</td>
<td align="right">0.609</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">amotivation</td>
<td align="left">W1_M3_1</td>
<td align="right">0.403</td>
<td align="right">0.022</td>
<td align="right">18.084</td>
<td align="right">0.773</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">amotivation</td>
<td align="left">W1_M3_6</td>
<td align="right">0.467</td>
<td align="right">0.046</td>
<td align="right">10.055</td>
<td align="right">0.456</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">external</td>
<td align="left">W1_M1_4</td>
<td align="right">0.957</td>
<td align="right">0.056</td>
<td align="right">17.029</td>
<td align="right">0.668</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">external</td>
<td align="left">W1_M2_3</td>
<td align="right">0.870</td>
<td align="right">0.054</td>
<td align="right">16.045</td>
<td align="right">0.648</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">external</td>
<td align="left">W1_M3_3</td>
<td align="right">1.033</td>
<td align="right">0.066</td>
<td align="right">15.682</td>
<td align="right">0.635</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">external</td>
<td align="left">W1_M3_8</td>
<td align="right">0.801</td>
<td align="right">0.052</td>
<td align="right">15.265</td>
<td align="right">0.628</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">introjected</td>
<td align="left">W1_M1_7</td>
<td align="right">0.905</td>
<td align="right">0.057</td>
<td align="right">15.795</td>
<td align="right">0.612</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">introjected</td>
<td align="left">W1_M2_2</td>
<td align="right">1.302</td>
<td align="right">0.065</td>
<td align="right">19.924</td>
<td align="right">0.735</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">introjected</td>
<td align="left">W1_M2_8</td>
<td align="right">1.287</td>
<td align="right">0.062</td>
<td align="right">20.805</td>
<td align="right">0.761</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">introjected</td>
<td align="left">W1_M3_7</td>
<td align="right">1.196</td>
<td align="right">0.067</td>
<td align="right">17.823</td>
<td align="right">0.678</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">identified</td>
<td align="left">W1_M1_3</td>
<td align="right">0.875</td>
<td align="right">0.073</td>
<td align="right">12.037</td>
<td align="right">0.507</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">identified</td>
<td align="left">W1_M1_8</td>
<td align="right">1.026</td>
<td align="right">0.077</td>
<td align="right">13.355</td>
<td align="right">0.562</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">identified</td>
<td align="left">W1_M2_7</td>
<td align="right">0.719</td>
<td align="right">0.064</td>
<td align="right">11.229</td>
<td align="right">0.459</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">identified</td>
<td align="left">W1_M3_4</td>
<td align="right">1.053</td>
<td align="right">0.064</td>
<td align="right">16.573</td>
<td align="right">0.615</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">integrated</td>
<td align="left">W1_M1_2</td>
<td align="right">1.012</td>
<td align="right">0.057</td>
<td align="right">17.709</td>
<td align="right">0.660</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">integrated</td>
<td align="left">W1_M2_1</td>
<td align="right">1.244</td>
<td align="right">0.068</td>
<td align="right">18.273</td>
<td align="right">0.683</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">integrated</td>
<td align="left">W1_M2_5</td>
<td align="right">1.203</td>
<td align="right">0.067</td>
<td align="right">18.015</td>
<td align="right">0.674</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">integrated</td>
<td align="left">W1_M3_5</td>
<td align="right">1.398</td>
<td align="right">0.064</td>
<td align="right">21.776</td>
<td align="right">0.779</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">intrinsic</td>
<td align="left">W1_M1_1</td>
<td align="right">0.959</td>
<td align="right">0.072</td>
<td align="right">13.409</td>
<td align="right">0.528</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">intrinsic</td>
<td align="left">W1_M1_6</td>
<td align="right">1.270</td>
<td align="right">0.071</td>
<td align="right">17.805</td>
<td align="right">0.666</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">intrinsic</td>
<td align="left">W1_M2_6</td>
<td align="right">1.413</td>
<td align="right">0.065</td>
<td align="right">21.669</td>
<td align="right">0.779</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">intrinsic</td>
<td align="left">W1_M3_2</td>
<td align="right">1.275</td>
<td align="right">0.064</td>
<td align="right">20.020</td>
<td align="right">0.732</td>
<td align="left">***</td>
</tr>
</tbody>
</table>
<p>So, as an example, for a 1-unit increase in the latent variable <em>amotivation</em> (i.e. 1-SD increase), the model predicts a 0.367 increase in W1_M1_5.</p>
<p><br></p>
<p>Let’s also get the correlations between the factors.</p>
<pre class="r"><code>parameterEstimates(fit, standardized=TRUE) %&gt;% 
  filter(op == &quot;~~&quot;, 
         lhs %in% c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;), 
         !is.na(pvalue)) %&gt;% 
  mutate(stars = ifelse(pvalue &lt; .001, &quot;***&quot;, 
                        ifelse(pvalue &lt; .01, &quot;**&quot;, 
                               ifelse(pvalue &lt; .05, &quot;*&quot;, &quot;&quot;)))) %&gt;% 
  select(&#39;Factor 1&#39;=lhs, 
         &#39;Factor 2&#39;=rhs, 
         Correlation=est, 
         sig=stars) %&gt;% 
  kable(digits = 3, format=&quot;pandoc&quot;, caption=&quot;Table 2: Latent Factor Correlations&quot;)</code></pre>
<table>
<caption>Table 2: Latent Factor Correlations</caption>
<thead>
<tr class="header">
<th align="left">Factor 1</th>
<th align="left">Factor 2</th>
<th align="right">Correlation</th>
<th align="left">sig</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">amotivation</td>
<td align="left">external</td>
<td align="right">0.192</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">amotivation</td>
<td align="left">introjected</td>
<td align="right">0.005</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">amotivation</td>
<td align="left">identified</td>
<td align="right">0.074</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">amotivation</td>
<td align="left">integrated</td>
<td align="right">-0.136</td>
<td align="left">**</td>
</tr>
<tr class="odd">
<td align="left">amotivation</td>
<td align="left">intrinsic</td>
<td align="right">-0.032</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">external</td>
<td align="left">introjected</td>
<td align="right">0.422</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">external</td>
<td align="left">identified</td>
<td align="right">0.863</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">external</td>
<td align="left">integrated</td>
<td align="right">0.544</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">external</td>
<td align="left">intrinsic</td>
<td align="right">0.631</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">introjected</td>
<td align="left">identified</td>
<td align="right">0.641</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">introjected</td>
<td align="left">integrated</td>
<td align="right">0.763</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">introjected</td>
<td align="left">intrinsic</td>
<td align="right">0.459</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">identified</td>
<td align="left">integrated</td>
<td align="right">0.797</td>
<td align="left">***</td>
</tr>
<tr class="even">
<td align="left">identified</td>
<td align="left">intrinsic</td>
<td align="right">0.963</td>
<td align="left">***</td>
</tr>
<tr class="odd">
<td align="left">integrated</td>
<td align="left">intrinsic</td>
<td align="right">0.644</td>
<td align="left">***</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>Now extract the factor scores, put them into a dataframe, delete missings, and standardize the factor scores (again). Also, we make a descriptive table.</p>
<pre class="r"><code>fs &lt;- lavPredict(fit, newdata = sms_clean, append.data = TRUE) # extract
fs &lt;- as.data.frame(fs[, c(1:6, 31)]) # subset factor scores and identifier in df
clus &lt;- fs %&gt;%
  select(-id) %&gt;%
  na.omit() %&gt;% # listwise deletion
  mutate_all(list(scale)) # standardize

clus$id &lt;- fs$id # add id again...

library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)

# describe

input &lt;- clus %&gt;% 
  select(-id) %&gt;% 
  gather(&quot;Variable&quot;, &quot;value&quot;) %&gt;% 
  group_by(Variable) %&gt;%
  summarise(Mean=mean(value, na.rm=TRUE), 
            SD=sd(value, na.rm=TRUE), 
            min=min(value, na.rm=TRUE), 
            max=max(value, na.rm=TRUE))

knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;Table 3. Descriptives of standardized factor scores SMS W1&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;)) </code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
Table 3. Descriptives of standardized factor scores SMS W1
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
SD
</th>
<th style="text-align:right;">
min
</th>
<th style="text-align:right;">
max
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
amotivation
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.71
</td>
<td style="text-align:right;">
6.61
</td>
</tr>
<tr>
<td style="text-align:left;">
external
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-1.56
</td>
<td style="text-align:right;">
3.01
</td>
</tr>
<tr>
<td style="text-align:left;">
identified
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-2.25
</td>
<td style="text-align:right;">
2.79
</td>
</tr>
<tr>
<td style="text-align:left;">
integrated
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-2.49
</td>
<td style="text-align:right;">
2.15
</td>
</tr>
<tr>
<td style="text-align:left;">
intrinsic
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-2.05
</td>
<td style="text-align:right;">
2.77
</td>
</tr>
<tr>
<td style="text-align:left;">
introjected
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-2.83
</td>
<td style="text-align:right;">
1.83
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>And check the distribution of our variables</p>
<pre class="r"><code>library(Hmisc)
hist(clus %&gt;%
       select(-id))</code></pre>
<p><img src="lpa2_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The produced standardized scores somewhat approximate a Z-score metric (i.e. where values range from ca. -3 to +3). Note that <em>amotivation</em> is an exception to the rule: it is very much right-skewed and has high kurtosis.</p>
<p><br></p>
<hr />
</div>
<div id="lpa" class="section level1">
<h1>3. LPA</h1>
<p>Let’s follow the same procedure for LPA, but now we include the standardized factor scores as input.</p>
<div id="model-fit" class="section level2 tabset tabset-fade">
<h2>Model fit</h2>
<p>Starting off by exploring model fit again, by plotting it.</p>
<div id="bic" class="section level3">
<h3>BIC</h3>
<pre class="r fold-hide"><code>library(mclust)
BIC &lt;- mclustBIC(clus %&gt;%
                   select(-id)) # exclude id
plot(BIC)</code></pre>
<p><img src="lpa2_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="icl" class="section level3">
<h3>ICL</h3>
<pre class="r fold-hide"><code>library(mclust)
ICL &lt;- mclustICL(clus %&gt;%
               select(-id))
plot(ICL)</code></pre>
<p><img src="lpa2_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="blrt" class="section level3">
<h3>BLRT</h3>
<pre class="r"><code>library(mclust)
mclustBootstrapLRT(clus %&gt;%
               select(-id), modelName = &quot;VEV&quot;)</code></pre>
</div>
</div>
<div id="section" class="section level2 unnumbered">
<h2></h2>
<p>And use the <em>summary</em>-function to show the top-three models based on BIC and ICL.</p>
</div>
<div id="section-1" class="section level2 tabset tabset-fade">
<h2></h2>
<div id="bic-1" class="section level3">
<h3>BIC</h3>
<pre class="r fold-hide"><code>summary(BIC)</code></pre>
<pre><code>## Best BIC values:
##            VEV,8       VEV,9      VEV,6
## BIC      -2791.8 -2834.11542 -3087.2602
## BIC diff     0.0   -42.31564  -295.4604</code></pre>
</div>
<div id="icl-1" class="section level3">
<h3>ICL</h3>
<pre class="r fold-hide"><code>summary(ICL)</code></pre>
<pre><code>## Best ICL values:
##              VEV,8       VEV,9      VEV,6
## ICL      -2894.032 -2943.38586 -3146.7988
## ICL diff     0.000   -49.35412  -252.7671</code></pre>
</div>
</div>
<div id="section-2" class="section level2 unnumbered">
<h2></h2>
<p><br></p>
<hr />
</div>
</div>
<div id="visualizing-lpa" class="section level1">
<h1>4. Visualizing LPA</h1>
<div id="section-3" class="section level2 tabset tabset-fade">
<h2></h2>
<p>Statistically, the best model is the VEV, 8. We do not plot this, but we estimate a sequence of models, incrementally increasing the number of profiles, until they do not provide theoretical additions to the model. Plotting the models will make it easier to, intuitively, assess which model is suitable. We start with 2 profiles.</p>
<div id="profiles" class="section level3">
<h3>2 profiles</h3>
<pre class="r fold-hide"><code>m2 &lt;- Mclust(clus %&gt;%
               select(-id),
             modelNames = &quot;VEV&quot;, G = 2, x = BIC)
summary(m2) </code></pre>
<pre><code>## ---------------------------------------------------- 
## Gaussian finite mixture model fitted by EM algorithm 
## ---------------------------------------------------- 
## 
## Mclust VEV (ellipsoidal, equal shape) model with 2 components: 
## 
##  log-likelihood   n df       BIC      ICL
##       -1533.622 645 50 -3390.707 -3394.49
## 
## Clustering table:
##   1   2 
## 436 209</code></pre>
<pre class="r fold-hide"><code>means &lt;- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %&gt;% 
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;% 
  mutate(Mean = round(Mean, 2))
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean latent SMS factor scores&quot;) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpa2_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
<div id="profiles-1" class="section level3">
<h3>3 profiles</h3>
<pre class="r fold-hide"><code>m3 &lt;- Mclust(clus %&gt;%
               select(-id),
             modelNames = &quot;VEV&quot;, G = 3, x = BIC)
summary(m3) </code></pre>
<pre><code>## ---------------------------------------------------- 
## Gaussian finite mixture model fitted by EM algorithm 
## ---------------------------------------------------- 
## 
## Mclust VEV (ellipsoidal, equal shape) model with 3 components: 
## 
##  log-likelihood   n df       BIC       ICL
##       -1413.333 645 73 -3298.921 -3311.212
## 
## Clustering table:
##   1   2   3 
##  30 182 433</code></pre>
<pre class="r fold-hide"><code>means &lt;- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %&gt;% 
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;% 
  mutate(Mean = round(Mean, 2))
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean latent SMS factor scores&quot;) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpa2_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
</div>
<div id="profiles-2" class="section level3">
<h3>4 profiles</h3>
<pre class="r fold-hide"><code>m4 &lt;- Mclust(clus %&gt;%
               select(-id),
             modelNames = &quot;VEV&quot;, G = 4, x = BIC)
summary(m4) </code></pre>
<pre><code>## ---------------------------------------------------- 
## Gaussian finite mixture model fitted by EM algorithm 
## ---------------------------------------------------- 
## 
## Mclust VEV (ellipsoidal, equal shape) model with 4 components: 
## 
##  log-likelihood   n df       BIC       ICL
##       -1346.123 645 96 -3313.294 -3328.086
## 
## Clustering table:
##   1   2   3   4 
##  27 164 432  22</code></pre>
<pre class="r fold-hide"><code>means &lt;- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %&gt;% 
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;% 
  mutate(Mean = round(Mean, 2))
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean latent SMS factor scores&quot;) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpa2_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="profiles-3" class="section level3">
<h3>5 profiles</h3>
<pre class="r fold-hide"><code>m5 &lt;- Mclust(clus %&gt;%
               select(-id),
             modelNames = &quot;VEV&quot;, G = 5, x = BIC)
summary(m5) </code></pre>
<pre><code>## ---------------------------------------------------- 
## Gaussian finite mixture model fitted by EM algorithm 
## ---------------------------------------------------- 
## 
## Mclust VEV (ellipsoidal, equal shape) model with 5 components: 
## 
##  log-likelihood   n  df       BIC       ICL
##        -1176.75 645 119 -3123.341 -3180.644
## 
## Clustering table:
##   1   2   3   4   5 
##  25 151 292  34 143</code></pre>
<pre class="r fold-hide"><code>means &lt;- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %&gt;% 
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;% 
  mutate(Mean = round(Mean, 2))
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean latent SMS factor scores&quot;) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpa2_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
</div>
</div>
<div id="section-4" class="section level2 unnumbered">
<h2></h2>
<p><br></p>
<hr />
<p>The output shows less theoretically interpretable motivational profiles compared to the previous LPA… As a last approach (see next page), we will use weighted sum scores (as described on page 3 of <a href="https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1226&amp;context=pare">this article</a>).</p>
</div>
</div>

<div id="rmd-source-code">---
title: "Latent Profile Analysis using Mclust"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 1
    code_folding: show
    code_download: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

<br>

## PART 2
*Last edited: January 20, 2021*

<br>

Let's now estimate the LPA model with as input the CFA factor-scores. Again, the idea is that this would provide subscale estimates that consider the unique contribution of each item (instead of averaging over all items), resulting in "true" motivational configurations (see [this article](https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1226&context=pare)).

We are going to use the [*Lavaan*](http://www.understandingdata.net/2017/03/22/cfa-in-lavaan/)-package for CFA. 


---

# 1. Data

Let's call our 'cleaned' SMS-data again.

```{r, warning=FALSE, message=FALSE}
library(sjlabelled)
library(dplyr)
library(tidyverse)
library(careless)
library(psych)

load("data_abs_public_v2.RData") # load data
data_abs_public <- unlabel(data_abs_public, verbose=F)

sms <- data_abs_public %>% select(W1_M1_1, W1_M1_2, W1_M1_3, W1_M1_4, W1_M1_5, W1_M1_6, W1_M1_7, W1_M1_8, W1_M2_1, W1_M2_2, W1_M2_3, W1_M2_4, W1_M2_5, W1_M2_6, W1_M2_7, W1_M2_8, W1_M3_1, W1_M3_2, W1_M3_3, W1_M3_4, W1_M3_5, W1_M3_6, W1_M3_7, W1_M3_8) # subset W1

sms$id <- 1:length(sms[, 1]) # add identifier

sms <- sms %>%
  mutate(string = longstring(.)) %>%
  mutate(md = outlier(., plot = FALSE)) # make string variable

cutoff <- (qchisq(p = 1 - .001, df = ncol(sms)))
sms_clean <- sms %>%
  filter(string <= 10,
         md < cutoff) %>%
  select(-string, -md) # cap string responding and use MD
```

<br>

----

# 2. CFA

Now we are going to perform confirmatory factor analysis using Lavaan. First, tell Lavaan the confirmatory structure.

```{r}
library(lavaan)

motivation_model <- "
amotivation =~ W1_M1_5 + W1_M2_4 + W1_M3_1 + W1_M3_6
external    =~ W1_M1_4 + W1_M2_3 + W1_M3_3 + W1_M3_8
introjected =~ W1_M1_7 + W1_M2_2 + W1_M2_8 + W1_M3_7
identified  =~ W1_M1_3 + W1_M1_8 + W1_M2_7 + W1_M3_4
integrated  =~ W1_M1_2 + W1_M2_1 + W1_M2_5 + W1_M3_5
intrinsic   =~ W1_M1_1 + W1_M1_6 + W1_M2_6 + W1_M3_2
id ~~ id"
```

When performing CFA (or any latent variable modeling) the question remains what scale to assign to the latent variable. Many statistical programs (including Lavaan) fix the loading of the first variable for a given latent variable to 1, which assigns the scale of that manifest indicator to the latent variable. We will use a standardized scale for the latent variable (i.e. mean = 0, sd = 1): the loading of the first variable is then freely estimated.

The default treatment of missing data is listwise deletion; perhaps not what we want. Later on we can try full information maximum likelihood (FIML), which will generally result in estimates similar to what you would get with multiple impution, but with the added advantage that it's all done in one step.

```{r echo=T, results='hide'}
fit <- cfa(motivation_model, data=sms_clean, # use the 'clean' data
            std.lv=T # this tells lavaan to use a standardized scale for the latent variables.
)
```

Let's call the CFA output with the *knitr*-package.

```{r}
library(knitr)

options(knitr.kable.NA = '') # this will hide missing values in the kable table

parameterEstimates(fit, standardized=TRUE) %>% 
  filter(op == "=~") %>% 
  mutate(stars = ifelse(pvalue < .001, "***", ifelse(pvalue < .01, "**", ifelse(pvalue < .05, "*", "")))) %>%
  select('Latent Factor'=lhs, 
         Indicator=rhs, 
         B=est, 
         SE=se, Z=z, 
         Beta=std.all, 
         sig=stars) %>% 
  kable(digits = 3, format="pandoc", caption="Table 1. Latent Factor Loadings"
  )

```


So, as an example, for a 1-unit increase in the latent variable *amotivation* (i.e. 1-SD increase), the model predicts a 0.367 increase in W1_M1_5.

<br>

Let's also get the correlations between the factors.

```{r}
parameterEstimates(fit, standardized=TRUE) %>% 
  filter(op == "~~", 
         lhs %in% c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic"), 
         !is.na(pvalue)) %>% 
  mutate(stars = ifelse(pvalue < .001, "***", 
                        ifelse(pvalue < .01, "**", 
                               ifelse(pvalue < .05, "*", "")))) %>% 
  select('Factor 1'=lhs, 
         'Factor 2'=rhs, 
         Correlation=est, 
         sig=stars) %>% 
  kable(digits = 3, format="pandoc", caption="Table 2: Latent Factor Correlations")
```

<br>

Now extract the factor scores, put them into a dataframe, delete missings, and standardize the factor scores (again). Also, we make a descriptive table.

```{r}
fs <- lavPredict(fit, newdata = sms_clean, append.data = TRUE) # extract
fs <- as.data.frame(fs[, c(1:6, 31)]) # subset factor scores and identifier in df
clus <- fs %>%
  select(-id) %>%
  na.omit() %>% # listwise deletion
  mutate_all(list(scale)) # standardize

clus$id <- fs$id # add id again...

library(dplyr)
library(tidyr)
library(knitr)
library(kableExtra)

# describe

input <- clus %>% 
  select(-id) %>% 
  gather("Variable", "value") %>% 
  group_by(Variable) %>%
  summarise(Mean=mean(value, na.rm=TRUE), 
            SD=sd(value, na.rm=TRUE), 
            min=min(value, na.rm=TRUE), 
            max=max(value, na.rm=TRUE))

knitr::kable(input, digits=2, "html", caption="Table 3. Descriptives of standardized factor scores SMS W1") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover")) 
```

<br>

And check the distribution of our variables

```{r}
library(Hmisc)
hist(clus %>%
       select(-id))
```

The produced standardized scores somewhat approximate a Z-score metric (i.e. where values range from ca. -3 to +3). Note that *amotivation* is an exception to the rule: it is very much right-skewed and has high kurtosis.


<br>

----

# 3. LPA

Let's follow the same procedure for LPA, but now we include the standardized factor scores as input.

## Model fit {.tabset .tabset-fade} 

Starting off by exploring model fit again, by plotting it.

### BIC
```{r class.source = 'fold-hide'}
library(mclust)
BIC <- mclustBIC(clus %>%
                   select(-id)) # exclude id
plot(BIC)
```

### ICL
```{r class.source = 'fold-hide'}
library(mclust)
ICL <- mclustICL(clus %>%
               select(-id))
plot(ICL)
```

### BLRT
```{r eval = FALSE}
library(mclust)
mclustBootstrapLRT(clus %>%
               select(-id), modelName = "VEV")
```

## {-}

And use the *summary*-function to show the top-three models based on BIC and ICL.

## {.tabset .tabset-fade}

### BIC
```{r class.source = 'fold-hide'}
summary(BIC)
```

### ICL
```{r class.source = 'fold-hide'}
summary(ICL)
```

## {-}

<br>

----

# 4. Visualizing LPA

## {.tabset .tabset-fade}

Statistically, the best model is the VEV, 8. We do not plot this, but we estimate a sequence of models, incrementally increasing the number of profiles, until they do not provide theoretical additions to the model. Plotting the models will make it easier to, intuitively, assess which model is suitable. We start with 2 profiles. 

### 2 profiles

```{r class.source = 'fold-hide'}
m2 <- Mclust(clus %>%
               select(-id),
             modelNames = "VEV", G = 2, x = BIC)
summary(m2) 
means <- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %>% 
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>% 
  mutate(Mean = round(Mean, 2))
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean latent SMS factor scores") +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")
```

### 3 profiles

```{r class.source = 'fold-hide'}
m3 <- Mclust(clus %>%
               select(-id),
             modelNames = "VEV", G = 3, x = BIC)
summary(m3) 
means <- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %>% 
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>% 
  mutate(Mean = round(Mean, 2))
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean latent SMS factor scores") +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")
```

### 4 profiles

```{r class.source = 'fold-hide'}
m4 <- Mclust(clus %>%
               select(-id),
             modelNames = "VEV", G = 4, x = BIC)
summary(m4) 
means <- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %>% 
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>% 
  mutate(Mean = round(Mean, 2))
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean latent SMS factor scores") +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")
```

### 5 profiles

```{r class.source = 'fold-hide'}
m5 <- Mclust(clus %>%
               select(-id),
             modelNames = "VEV", G = 5, x = BIC)
summary(m5) 
means <- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %>% 
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>% 
  mutate(Mean = round(Mean, 2))
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean latent SMS factor scores") +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")
```

## {-}

<br>

----

The output shows less theoretically interpretable motivational profiles compared to the previous LPA...
As a last approach (see next page), we will use weighted sum scores (as described on page 3 of [this article](https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1226&context=pare
)).
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("lpa2.rmd");
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
