<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Latent Profile Transition Analysis</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
#rmd-source-code {
  display: none;
}
</style>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Motivation</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="lpa1.html">Exploring LPA</a>
</li>
<li>
  <a href="lpta.html">LPTA</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
<li role="separator" class="divider"></li>
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Latent Profile Transition Analysis</h1>

</div>


<p><br></p>
<p><em>Last edited: January 25, 2021</em></p>
<p><br></p>
<p>In the following, we will explore motivational profiles in the context of longitudinal data, using SDT as a theoretical framework. We will explore movement between motivational profiles over time.</p>
<p><br></p>
<div id="approach" class="section level2">
<h2>Approach</h2>
<p>EDIT! First, we obtain weighted factor-scores for each SMS-subscale with CFA using MLE, as input for our subsequent LPA. Then, we use a three-step approach (see <a href="https://www.tandfonline.com/doi/pdf/10.1080/10705511.2014.915181">this article</a>; or the paper by <a href="https://www.sciencedirect.com/science/article/pii/S1469029219303851">Emm-Collison and colleagues</a> who used the same procedure).</p>
<hr />
</div>
<div id="preliminary-steps" class="section level1">
<h1>Preliminary steps</h1>
<div id="data" class="section level2">
<h2>1. Data</h2>
<p>Let’s get our ‘cleaned’ SMS-data, for each wave. We identify “string responding”, and cap it to a maximum of 10 and we exclude multivariate outliers with Mahalanobis Distance, using alpha .001 as a cutoff. Next, we make a long file of the SMS data.</p>
<pre class="r fold-hide"><code>library(sjlabelled)
library(dplyr)
library(tidyverse)
library(careless)
library(psych)

load(&quot;data_abs_public_v2.RData&quot;) # load data
data_abs_public &lt;- unlabel(data_abs_public, verbose=F) # unlabel

data_abs_public$id &lt;- 1:nrow(data_abs_public) # add identifier for subsequent LPTA

# subset sms data in each wave
sms_w1 &lt;- data_abs_public %&gt;% select(W1_M1_1, W1_M1_2, W1_M1_3, W1_M1_4, W1_M1_5, W1_M1_6, W1_M1_7, W1_M1_8, W1_M2_1, W1_M2_2, W1_M2_3, W1_M2_4, W1_M2_5, W1_M2_6, W1_M2_7, W1_M2_8, W1_M3_1, W1_M3_2, W1_M3_3, W1_M3_4, W1_M3_5, W1_M3_6, W1_M3_7, W1_M3_8, id)

sms_w2 &lt;- data_abs_public %&gt;% select(W2_M1_1, W2_M1_2, W2_M1_3, W2_M1_4, W2_M1_5, W2_M1_6, W2_M1_7, W2_M1_8, W2_M2_1, W2_M2_2, W2_M2_3, W2_M2_4, W2_M2_5, W2_M2_6, W2_M2_7, W2_M2_8, W2_M3_1, W2_M3_2, W2_M3_3, W2_M3_4, W2_M3_5, W2_M3_6, W2_M3_7, W2_M3_8, id) 

sms_w3 &lt;- data_abs_public %&gt;% select(W3_M1_1, W3_M1_2, W3_M1_3, W3_M1_4, W3_M1_5, W3_M1_6, W3_M1_7, W3_M1_8, W3_M2_1, W3_M2_2, W3_M2_3, W3_M2_4, W3_M2_5, W3_M2_6, W3_M2_7, W3_M2_8, W3_M3_1, W3_M3_2, W3_M3_3, W3_M3_4, W3_M3_5, W3_M3_6, W3_M3_7, W3_M3_8, id)

# make a &#39;string&#39; variable 
sms_w1 &lt;- sms_w1 %&gt;%
  mutate(string_w1 = longstring(.)) %&gt;%
  mutate(md_w1 = outlier(., plot = FALSE))

sms_w2 &lt;- sms_w2 %&gt;%
  mutate(string_w2 = longstring(.)) %&gt;%
  mutate(md_w2 = outlier(., plot = FALSE)) 

sms_w3 &lt;- sms_w3 %&gt;%
  mutate(string_w3 = longstring(.)) %&gt;%
  mutate(md_w3 = outlier(., plot = FALSE)) 

# cap string responding and use MD
cutoff_w1 &lt;- (qchisq(p = 1 - .001, df = (ncol(sms_w1) - 1)))
sms_w1 &lt;- sms_w1 %&gt;%
  filter(string_w1 &lt;= 10,
         md_w1 &lt; cutoff_w1) %&gt;%
  select(-string_w1, -md_w1)

  cutoff_w2 &lt;- (qchisq(p = 1 - .001, df = (ncol(sms_w2) - 1)))
sms_w2 &lt;- sms_w2 %&gt;%
  filter(string_w2 &lt;= 10,
         md_w2 &lt; cutoff_w2) %&gt;%
  select(-string_w2, -md_w2)

cutoff_w3 &lt;- (qchisq(p = 1 - .001, df = (ncol(sms_w3) - 1)))
sms_w3 &lt;- sms_w3 %&gt;%
  filter(string_w3 &lt;= 10,
         md_w3 &lt; cutoff_w3) %&gt;%
  select(-string_w3, -md_w3)

# first, make a wide format
sms_wide &lt;- merge(sms_w1, sms_w2, by = &quot;id&quot;) # first wave 1 and 2
sms_wide &lt;- merge(sms_wide, sms_w3, by = &quot;id&quot;) # add wave 3

# then transform into long shape
library(reshape2)
sms_long &lt;- reshape(sms_wide,
                    direction = &quot;long&quot;,
                    varying = c(list(names(sms_wide)[c(2, 26, 50)]), list(names(sms_wide)[c(3, 27, 51)]), list(names(sms_wide)[c(4, 28, 52)]), list(names(sms_wide)[c(5, 29, 53)]), list(names(sms_wide)[c(6, 30, 54)]), list(names(sms_wide)[c(7, 31, 55)]), list(names(sms_wide)[c(8, 32, 56)]), list(names(sms_wide)[c(9, 33, 57)]), list(names(sms_wide)[c(10, 34, 58)]),list(names(sms_wide)[c(11, 35, 59)]), list(names(sms_wide)[c(12, 36, 60)]), list(names(sms_wide)[c(13, 37, 61)]), list(names(sms_wide)[c(14, 38, 62)]),list(names(sms_wide)[c(15, 39, 63)]), list(names(sms_wide)[c(16, 40, 64)]), list(names(sms_wide)[c(17, 41, 65)]), list(names(sms_wide)[c(18, 42, 66)]), list(names(sms_wide)[c(19, 43, 67)]), list(names(sms_wide)[c(20, 44, 68)]),  list(names(sms_wide)[c(21, 45, 69)]),  list(names(sms_wide)[c(22, 46, 70)]), list(names(sms_wide)[c(23, 47, 71)]), list(names(sms_wide)[c(24, 48, 72)]), list(names(sms_wide)[c(25, 49, 73)])),
                    v.names = c(&quot;M1_1&quot;, &quot;M1_2&quot;, &quot;M1_3&quot;,&quot;M1_4&quot;, &quot;M1_5&quot;, &quot;M1_6&quot;, &quot;M1_7&quot;, &quot;M1_8&quot;, &quot;M2_1&quot;, &quot;M2_2&quot;, &quot;M2_3&quot;,&quot;M2_4&quot;, &quot;M2_5&quot;, &quot;M2_6&quot;, &quot;M2_7&quot;, &quot;M2_8&quot;, &quot;M3_1&quot;, &quot;M3_2&quot;, &quot;M3_3&quot;,&quot;M3_4&quot;, &quot;M3_5&quot;, &quot;M3_6&quot;, &quot;M3_7&quot;, &quot;M3_8&quot;),
                    idvar = &quot;id&quot;,
                    timevar = &quot;Timepoint&quot;,
                    times = 1:3)
# Reorder
sms_long  &lt;- sms_long [(order(sms_long$id)), ]
# fix(sms_long) to check data structure

sms_long_nm &lt;- sms_long %&gt;%
  na.omit() # listwise deletion</code></pre>
<p><br></p>
<hr />
</div>
<div id="cfa" class="section level2">
<h2>2. CFA</h2>
<p>First, confirmatory factor analysis using maximum likelihood estimation was conducted to obtain weighted factor scores for each SMS subscale. We first conduct CFA on the stacked data (hence assuming observations to be independent of each other). We will assess model fit using multiple indices. Afterwards, we will assess longitudinal invariance of the measurement model via a series of increasingly constrained models, indicating invariance by a change of CFI of ≤0.01.</p>
<div id="lavaan" class="section level3">
<h3>Lavaan</h3>
<p>Tell Lavaan the confirmatory structure.</p>
<pre class="r"><code>library(lavaan)

motivation_model &lt;- &quot;
amotivation =~ M1_5 + M2_4 + M3_1 + M3_6
external    =~ M1_4 + M2_3 + M3_3 + M3_8
introjected =~ M1_7 + M2_2 + M2_8 + M3_7
identified  =~ M1_3 + M1_8 + M2_7 + M3_4
integrated  =~ M1_2 + M2_1 + M2_5 + M3_5
intrinsic   =~ M1_1 + M1_6 + M2_6 + M3_2
&quot;</code></pre>
<p>Now let’s inspect the model. We will get the fit of the model, the (standardized) factor loadings, item averages (intercepts), error variances, and R-square scores. We will also make a table of the various fit indices.</p>
<pre class="r"><code># examine overall fit
overall.fit &lt;- cfa(model = motivation_model, data = sms_long_nm,
           meanstructure = TRUE,  # gives us the means
           std.lv = TRUE) 

#summary(overall.fit, standardized = TRUE, rsquare = TRUE, fit.measure = TRUE) #for inspection

# make table of fit indices
table_fit &lt;- matrix(NA, nrow = 8, ncol = 6)
colnames(table_fit) &lt;- c(&quot;Model&quot;, &quot;X2&quot;, &quot;df&quot;, &quot;CFI&quot;, &quot;RMSEA&quot;, &quot;SRMR&quot;)
table_fit[1, ] &lt;- c(&quot;Overall Model&quot;, round(fitmeasures(overall.fit, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))</code></pre>
<p><br></p>
<p>To check the confirmatory structure of our model, we will also create a picture of the standardized solution (quick and dirty; it can be edited…). The triangles depict the (standardized) intercepts, the arrows depic the variance (i.e. the loops) and (standardized) factor loadings.</p>
<pre class="r"><code>library(semPlot)
semPaths(overall.fit, whatLabels = &quot;std&quot;, layout = &quot;tree&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
<div id="longitudinal-invariance" class="section level3 tabset tabset-fade">
<h3>Longitudinal invariance</h3>
<p>Since we are dealing with panel data, and we want to explore movement over time in motivations, we should investigate to what extent our CFA solution is invariant over time (because we don’t want to compare apples with oranges). We will compare the SMS data of W1-W3 and compare them in CFA for configural, metric, scalar, and strict residual invariance (see e.g., <a href="https://www.tandfonline.com/doi/pdf/10.1207/S15328007SEM0902_5?casa_token=scyVPZRkncQAAAAA:PDDawXxC0BMvLu-kjcvtaFcHseZnO3rkwX4nJGtd8OrK-nuTq4B1Mk571ajpjaq3JQhasVHnyXtofdg">Cheung &amp; Rensvold 2002</a>).</p>
<p><br></p>
<div id="configural-invariance" class="section level4">
<h4>Configural invariance</h4>
<p>Starting with a test for configural invariance - is the ‘picture’/structure of the model the same for all waves. We make a multi-group model by using the group-argument.</p>
<pre class="r"><code>con.fit &lt;- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
               group = &quot;Timepoint&quot;)
table_fit[2, ] &lt;- c(&quot;Configural Model&quot;, round(fitmeasures(con.fit, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3)) #add results to the table

library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

input &lt;- table_fit[1:2, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
2786.122
</td>
<td style="text-align:left;">
711
</td>
<td style="text-align:left;">
0.867
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
</tbody>
</table>
<p>This is the model against which we will test the next model. So, we will conduct a sequential testing analysis.</p>
<p><br></p>
</div>
<div id="metric-invariance" class="section level4">
<h4>Metric invariance</h4>
<p>Next, we will assess metric invariance, by constraining the factor loadings to be equal across the waves. In the configural model, factor loadings were “freely” estimated in both waves; now, only 1 loading gets estimated for both groups. Let’s see what happens to the model.</p>
<pre class="r"><code>met.fit &lt;- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
               group = &quot;Timepoint&quot;, group.equal = c(&quot;loadings&quot;))
table_fit[3, ] &lt;- c(&quot;Metric Model&quot;, round(fitmeasures(met.fit, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:3, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
2786.122
</td>
<td style="text-align:left;">
711
</td>
<td style="text-align:left;">
0.867
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
2917.742
</td>
<td style="text-align:left;">
747
</td>
<td style="text-align:left;">
0.861
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
</tbody>
</table>
<p>The metric model seems to be invariant in comparison to the configural model: the CFI difference is smaller than .01, hence assuming invariance (same holds for RMSEA/SRMR). Conclusion: the metric model holds: the loadings are equal (or close enough).</p>
<p><br></p>
</div>
<div id="scalar-invariance" class="section level4">
<h4>Scalar invariance</h4>
<p>We have constrained our model to contain the same structure, the same loadings; now let’s test for scalar invariance, to see if the intercepts are the same across waves.</p>
<pre class="r"><code>sca.fit &lt;- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
               group = &quot;Timepoint&quot;, group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;))
table_fit[4, ] &lt;- c(&quot;Scalar Model&quot;, round(fitmeasures(sca.fit, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:4, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
2786.122
</td>
<td style="text-align:left;">
711
</td>
<td style="text-align:left;">
0.867
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
2917.742
</td>
<td style="text-align:left;">
747
</td>
<td style="text-align:left;">
0.861
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
3020.438
</td>
<td style="text-align:left;">
783
</td>
<td style="text-align:left;">
0.857
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
</tbody>
</table>
<p>The intercepts are equal on the scale between the waves.</p>
<p><br></p>
</div>
<div id="strict-residual-invariance" class="section level4">
<h4>Strict (residual) invariance</h4>
<p>Last, we constrain the model to the strict model, to check for strict residual invariance. It will inform whether the variance around items is the same across time.</p>
<pre class="r"><code>str.fit &lt;- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
               group = &quot;Timepoint&quot;, group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;))
table_fit[5, ] &lt;- c(&quot;Strict Model&quot;, round(fitmeasures(str.fit, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))


input &lt;- table_fit[1:5, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
2786.122
</td>
<td style="text-align:left;">
711
</td>
<td style="text-align:left;">
0.867
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
2917.742
</td>
<td style="text-align:left;">
747
</td>
<td style="text-align:left;">
0.861
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
3020.438
</td>
<td style="text-align:left;">
783
</td>
<td style="text-align:left;">
0.857
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
3360.192
</td>
<td style="text-align:left;">
831
</td>
<td style="text-align:left;">
0.838
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.064
</td>
</tr>
</tbody>
</table>
<p>From here it goes downwards… CFI dropped more than 0.01, suggesting that the residuals vary between the waves.</p>
<p><br></p>
</div>
<div id="partial-invariance" class="section level4">
<h4>Partial invariance</h4>
<p>We could estimate partial invariance, to investigate where the problem is and subsequently update the model to fix it. We are going to do so by freeing the variances of item residuals, one at a time, to figure out which equality constaint(s) is/are causing the problem. We will use the following loop for this.</p>
<pre class="r"><code># write out partial codes
partial_syntax &lt;- paste(colnames(sms_long_nm)[3:26], #all sms columns
                        &quot;~~&quot;, #residuals
                        colnames(sms_long_nm)[3:26]) #all columns again

CFI_list &lt;- 1:length(partial_syntax)
names(CFI_list) &lt;- partial_syntax 

for (i in 1:length(partial_syntax)){
  
  temp &lt;- cfa(model = motivation_model,
              data = sms_long_nm,
              meanstructure = TRUE,
              group = &quot;Timepoint&quot;,
              group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;),
              group.partial = partial_syntax[i])
  
  CFI_list[i] &lt;- fitmeasures(temp, &quot;cfi&quot;)
}


# now figure out which parameters to &quot;free&quot;
options(scipen = 999)
sort(CFI_list - fitmeasures(str.fit, &quot;cfi&quot;), decreasing = TRUE)</code></pre>
<pre><code>##   M1_5 ~~ M1_5   M1_7 ~~ M1_7   M1_6 ~~ M1_6   M3_5 ~~ M3_5   M2_4 ~~ M2_4 
##  0.00335333572  0.00286285010  0.00227724483  0.00192212952  0.00125666372 
##   M2_1 ~~ M2_1   M1_8 ~~ M1_8   M2_8 ~~ M2_8   M1_2 ~~ M1_2   M3_1 ~~ M3_1 
##  0.00111389577  0.00082903852  0.00078705534  0.00076979445  0.00067184456 
##   M1_1 ~~ M1_1   M3_7 ~~ M3_7   M3_4 ~~ M3_4   M2_6 ~~ M2_6   M3_8 ~~ M3_8 
##  0.00054403285  0.00050934376  0.00050661463  0.00048206031  0.00041072029 
##   M3_2 ~~ M3_2   M3_6 ~~ M3_6   M3_3 ~~ M3_3   M1_3 ~~ M1_3   M2_3 ~~ M2_3 
##  0.00033769117  0.00017074717  0.00016690930  0.00015376509  0.00009265141 
##   M2_2 ~~ M2_2   M2_7 ~~ M2_7   M1_4 ~~ M1_4   M2_5 ~~ M2_5 
##  0.00007309850  0.00006553126 -0.00001060543 -0.00006125562</code></pre>
<p>Let’s free up those parameters, starting with the one that increases CFI to the greatest extent.</p>
<pre class="r"><code>par.fit &lt;- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
               group = &quot;Timepoint&quot;, group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;),
               group.partial = &quot;M1_5~~M1_5&quot;)
table_fit[6, ] &lt;- c(&quot;Strict Model + M1_5&quot;, round(fitmeasures(par.fit, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:6, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
2786.122
</td>
<td style="text-align:left;">
711
</td>
<td style="text-align:left;">
0.867
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
2917.742
</td>
<td style="text-align:left;">
747
</td>
<td style="text-align:left;">
0.861
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
3020.438
</td>
<td style="text-align:left;">
783
</td>
<td style="text-align:left;">
0.857
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
3360.192
</td>
<td style="text-align:left;">
831
</td>
<td style="text-align:left;">
0.838
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.064
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model + M1_5
</td>
<td style="text-align:left;">
3305.736
</td>
<td style="text-align:left;">
829
</td>
<td style="text-align:left;">
0.842
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.063
</td>
</tr>
</tbody>
</table>
<p>CFI improved, but the difference in CFI with the baseline scalar model is still greater than .01. Thus, we still need to free (at least) one more, to achieve “partial” invariance.</p>
<pre class="r"><code>par.fit2 &lt;- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
                group = &quot;Timepoint&quot;, group.partial = c(&quot;M1_5~~M1_5&quot;, &quot;M1_7~~M1_7&quot;),
                group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;))
table_fit[7, ] &lt;- c(&quot;Strict Model + M1_5 + M1_7&quot;, round(fitmeasures(par.fit2, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:7, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
2786.122
</td>
<td style="text-align:left;">
711
</td>
<td style="text-align:left;">
0.867
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
2917.742
</td>
<td style="text-align:left;">
747
</td>
<td style="text-align:left;">
0.861
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
3020.438
</td>
<td style="text-align:left;">
783
</td>
<td style="text-align:left;">
0.857
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
3360.192
</td>
<td style="text-align:left;">
831
</td>
<td style="text-align:left;">
0.838
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.064
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model + M1_5
</td>
<td style="text-align:left;">
3305.736
</td>
<td style="text-align:left;">
829
</td>
<td style="text-align:left;">
0.842
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.063
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model + M1_5 + M1_7
</td>
<td style="text-align:left;">
3258.948
</td>
<td style="text-align:left;">
827
</td>
<td style="text-align:left;">
0.845
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.063
</td>
</tr>
</tbody>
</table>
<p>Ditto…</p>
<pre class="r"><code>par.fit3 &lt;- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
                group = &quot;Timepoint&quot;, group.partial = c(&quot;M1_5~~M1_5&quot;, &quot;M1_7~~M1_7&quot;, &quot;M1_6~~M1_6&quot;),
                group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;))
table_fit[8, ] &lt;- c(&quot;Strict Model + M1_5 + M1_7 + M1_6&quot;, round(fitmeasures(par.fit3, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:8, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
2786.122
</td>
<td style="text-align:left;">
711
</td>
<td style="text-align:left;">
0.867
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
2917.742
</td>
<td style="text-align:left;">
747
</td>
<td style="text-align:left;">
0.861
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
3020.438
</td>
<td style="text-align:left;">
783
</td>
<td style="text-align:left;">
0.857
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
3360.192
</td>
<td style="text-align:left;">
831
</td>
<td style="text-align:left;">
0.838
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.064
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model + M1_5
</td>
<td style="text-align:left;">
3305.736
</td>
<td style="text-align:left;">
829
</td>
<td style="text-align:left;">
0.842
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.063
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model + M1_5 + M1_7
</td>
<td style="text-align:left;">
3258.948
</td>
<td style="text-align:left;">
827
</td>
<td style="text-align:left;">
0.845
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.063
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model + M1_5 + M1_7 + M1_6
</td>
<td style="text-align:left;">
3221.304
</td>
<td style="text-align:left;">
825
</td>
<td style="text-align:left;">
0.847
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.063
</td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<p>We can conclude that the SMS is mostly invariant - the structure, factor loadings, intercepts, and most of the error variances were equal across time.</p>
<p><br></p>
</div>
<div id="weighted-factor-scores" class="section level3">
<h3>Weighted factor-scores</h3>
<p>Now we use the (partially) invariant measurement model to generate (weighted) factor scores as input variables for the subsequent LPA. Weighted factor scores are computed by multiplying the factor loading of each item to the scaled score for each item before summing (see <a href="https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1226&amp;context=pare">DiStefano et al. (2009)</a>).</p>
<p>We extract the factor loadings, and calculate the weighted sum scores.</p>
<pre class="r"><code>loading &lt;- parameterEstimates(par.fit3)$est[1:24] # extract factor loadings

# calculate weighted (sum) factor-scores
sms_long_nm$amotivation &lt;- rowMeans(cbind((sms_long_nm$M1_5*loading[1]), (sms_long_nm$M2_4*loading[2]), (sms_long_nm$M3_1*loading[3]), (sms_long_nm$M3_6*loading[4])))

sms_long_nm$external &lt;- rowMeans(cbind((sms_long_nm$M1_4*loading[5]), (sms_long_nm$M2_3*loading[6]), (sms_long_nm$M3_3*loading[7]),   (sms_long_nm$M3_8*loading[8])))

sms_long_nm$introjected &lt;- rowMeans(cbind((sms_long_nm$M1_7*loading[9]), (sms_long_nm$M2_2*loading[10]), (sms_long_nm$M2_8*loading[11]), (sms_long_nm$M3_7*loading[12])))

sms_long_nm$identified &lt;- rowMeans(cbind((sms_long_nm$M1_3*loading[13]), (sms_long_nm$M1_8*loading[14]), (sms_long_nm$M2_7*loading[15]), (sms_long_nm$M3_4*loading[16])))

sms_long_nm$integrated &lt;- rowMeans(cbind((sms_long_nm$M1_2*loading[17]), (sms_long_nm$M2_1*loading[18]), (sms_long_nm$M2_5*loading[19]), (sms_long_nm$M3_5*loading[20])))

sms_long_nm$intrinsic &lt;- rowMeans(cbind((sms_long_nm$M1_1*loading[21]), (sms_long_nm$M1_6*loading[22]), (sms_long_nm$M2_6*loading[23]), (sms_long_nm$M3_2*loading[24])))</code></pre>
<p><br></p>
<hr />
</div>
</div>
<div id="descriptives" class="section level2">
<h2>3. Descriptives</h2>
<p>Let’s describe our weighted factor scores over time.</p>
<pre class="r"><code>library(crosstable)

input &lt;- sms_long_nm %&gt;% #get factor scores and timepoint as grouping variable
  select(27:32, 2)

# integrate wave number and n in header
n &lt;- as.vector(table(input$Timepoint))
x &lt;- paste(levels(as.factor(input$Timepoint)), &quot; (N=&quot;, n, &quot;)&quot;, sep=&quot;&quot;)
input$Timepoint &lt;- as.factor(input$Timepoint)
levels(input$Timepoint) &lt;- x

#flextable
crosstable(input, by=Timepoint,
           funs=c(&quot;Mean&quot; = mean, &quot;Std. dev.&quot; = sd, &quot;Min&quot; = min, &quot;Max&quot; = max), funs_arg=list(digits=3)) %&gt;%
  as_flextable(by_header = &quot;Wave&quot;)</code></pre>
<template id="b90a1c91-035a-4adb-98dc-b7514b9984c3"><style>
.tabwid table{
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-spacing: 0;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
</style><div class="tabwid"><style>.cl-71d5af4e{border-collapse:collapse;}.cl-71c898d6{font-family:'Arial';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-71c898d7{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-71c8bfd2{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-71c8bfd3{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-71c934b2{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c934b3{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c934b4{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c934b5{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c934b6{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c934b7{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c934b8{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c934b9{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c934ba{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c934bb{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c934bc{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c95ba4{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c95ba5{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c95ba6{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c95ba7{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c95ba8{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c95ba9{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c95baa{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c95bab{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c95bac{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c95bad{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c95bae{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c98296{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c98297{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c98298{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c98299{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9829a{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9829b{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9829c{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9829d{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9829e{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9829f{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c982a0{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9a988{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9a989{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9a98a{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9a98b{width:69.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9a98c{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-71c9a98d{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}caption {color: #777;margin-top: 10px;margin-bottom: 10px;text-align: center;}</style><table class='cl-71d5af4e'><thead><tr style="overflow-wrap:break-word;"><td  rowspan="2"class="cl-71c9a98a"><p class="cl-71c8bfd2"><span class="cl-71c898d6">label</span></p></td><td  rowspan="2"class="cl-71c9a988"><p class="cl-71c8bfd2"><span class="cl-71c898d6">variable</span></p></td><td  colspan="3"class="cl-71c9a989"><p class="cl-71c8bfd2"><span class="cl-71c898d6">Wave</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c9a98b"><p class="cl-71c8bfd3"><span class="cl-71c898d6">1 (N=621)</span></p></td><td class="cl-71c9a98b"><p class="cl-71c8bfd3"><span class="cl-71c898d6">2 (N=486)</span></p></td><td class="cl-71c9a98b"><p class="cl-71c8bfd3"><span class="cl-71c898d6">3 (N=506)</span></p></td></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-71c934b3"><p class="cl-71c8bfd3"><span class="cl-71c898d7">amotivation</span></p></td><td class="cl-71c934b4"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Mean</span></p></td><td class="cl-71c934b2"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.606</span></p></td><td class="cl-71c934b2"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.677</span></p></td><td class="cl-71c934b2"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.753</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934b6"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Std. dev.</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">0.665</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">0.746</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">0.818</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934b8"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Min</span></p></td><td class="cl-71c934ba"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.275</span></p></td><td class="cl-71c934ba"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.275</span></p></td><td class="cl-71c934ba"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.275</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934bc"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Max</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">5.909</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">5.415</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">5.672</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-71c9829e"><p class="cl-71c8bfd3"><span class="cl-71c898d7">external</span></p></td><td class="cl-71c9829d"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Mean</span></p></td><td class="cl-71c9829c"><p class="cl-71c8bfd3"><span class="cl-71c898d7">2.059</span></p></td><td class="cl-71c9829c"><p class="cl-71c8bfd3"><span class="cl-71c898d7">2.292</span></p></td><td class="cl-71c9829c"><p class="cl-71c8bfd3"><span class="cl-71c898d7">2.329</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934b6"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Std. dev.</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.030</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.147</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.167</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934b8"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Min</span></p></td><td class="cl-71c934ba"><p class="cl-71c8bfd3"><span class="cl-71c898d7">0.982</span></p></td><td class="cl-71c934ba"><p class="cl-71c8bfd3"><span class="cl-71c898d7">0.982</span></p></td><td class="cl-71c934ba"><p class="cl-71c8bfd3"><span class="cl-71c898d7">0.982</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c982a0"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Max</span></p></td><td class="cl-71c9829f"><p class="cl-71c8bfd3"><span class="cl-71c898d7">5.649</span></p></td><td class="cl-71c9829f"><p class="cl-71c8bfd3"><span class="cl-71c898d7">5.892</span></p></td><td class="cl-71c9829f"><p class="cl-71c8bfd3"><span class="cl-71c898d7">6.135</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-71c95bab"><p class="cl-71c8bfd3"><span class="cl-71c898d7">introjected</span></p></td><td class="cl-71c95baa"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Mean</span></p></td><td class="cl-71c95ba9"><p class="cl-71c8bfd3"><span class="cl-71c898d7">6.068</span></p></td><td class="cl-71c95ba9"><p class="cl-71c8bfd3"><span class="cl-71c898d7">6.286</span></p></td><td class="cl-71c95ba9"><p class="cl-71c8bfd3"><span class="cl-71c898d7">6.588</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934b6"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Std. dev.</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.681</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.621</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.457</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934b8"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Min</span></p></td><td class="cl-71c934ba"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.510</span></p></td><td class="cl-71c934ba"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.510</span></p></td><td class="cl-71c934ba"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.510</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934bc"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Max</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">8.822</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">8.822</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">8.822</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-71c95ba7"><p class="cl-71c8bfd3"><span class="cl-71c898d7">identified</span></p></td><td class="cl-71c95ba5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Mean</span></p></td><td class="cl-71c95ba6"><p class="cl-71c8bfd3"><span class="cl-71c898d7">3.056</span></p></td><td class="cl-71c95ba6"><p class="cl-71c8bfd3"><span class="cl-71c898d7">3.346</span></p></td><td class="cl-71c95ba6"><p class="cl-71c8bfd3"><span class="cl-71c898d7">3.345</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934b6"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Std. dev.</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.129</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.188</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.105</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934b4"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Min</span></p></td><td class="cl-71c934b2"><p class="cl-71c8bfd3"><span class="cl-71c898d7">0.939</span></p></td><td class="cl-71c934b2"><p class="cl-71c8bfd3"><span class="cl-71c898d7">0.939</span></p></td><td class="cl-71c934b2"><p class="cl-71c8bfd3"><span class="cl-71c898d7">0.939</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934bc"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Max</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">6.571</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">6.571</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">6.571</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-71c95bab"><p class="cl-71c8bfd3"><span class="cl-71c898d7">integrated</span></p></td><td class="cl-71c95baa"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Mean</span></p></td><td class="cl-71c95ba9"><p class="cl-71c8bfd3"><span class="cl-71c898d7">5.164</span></p></td><td class="cl-71c95ba9"><p class="cl-71c8bfd3"><span class="cl-71c898d7">5.615</span></p></td><td class="cl-71c95ba9"><p class="cl-71c8bfd3"><span class="cl-71c898d7">5.739</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934b6"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Std. dev.</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.702</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.704</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.619</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934b4"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Min</span></p></td><td class="cl-71c934b2"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.246</span></p></td><td class="cl-71c934b2"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.593</span></p></td><td class="cl-71c934b2"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.246</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934bc"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Max</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">8.724</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">8.724</span></p></td><td class="cl-71c934bb"><p class="cl-71c8bfd3"><span class="cl-71c898d7">8.724</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-71c95bae"><p class="cl-71c8bfd3"><span class="cl-71c898d7">intrinsic</span></p></td><td class="cl-71c95bad"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Mean</span></p></td><td class="cl-71c95bac"><p class="cl-71c8bfd3"><span class="cl-71c898d7">4.641</span></p></td><td class="cl-71c95bac"><p class="cl-71c8bfd3"><span class="cl-71c898d7">5.044</span></p></td><td class="cl-71c95bac"><p class="cl-71c8bfd3"><span class="cl-71c898d7">5.085</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c934b6"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Std. dev.</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.769</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.777</span></p></td><td class="cl-71c934b5"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.685</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c98297"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Min</span></p></td><td class="cl-71c98296"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.277</span></p></td><td class="cl-71c98296"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.277</span></p></td><td class="cl-71c98296"><p class="cl-71c8bfd3"><span class="cl-71c898d7">1.277</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-71c9829a"><p class="cl-71c8bfd3"><span class="cl-71c898d7">Max</span></p></td><td class="cl-71c98299"><p class="cl-71c8bfd3"><span class="cl-71c898d7">8.940</span></p></td><td class="cl-71c98299"><p class="cl-71c8bfd3"><span class="cl-71c898d7">8.940</span></p></td><td class="cl-71c98299"><p class="cl-71c8bfd3"><span class="cl-71c898d7">8.613</span></p></td></tr></tbody></table></div></template>
<div id="65b7b0f6-fa09-4532-9d27-5ef813145626"></div>
<script>
var dest = document.getElementById("65b7b0f6-fa09-4532-9d27-5ef813145626");
var template = document.getElementById("b90a1c91-035a-4adb-98dc-b7514b9984c3");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
</script>

<p>At face value, respondents seem to be pretty high in all types of motivation (e.g., compared with the sample of <a href="https://www.sciencedirect.com/science/article/pii/S1469029219303851">Emm-Collison and colleagues</a> - though these were sum scores).</p>
<p><br></p>
<hr />
</div>
</div>
<div id="lpa" class="section level1">
<h1>LPA</h1>
<div id="step-1" class="section level2">
<h2>Step 1</h2>
<p><br></p>
<div id="model-based-clustering" class="section level3 tabset tabset-fade">
<h3>Model-based clustering</h3>
<p>As a first step for the LPA, we carefully select a measurement model that accurately captures the construct of motivational profile, in each wave.</p>
<p><br></p>
<div id="wave-1" class="section level4">
<h4>Wave 1</h4>
<p>We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).</p>
<pre class="r"><code>sms_w1 &lt;- sms_long_nm[sms_long_nm$Timepoint==1, ] %&gt;%
  select(-Timepoint, -id) %&gt;% # subset W1
  select(25:30) %&gt;% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
sms_w1$id &lt;- sms_long_nm[sms_long_nm$Timepoint==1, ]$id #add id again</code></pre>
<p>We then compute the model-based clustering, and ask for a summary.</p>
<pre class="r"><code>library(mclust)
mc &lt;- Mclust(sms_w1 %&gt;%
               select(-id))
summary(mc)                 </code></pre>
<pre><code>## ---------------------------------------------------- 
## Gaussian finite mixture model fitted by EM algorithm 
## ---------------------------------------------------- 
## 
## Mclust VEV (ellipsoidal, equal shape) model with 7 components: 
## 
##  log-likelihood   n  df       BIC       ICL
##       -3649.856 621 165 -8360.882 -8489.281
## 
## Clustering table:
##   1   2   3   4   5   6   7 
## 154  71  52  76  92 125  51</code></pre>
<p>For this wave, Mclust selected a model with 7 profiles; the optimal selected model is VEV, i.e., the profiles are ellipsoidal with equal shape (see <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/">this article</a>).</p>
<p>Now we will access to the results and visualize the model. To visualize, we will use a new package (<em>factoextra</em>), to create nicer plots based on ggplot2.</p>
<pre class="r"><code>library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, &quot;BIC&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
</div>
<div id="wave-2" class="section level4">
<h4>Wave 2</h4>
<p>We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).</p>
<pre class="r"><code>sms_w2 &lt;- sms_long_nm[sms_long_nm$Timepoint==2, ] %&gt;%
  select(-Timepoint, -id) %&gt;% # subset W1
  select(25:30) %&gt;% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
sms_w2$id &lt;- sms_long_nm[sms_long_nm$Timepoint==2, ]$id #add id again</code></pre>
<p>We then compute the model-based clustering, and ask for a summary.</p>
<pre class="r"><code>library(mclust)
mc &lt;- Mclust(sms_w2 %&gt;%
               select(-id))
summary(mc)                 </code></pre>
<pre><code>## ---------------------------------------------------- 
## Gaussian finite mixture model fitted by EM algorithm 
## ---------------------------------------------------- 
## 
## Mclust EEV (ellipsoidal, equal volume and shape) model with 9 components: 
## 
##  log-likelihood   n  df       BIC       ICL
##       -2665.856 486 203 -6587.513 -6723.082
## 
## Clustering table:
##   1   2   3   4   5   6   7   8   9 
##  30  48  19  33 133  55  25 117  26</code></pre>
<p>For this wave, Mclust selected a model with 9 (!) profiles; the optimal selected model is EEV, i.e., the profiles are ellipsoidal with equal volume and shape (see <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/">this article</a>).</p>
<p>Now we will access to the results and visualize the model. To visualize, we will use a new package (<em>factoextra</em>), to create nicer plots based on ggplot2. Note, that overall the VEV is best, and that VEV,5 is not far behind.</p>
<pre class="r"><code>library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, &quot;BIC&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
<div id="wave-3" class="section level4">
<h4>Wave 3</h4>
<p>We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).</p>
<pre class="r"><code>sms_w3 &lt;- sms_long_nm[sms_long_nm$Timepoint==3, ] %&gt;%
  select(-Timepoint, -id) %&gt;% # subset W1
  select(25:30) %&gt;% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
sms_w3$id &lt;- sms_long_nm[sms_long_nm$Timepoint==3, ]$id #add id again</code></pre>
<p>We then compute the model-based clustering, and ask for a summary.</p>
<pre class="r"><code>library(mclust)
mc &lt;- Mclust(sms_w3 %&gt;%
               select(-id))
summary(mc)                 </code></pre>
<pre><code>## ---------------------------------------------------- 
## Gaussian finite mixture model fitted by EM algorithm 
## ---------------------------------------------------- 
## 
## Mclust EEV (ellipsoidal, equal volume and shape) model with 9 components: 
## 
##  log-likelihood   n  df       BIC       ICL
##       -2858.953 506 203 -6981.893 -7096.844
## 
## Clustering table:
##   1   2   3   4   5   6   7   8   9 
##  42 142  32  27  57 149  22  21  14</code></pre>
<p>For this wave, Mclust selected a model with 9 (!) profiles; the optimal selected model is EEV, i.e., the profiles are ellipsoidal with equal volume and shape (see <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/">this article</a>).</p>
<p>Now we will access to the results and visualize the model. To visualize, we will use a new package (<em>factoextra</em>), to create nicer plots based on ggplot2. Note, that overall the VEV is best, and that VEV,4 is not far behind.</p>
<pre class="r"><code>library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, &quot;BIC&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p><br></p>
</div>
</div>
<div id="exploring-models" class="section level3 tabset tabset-fade">
<h3>Exploring models</h3>
<p>We will fit a series of measurement models for each wave to determine which model provides the best fit at each wave (following recommendations of <a href="https://srcd.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-8624.2007.01097.x?casa_token=0wyzjh9Ozk0AAAAA:iasgTYid_gJ5kGH42Jyys61DsBhEDl0zxVrukoJdaeX2e2MGOlm1nfyooEUc1v5SaB3lFYyX1wqVLGNOvQ">Nylund et al. (2007)</a> and similar to the article by <a href="https://www.tandfonline.com/doi/pdf/10.1080/10413200.2014.993485?casa_token=CsBgfG9lbtgAAAAA:CMEXxc96xNC-rF6Sowi7X2X0qvXlxI9MuODWtQ1Db92UyZUeLZcWJem1jhhympbi8dBboyrA282A5Ns">Martinent &amp; Decret (2015)</a>).</p>
<p>We will examine a sequence of models, with an increasing number of profiles from 2 to 6, to ascertain whether more complex (i.e. more profiles) or parsimonious (i.e. fewer profiles) models provided the best description of the data. We will use the VEV model (varying volume, equal shape, varying orientation), as this model provided the best fit (at least for relatively parsimonious models, which we want).</p>
<p>We will plot the profile means, the clustering and the clustering uncertainty. If the data contain more than two variables (which is the case in our data), the <em>fviz_mclust()</em>-function will use PCA to reduce the dimensionality of the data. The first two principal components are used to produce a scatter plot of the data. If we want to plot the data using only two variables (e.g., <em>external regulation</em> and <em>intrinsic motivation</em>), we can specify that in the function using the argument <em>choose.vars = c(“external”, “intrinsic”)</em>. Note that, in the uncertainty plot, larger symbols indicate the more uncertain observations.</p>
<p><br></p>
<div id="wave-1-1" class="section level4">
<h4>Wave 1</h4>
<div id="section" class="section level5 tabset tabset-fade">
<h5></h5>
<div id="profiles" class="section level6">
<h6>2 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w1 %&gt;%
                   select(-id))
m2 &lt;- Mclust(sms_w1 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m2, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-24-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m2, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-24-3.png" width="672" /></p>
</div>
<div id="profiles-1" class="section level6">
<h6>3 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w1 %&gt;%
                   select(-id))
m3 &lt;- Mclust(sms_w1 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m3, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-25-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m3, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-25-3.png" width="672" /></p>
<pre class="r fold-hide"><code># save solution
#save(m3, file = &quot;3profile_w1.RData&quot;)</code></pre>
</div>
<div id="profiles-2" class="section level6">
<h6>4 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w1 %&gt;%
                   select(-id)) 
m4 &lt;- Mclust(sms_w1 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m4, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-26-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m4, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-26-3.png" width="672" /></p>
</div>
<div id="profiles-3" class="section level6">
<h6>5 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w1 %&gt;%
                   select(-id))
m5 &lt;- Mclust(sms_w1 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m5, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-27-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m5, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-27-3.png" width="672" /></p>
</div>
<div id="profiles-4" class="section level6">
<h6>6 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w1 %&gt;%
                   select(-id))
m6 &lt;- Mclust(sms_w1 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 6, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m6$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m6, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-28-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m6, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-28-3.png" width="672" /></p>
</div>
</div>
</div>
<div id="wave-2-1" class="section level4">
<h4>Wave 2</h4>
<div id="section-1" class="section level5 tabset tabset-fade">
<h5></h5>
<div id="profiles-5" class="section level6">
<h6>2 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w2 %&gt;%
                   select(-id)) 
m2 &lt;- Mclust(sms_w2 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m2, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-29-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m2, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-29-3.png" width="672" /></p>
</div>
<div id="profiles-6" class="section level6">
<h6>3 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w2 %&gt;%
                   select(-id)) 
m3 &lt;- Mclust(sms_w2 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m3, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-30-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m3, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-30-3.png" width="672" /></p>
<pre class="r fold-hide"><code># save solution
#save(m3, file = &quot;3profile_w2.RData&quot;)</code></pre>
</div>
<div id="profiles-7" class="section level6">
<h6>4 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w2 %&gt;%
                   select(-id))
m4 &lt;- Mclust(sms_w2 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m4, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-31-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m4, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-31-3.png" width="672" /></p>
</div>
<div id="profiles-8" class="section level6">
<h6>5 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w2 %&gt;%
                   select(-id))
m5 &lt;- Mclust(sms_w2 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m5, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-32-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m5, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-32-3.png" width="672" /></p>
</div>
<div id="profiles-9" class="section level6">
<h6>6 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w2 %&gt;%
                   select(-id))
m6 &lt;- Mclust(sms_w2 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 6, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m6$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m6, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-33-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m6, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-33-3.png" width="672" /></p>
</div>
</div>
</div>
<div id="wave-3-1" class="section level4">
<h4>Wave 3</h4>
<div id="section-2" class="section level5 tabset tabset-fade">
<h5></h5>
<div id="profiles-10" class="section level6">
<h6>2 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w3 %&gt;%
                   select(-id)) 
m2 &lt;- Mclust(sms_w3 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m2, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-34-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m2, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-34-3.png" width="672" /></p>
</div>
<div id="profiles-11" class="section level6">
<h6>3 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w3 %&gt;%
                   select(-id))
m3 &lt;- Mclust(sms_w3 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m3, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-35-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m3, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-35-3.png" width="672" /></p>
<pre class="r fold-hide"><code># save solution
#save(m3, file = &quot;3profile_w3.RData&quot;)</code></pre>
</div>
<div id="profiles-12" class="section level6">
<h6>4 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w3 %&gt;%
                   select(-id)) 
m4 &lt;- Mclust(sms_w3 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m4, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-36-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m4, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-36-3.png" width="672" /></p>
</div>
<div id="profiles-13" class="section level6">
<h6>5 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w3 %&gt;%
                   select(-id))
m5 &lt;- Mclust(sms_w3 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m5, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-37-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m5, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-37-3.png" width="672" /></p>
</div>
<div id="profiles-14" class="section level6">
<h6>6 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w3 %&gt;%
                   select(-id))
m6 &lt;- Mclust(sms_w3 %&gt;%
               select(-id), modelNames = &quot;VEV&quot;, G = 6, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m6$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean &gt; 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean &lt; -1, -1, Mean))   #and -1

# Plot showing the standardized means
p &lt;- means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)

p &lt;- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)
# Plot showing the clustering
fviz_mclust(m6, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-38-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m6, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-38-3.png" width="672" /></p>
</div>
</div>
</div>
</div>
<div id="interpretation" class="section level3">
<h3>Interpretation</h3>
<p>Based on statistical criteria (i.c. BIC), complex models were more appropriate (note-to-self: also check SSA_BIC, which adjusts for sample size, or ICL, which penalizes on entropy). However, more complex models did not necessarily mean more meaningful models, guided by SDT. In all waves we found that the 3-class solution provided meaningfull profiles. We have re-ordened the profiles to match the motivational continuum proposed from SDT:</p>
<ol style="list-style-type: decimal">
<li><strong>Amotivated</strong>: primarily amotivation, and about average (or somewhat above average) on all other forms of behavioral regulation.</li>
<li><strong>Low in motivation</strong>: low levels (i.c., ~ -0.5 SD) of all types of behavioral regulation.</li>
<li><strong>High in motivation</strong>: high in autonomous forms of motivation (i.e. intrinsic, integrated, identified), and also in controlled forms (i.e. external, introjected), but low in amotivation.</li>
</ol>
<p>The fourth profile provided an extra (read: interpretable) profile in Wave 1 (i.e., high in introjected), and Wave 3 (i.e., moderate on all, low in amotivation), but not in Wave 2 (where profiles seemed to differ only quantitatively). The addition of this fourth profile makes longitudinal comparison very difficult. Therefore, we chose the 3-class solution.</p>
<p><br></p>
</div>
<div id="membership-probabilities" class="section level3 tabset tabset-fade">
<h3>Membership probabilities</h3>
<p>We also checked the profile sizes and the (average posterior) profile membership probabilities to assess if the 3-profile solution is problematic. (Note that we saved the 3-profile solution in each wave.) The table below supports the three-class solution, with high probabilities that athletes belong to their assigned profiles (albeit slight overlap) - average posterior probabilities in all waves above .89. Moreover, the relative proportion of the classes did not change substantially across time.</p>
<div id="wave-1-2" class="section level4">
<h4>Wave 1</h4>
<pre class="r fold-hide"><code>load(file = &quot;3profile_w1.RData&quot;) #load the model
prob &lt;- as.data.frame(m3$z) #turn probabilities into df
prob$class &lt;- m3$classification #get assigned profiles

c1 &lt;- prob %&gt;% #calculate average posterior probabilities
  filter(class == 1)
c2 &lt;- prob %&gt;%
  filter(class == 2)
c3 &lt;- prob %&gt;%
  filter(class == 3)

df &lt;- as.data.frame(rbind(colMeans(c1), colMeans(c2), colMeans(c3))) #make df for posterior probability table
colnames(df) &lt;- c(&quot;Low&quot;, &quot;High&quot;, &quot;Amotivation&quot;, &quot;class&quot;)
df &lt;- df[, c(&quot;class&quot;, &quot;Low&quot;, &quot;High&quot;, &quot;Amotivation&quot; )] #reorder

p &lt;- c(&quot;Low&quot;, &quot;High&quot;, &quot;Amotivation&quot;)
n &lt;- as.character(c(length(m3$n[m3$classification==1]), length(m3$n[m3$classification==2]), length(m3$n[m3$classification==3]))) #get profile sizes
n2 &lt;- as.character(round(as.numeric(n) / length(m3$classification) * 100))

df$class &lt;- ifelse(df$class == 1, paste(p[1], &quot; (N=&quot;, n[1], &quot;, &quot;, n2[1], &quot;%&quot;, &quot;)&quot;, sep = &quot;&quot;), ifelse(df$class == 2, paste(p[2], &quot; (N=&quot;, n[2], &quot;, &quot;, n2[2], &quot;%&quot;, &quot;)&quot;, sep = &quot;&quot;), paste(p[3], &quot; (N=&quot;, n[3], &quot;, &quot;, n2[3], &quot;%&quot;, &quot;)&quot;, sep = &quot;&quot;)))

knitr::kable(df, digits=2, &quot;html&quot;, caption=&quot;Membership probabilities in Wave 1&quot;) %&gt;% #make table
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
Membership probabilities in Wave 1
</caption>
<thead>
<tr>
<th style="text-align:left;">
class
</th>
<th style="text-align:right;">
Low
</th>
<th style="text-align:right;">
High
</th>
<th style="text-align:right;">
Amotivation
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Low (N=261, 42%)
</td>
<td style="text-align:right;">
0.91
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.02
</td>
</tr>
<tr>
<td style="text-align:left;">
High (N=205, 33%)
</td>
<td style="text-align:right;">
0.06
</td>
<td style="text-align:right;">
0.87
</td>
<td style="text-align:right;">
0.07
</td>
</tr>
<tr>
<td style="text-align:left;">
Amotivation (N=155, 25%)
</td>
<td style="text-align:right;">
0.02
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.94
</td>
</tr>
</tbody>
</table>
</div>
<div id="wave-2-2" class="section level4">
<h4>Wave 2</h4>
<pre class="r fold-hide"><code>load(file = &quot;3profile_w2.RData&quot;) #load the model
prob &lt;- as.data.frame(m3$z) #turn probabilities into df
prob$class &lt;- m3$classification #get assigned profiles

c1 &lt;- prob %&gt;% #calculate average posterior probabilities
  filter(class == 1)
c2 &lt;- prob %&gt;%
  filter(class == 2)
c3 &lt;- prob %&gt;%
  filter(class == 3)

df &lt;- as.data.frame(rbind(colMeans(c1), colMeans(c2), colMeans(c3))) #make df for posterior probability table
colnames(df) &lt;- c(&quot;Low&quot;, &quot;High&quot;, &quot;Amotivation&quot;, &quot;class&quot;)
df &lt;- df[, c(&quot;class&quot;, &quot;Low&quot;, &quot;High&quot;, &quot;Amotivation&quot; )] #reorder

p &lt;- c(&quot;Low&quot;, &quot;High&quot;, &quot;Amotivation&quot;)
n &lt;- as.character(c(length(m3$n[m3$classification==1]), length(m3$n[m3$classification==2]), length(m3$n[m3$classification==3]))) #get profile sizes
n2 &lt;- as.character(round(as.numeric(n) / length(m3$classification) * 100))

df$class &lt;- ifelse(df$class == 1, paste(p[1], &quot; (N=&quot;, n[1], &quot;, &quot;, n2[1], &quot;%&quot;, &quot;)&quot;, sep = &quot;&quot;), ifelse(df$class == 2, paste(p[2], &quot; (N=&quot;, n[2], &quot;, &quot;, n2[2], &quot;%&quot;, &quot;)&quot;, sep = &quot;&quot;), paste(p[3], &quot; (N=&quot;, n[3], &quot;, &quot;, n2[3], &quot;%&quot;, &quot;)&quot;, sep = &quot;&quot;)))

knitr::kable(df, digits=2, &quot;html&quot;, caption=&quot;Membership probabilities in Wave 2&quot;) %&gt;% #make table
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
Membership probabilities in Wave 2
</caption>
<thead>
<tr>
<th style="text-align:left;">
class
</th>
<th style="text-align:right;">
Low
</th>
<th style="text-align:right;">
High
</th>
<th style="text-align:right;">
Amotivation
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Low (N=216, 44%)
</td>
<td style="text-align:right;">
0.88
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
0.04
</td>
</tr>
<tr>
<td style="text-align:left;">
High (N=135, 28%)
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
0.86
</td>
<td style="text-align:right;">
0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
Amotivation (N=135, 28%)
</td>
<td style="text-align:right;">
0.02
</td>
<td style="text-align:right;">
0.03
</td>
<td style="text-align:right;">
0.95
</td>
</tr>
</tbody>
</table>
</div>
<div id="wave-3-2" class="section level4">
<h4>Wave 3</h4>
<pre class="r fold-hide"><code>load(file = &quot;3profile_w3.RData&quot;) #load the model
prob &lt;- as.data.frame(m3$z) #turn probabilities into df
prob$class &lt;- m3$classification #get assigned profiles

c1 &lt;- prob %&gt;% #calculate average posterior probabilities
  filter(class == 1)
c2 &lt;- prob %&gt;%
  filter(class == 2)
c3 &lt;- prob %&gt;%
  filter(class == 3)

df &lt;- as.data.frame(rbind(colMeans(c1), colMeans(c2), colMeans(c3))) #make df for posterior probability table
colnames(df) &lt;- c(&quot;Low&quot;, &quot;Amotivation&quot;, &quot;High&quot;, &quot;class&quot;)
df &lt;- df[, c(&quot;class&quot;, &quot;Low&quot;, &quot;Amotivation&quot;, &quot;High&quot; )] #reorder

p &lt;- c(&quot;Low&quot;, &quot;Amotivation&quot;, &quot;High&quot;)
n &lt;- as.character(c(length(m3$n[m3$classification==1]), length(m3$n[m3$classification==2]), length(m3$n[m3$classification==3]))) #get profile sizes
n2 &lt;- as.character(round(as.numeric(n) / length(m3$classification) * 100))

df$class &lt;- ifelse(df$class == 1, paste(p[1], &quot; (N=&quot;, n[1], &quot;, &quot;, n2[1], &quot;%&quot;, &quot;)&quot;, sep = &quot;&quot;), ifelse(df$class == 2, paste(p[2], &quot; (N=&quot;, n[2], &quot;, &quot;, n2[2], &quot;%&quot;, &quot;)&quot;, sep = &quot;&quot;), paste(p[3], &quot; (N=&quot;, n[3], &quot;, &quot;, n2[3], &quot;%&quot;, &quot;)&quot;, sep = &quot;&quot;)))

knitr::kable(df, digits=2, &quot;html&quot;, caption=&quot;Membership probabilities in Wave 3&quot;) %&gt;% #make table
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
Membership probabilities in Wave 3
</caption>
<thead>
<tr>
<th style="text-align:left;">
class
</th>
<th style="text-align:right;">
Low
</th>
<th style="text-align:right;">
Amotivation
</th>
<th style="text-align:right;">
High
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Low (N=229, 45%)
</td>
<td style="text-align:right;">
0.87
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.09
</td>
</tr>
<tr>
<td style="text-align:left;">
Amotivation (N=124, 25%)
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.95
</td>
<td style="text-align:right;">
0.01
</td>
</tr>
<tr>
<td style="text-align:left;">
High (N=153, 30%)
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.86
</td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
</div>
</div>
<div id="step-2" class="section level2">
<h2>Step 2</h2>
<div id="old-3-step-approach" class="section level3">
<h3>Old 3-step approach</h3>
<p>As a second step, we assign to each subject their profile membership. Through “the old 3-step approach” each subject’s class membership is <em>determined</em> by their most likely class membership. However, this approach may be problematic, as it does not account for classification error, and thus may give biased estimates and standard errors with the relationships with other variables, and the transition probabilities (see <a href="#new">new approach</a>).</p>
<pre class="r"><code>names(sms_long_nm)</code></pre>
<pre><code>##  [1] &quot;id&quot;          &quot;Timepoint&quot;   &quot;M1_1&quot;        &quot;M1_2&quot;        &quot;M1_3&quot;       
##  [6] &quot;M1_4&quot;        &quot;M1_5&quot;        &quot;M1_6&quot;        &quot;M1_7&quot;        &quot;M1_8&quot;       
## [11] &quot;M2_1&quot;        &quot;M2_2&quot;        &quot;M2_3&quot;        &quot;M2_4&quot;        &quot;M2_5&quot;       
## [16] &quot;M2_6&quot;        &quot;M2_7&quot;        &quot;M2_8&quot;        &quot;M3_1&quot;        &quot;M3_2&quot;       
## [21] &quot;M3_3&quot;        &quot;M3_4&quot;        &quot;M3_5&quot;        &quot;M3_6&quot;        &quot;M3_7&quot;       
## [26] &quot;M3_8&quot;        &quot;amotivation&quot; &quot;external&quot;    &quot;introjected&quot; &quot;identified&quot; 
## [31] &quot;integrated&quot;  &quot;intrinsic&quot;</code></pre>
</div>
<div id="new" class="section level3">
<h3>New 3-step approach</h3>
<p>We created a nominal “most likely class” variable <em>N</em>, and a latent class variable <em>z</em>, which reflects the probability to belong to N.</p>
<hr />
</div>
</div>
</div>
<div id="lpta" class="section level1">
<h1>LPTA</h1>
<p>Given that the motivational profiles observed on the LPAs appeared fairly consistent across the waves, the next step is to use LPTA to describe respondents’ change of motivational profiles across time. This allows us to examine the issue of consistency or change from an intraindividual perspective.</p>
</div>

<div id="rmd-source-code">---
title: "Latent Profile Transition Analysis"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 3
    code_folding: show
    code_download: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```


<br>

*Last edited: January 25, 2021*

<br>

In the following, we will explore motivational profiles in the context of longitudinal data, using SDT as a theoretical framework. We will explore movement between motivational profiles over time.

<br>

## Approach

EDIT!
First, we obtain weighted factor-scores for each SMS-subscale with CFA using MLE, as input for our subsequent LPA. Then, we use a three-step approach (see [this article](https://www.tandfonline.com/doi/pdf/10.1080/10705511.2014.915181); or the paper by [Emm-Collison and colleagues](https://www.sciencedirect.com/science/article/pii/S1469029219303851) who used the same procedure).


---

# Preliminary steps

## 1. Data

Let's get our 'cleaned' SMS-data, for each wave. We identify "string responding", and cap it to a maximum of 10 and we exclude multivariate outliers with Mahalanobis Distance, using alpha .001 as a cutoff. Next, we make a long file of the SMS data.

```{r, warning=FALSE, message=FALSE, class.source = 'fold-hide'}
library(sjlabelled)
library(dplyr)
library(tidyverse)
library(careless)
library(psych)

load("data_abs_public_v2.RData") # load data
data_abs_public <- unlabel(data_abs_public, verbose=F) # unlabel

data_abs_public$id <- 1:nrow(data_abs_public) # add identifier for subsequent LPTA

# subset sms data in each wave
sms_w1 <- data_abs_public %>% select(W1_M1_1, W1_M1_2, W1_M1_3, W1_M1_4, W1_M1_5, W1_M1_6, W1_M1_7, W1_M1_8, W1_M2_1, W1_M2_2, W1_M2_3, W1_M2_4, W1_M2_5, W1_M2_6, W1_M2_7, W1_M2_8, W1_M3_1, W1_M3_2, W1_M3_3, W1_M3_4, W1_M3_5, W1_M3_6, W1_M3_7, W1_M3_8, id)

sms_w2 <- data_abs_public %>% select(W2_M1_1, W2_M1_2, W2_M1_3, W2_M1_4, W2_M1_5, W2_M1_6, W2_M1_7, W2_M1_8, W2_M2_1, W2_M2_2, W2_M2_3, W2_M2_4, W2_M2_5, W2_M2_6, W2_M2_7, W2_M2_8, W2_M3_1, W2_M3_2, W2_M3_3, W2_M3_4, W2_M3_5, W2_M3_6, W2_M3_7, W2_M3_8, id) 

sms_w3 <- data_abs_public %>% select(W3_M1_1, W3_M1_2, W3_M1_3, W3_M1_4, W3_M1_5, W3_M1_6, W3_M1_7, W3_M1_8, W3_M2_1, W3_M2_2, W3_M2_3, W3_M2_4, W3_M2_5, W3_M2_6, W3_M2_7, W3_M2_8, W3_M3_1, W3_M3_2, W3_M3_3, W3_M3_4, W3_M3_5, W3_M3_6, W3_M3_7, W3_M3_8, id)

# make a 'string' variable 
sms_w1 <- sms_w1 %>%
  mutate(string_w1 = longstring(.)) %>%
  mutate(md_w1 = outlier(., plot = FALSE))

sms_w2 <- sms_w2 %>%
  mutate(string_w2 = longstring(.)) %>%
  mutate(md_w2 = outlier(., plot = FALSE)) 

sms_w3 <- sms_w3 %>%
  mutate(string_w3 = longstring(.)) %>%
  mutate(md_w3 = outlier(., plot = FALSE)) 

# cap string responding and use MD
cutoff_w1 <- (qchisq(p = 1 - .001, df = (ncol(sms_w1) - 1)))
sms_w1 <- sms_w1 %>%
  filter(string_w1 <= 10,
         md_w1 < cutoff_w1) %>%
  select(-string_w1, -md_w1)

  cutoff_w2 <- (qchisq(p = 1 - .001, df = (ncol(sms_w2) - 1)))
sms_w2 <- sms_w2 %>%
  filter(string_w2 <= 10,
         md_w2 < cutoff_w2) %>%
  select(-string_w2, -md_w2)

cutoff_w3 <- (qchisq(p = 1 - .001, df = (ncol(sms_w3) - 1)))
sms_w3 <- sms_w3 %>%
  filter(string_w3 <= 10,
         md_w3 < cutoff_w3) %>%
  select(-string_w3, -md_w3)

# first, make a wide format
sms_wide <- merge(sms_w1, sms_w2, by = "id") # first wave 1 and 2
sms_wide <- merge(sms_wide, sms_w3, by = "id") # add wave 3

# then transform into long shape
library(reshape2)
sms_long <- reshape(sms_wide,
                    direction = "long",
                    varying = c(list(names(sms_wide)[c(2, 26, 50)]), list(names(sms_wide)[c(3, 27, 51)]), list(names(sms_wide)[c(4, 28, 52)]), list(names(sms_wide)[c(5, 29, 53)]), list(names(sms_wide)[c(6, 30, 54)]), list(names(sms_wide)[c(7, 31, 55)]), list(names(sms_wide)[c(8, 32, 56)]), list(names(sms_wide)[c(9, 33, 57)]), list(names(sms_wide)[c(10, 34, 58)]),list(names(sms_wide)[c(11, 35, 59)]), list(names(sms_wide)[c(12, 36, 60)]), list(names(sms_wide)[c(13, 37, 61)]), list(names(sms_wide)[c(14, 38, 62)]),list(names(sms_wide)[c(15, 39, 63)]), list(names(sms_wide)[c(16, 40, 64)]), list(names(sms_wide)[c(17, 41, 65)]), list(names(sms_wide)[c(18, 42, 66)]), list(names(sms_wide)[c(19, 43, 67)]), list(names(sms_wide)[c(20, 44, 68)]),  list(names(sms_wide)[c(21, 45, 69)]),  list(names(sms_wide)[c(22, 46, 70)]), list(names(sms_wide)[c(23, 47, 71)]), list(names(sms_wide)[c(24, 48, 72)]), list(names(sms_wide)[c(25, 49, 73)])),
                    v.names = c("M1_1", "M1_2", "M1_3","M1_4", "M1_5", "M1_6", "M1_7", "M1_8", "M2_1", "M2_2", "M2_3","M2_4", "M2_5", "M2_6", "M2_7", "M2_8", "M3_1", "M3_2", "M3_3","M3_4", "M3_5", "M3_6", "M3_7", "M3_8"),
                    idvar = "id",
                    timevar = "Timepoint",
                    times = 1:3)
# Reorder
sms_long  <- sms_long [(order(sms_long$id)), ]
# fix(sms_long) to check data structure

sms_long_nm <- sms_long %>%
  na.omit() # listwise deletion
```

<br>

----

## 2. CFA

First, confirmatory factor analysis using maximum likelihood estimation was conducted to obtain weighted factor scores for each SMS subscale. We first conduct CFA on the stacked data (hence assuming observations to be independent of each other). We will assess model fit using multiple indices. Afterwards, we will assess longitudinal invariance of the measurement model via a series of increasingly constrained models, indicating invariance by a change of CFI of ≤0.01.

### Lavaan

Tell Lavaan the confirmatory structure.

```{r}
library(lavaan)

motivation_model <- "
amotivation =~ M1_5 + M2_4 + M3_1 + M3_6
external    =~ M1_4 + M2_3 + M3_3 + M3_8
introjected =~ M1_7 + M2_2 + M2_8 + M3_7
identified  =~ M1_3 + M1_8 + M2_7 + M3_4
integrated  =~ M1_2 + M2_1 + M2_5 + M3_5
intrinsic   =~ M1_1 + M1_6 + M2_6 + M3_2
"
```

Now let's inspect the model. We will get the fit of the model, the (standardized) factor loadings, item averages (intercepts), error variances, and R-square scores. We will also make a table of the various fit indices. 
 
```{r}
# examine overall fit
overall.fit <- cfa(model = motivation_model, data = sms_long_nm,
           meanstructure = TRUE,  # gives us the means
           std.lv = TRUE) 

#summary(overall.fit, standardized = TRUE, rsquare = TRUE, fit.measure = TRUE) #for inspection

# make table of fit indices
table_fit <- matrix(NA, nrow = 8, ncol = 6)
colnames(table_fit) <- c("Model", "X2", "df", "CFI", "RMSEA", "SRMR")
table_fit[1, ] <- c("Overall Model", round(fitmeasures(overall.fit, c("chisq", "df", "cfi", "rmsea", "srmr")),3))
```

<br>

To check the confirmatory structure of our model, we will also create a picture of the standardized solution (quick and dirty; it can be edited...). The triangles depict the (standardized) intercepts, the arrows depic the variance (i.e. the loops) and (standardized) factor loadings. 

```{r}
library(semPlot)
semPaths(overall.fit, whatLabels = "std", layout = "tree")
```

### Longitudinal invariance {.tabset .tabset-fade}

Since we are dealing with panel data, and we want to explore movement over time in motivations, we should investigate to what extent our CFA solution is invariant over time (because we don't want to compare apples with oranges).
We will compare the SMS data of W1-W3 and compare them in CFA for configural, metric, scalar, and strict residual invariance (see e.g., [Cheung & Rensvold 2002](https://www.tandfonline.com/doi/pdf/10.1207/S15328007SEM0902_5?casa_token=scyVPZRkncQAAAAA:PDDawXxC0BMvLu-kjcvtaFcHseZnO3rkwX4nJGtd8OrK-nuTq4B1Mk571ajpjaq3JQhasVHnyXtofdg)).

<br>

#### Configural invariance

Starting with a test for configural invariance - is the 'picture'/structure of the model the same for all waves. We make a multi-group model by using the group-argument.

```{r}
con.fit <- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
               group = "Timepoint")
table_fit[2, ] <- c("Configural Model", round(fitmeasures(con.fit, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) #add results to the table

library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

input <- table_fit[1:2, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

This is the model against which we will test the next model. So, we will conduct a sequential testing analysis.  

<br>

#### Metric invariance
Next, we will assess metric invariance, by constraining the factor loadings to be equal across the waves. In the configural model, factor loadings were "freely" estimated in both waves; now, only 1 loading gets estimated for both groups. Let's see what happens to the model.


```{r}
met.fit <- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
               group = "Timepoint", group.equal = c("loadings"))
table_fit[3, ] <- c("Metric Model", round(fitmeasures(met.fit, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:3, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

The metric model seems to be invariant in comparison to the configural model: the CFI difference is smaller than .01, hence assuming invariance (same holds for RMSEA/SRMR). Conclusion: the metric model holds: the loadings are equal (or close enough). 

<br>

#### Scalar invariance
We have constrained our model to contain the same structure, the same loadings; now let's test for scalar invariance, to see if the intercepts are the same across waves. 

```{r}
sca.fit <- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
               group = "Timepoint", group.equal = c("loadings", "intercepts"))
table_fit[4, ] <- c("Scalar Model", round(fitmeasures(sca.fit, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:4, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

The intercepts are equal on the scale between the waves. 

<br>

#### Strict (residual) invariance
Last, we constrain the model to the strict model, to check for strict residual invariance. It will inform whether the variance around items is the same across time.

```{r}
str.fit <- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
               group = "Timepoint", group.equal = c("loadings", "intercepts", "residuals"))
table_fit[5, ] <- c("Strict Model", round(fitmeasures(str.fit, c("chisq", "df", "cfi", "rmsea", "srmr")),3))


input <- table_fit[1:5, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

From here it goes downwards... CFI dropped more than 0.01, suggesting that the residuals vary between the waves. 

<br>

#### Partial invariance
We could estimate partial invariance, to investigate where the problem is and subsequently update the model to fix it. We are going to do so by freeing the variances of item residuals, one at a time, to figure out which equality constaint(s) is/are causing the problem. We will use the following loop for this. 

```{r}
# write out partial codes
partial_syntax <- paste(colnames(sms_long_nm)[3:26], #all sms columns
                        "~~", #residuals
                        colnames(sms_long_nm)[3:26]) #all columns again

CFI_list <- 1:length(partial_syntax)
names(CFI_list) <- partial_syntax 

for (i in 1:length(partial_syntax)){
  
  temp <- cfa(model = motivation_model,
              data = sms_long_nm,
              meanstructure = TRUE,
              group = "Timepoint",
              group.equal = c("loadings", "intercepts", "residuals"),
              group.partial = partial_syntax[i])
  
  CFI_list[i] <- fitmeasures(temp, "cfi")
}


# now figure out which parameters to "free"
options(scipen = 999)
sort(CFI_list - fitmeasures(str.fit, "cfi"), decreasing = TRUE)
```

Let's free up those parameters, starting with the one that increases CFI to the greatest extent. 

```{r}
par.fit <- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
               group = "Timepoint", group.equal = c("loadings", "intercepts", "residuals"),
               group.partial = "M1_5~~M1_5")
table_fit[6, ] <- c("Strict Model + M1_5", round(fitmeasures(par.fit, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:6, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

CFI improved, but the difference in CFI with the baseline scalar model is still greater than .01. Thus, we still need to free (at least) one more, to achieve "partial" invariance. 

```{r}
par.fit2 <- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
                group = "Timepoint", group.partial = c("M1_5~~M1_5", "M1_7~~M1_7"),
                group.equal = c("loadings", "intercepts", "residuals"))
table_fit[7, ] <- c("Strict Model + M1_5 + M1_7", round(fitmeasures(par.fit2, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:7, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

Ditto...

```{r}
par.fit3 <- cfa(model = motivation_model, data = sms_long_nm, meanstructure = TRUE,
                group = "Timepoint", group.partial = c("M1_5~~M1_5", "M1_7~~M1_7", "M1_6~~M1_6"),
                group.equal = c("loadings", "intercepts", "residuals"))
table_fit[8, ] <- c("Strict Model + M1_5 + M1_7 + M1_6", round(fitmeasures(par.fit3, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:8, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

<br>

### Conclusion

We can conclude that the SMS is mostly invariant - the structure, factor loadings, intercepts, and most of the error variances were equal across time.

<br>

### Weighted factor-scores
Now we use the (partially) invariant measurement model to generate (weighted) factor scores as input variables for the subsequent LPA. Weighted factor scores are computed by multiplying the factor loading of each item to the scaled score for each item before summing (see [DiStefano et al. (2009)](https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1226&context=pare)). 

We extract the factor loadings, and calculate the weighted sum scores.

```{r}
loading <- parameterEstimates(par.fit3)$est[1:24] # extract factor loadings

# calculate weighted (sum) factor-scores
sms_long_nm$amotivation <- rowMeans(cbind((sms_long_nm$M1_5*loading[1]), (sms_long_nm$M2_4*loading[2]), (sms_long_nm$M3_1*loading[3]), (sms_long_nm$M3_6*loading[4])))

sms_long_nm$external <- rowMeans(cbind((sms_long_nm$M1_4*loading[5]), (sms_long_nm$M2_3*loading[6]), (sms_long_nm$M3_3*loading[7]),   (sms_long_nm$M3_8*loading[8])))

sms_long_nm$introjected <- rowMeans(cbind((sms_long_nm$M1_7*loading[9]), (sms_long_nm$M2_2*loading[10]), (sms_long_nm$M2_8*loading[11]), (sms_long_nm$M3_7*loading[12])))

sms_long_nm$identified <- rowMeans(cbind((sms_long_nm$M1_3*loading[13]), (sms_long_nm$M1_8*loading[14]), (sms_long_nm$M2_7*loading[15]), (sms_long_nm$M3_4*loading[16])))

sms_long_nm$integrated <- rowMeans(cbind((sms_long_nm$M1_2*loading[17]), (sms_long_nm$M2_1*loading[18]), (sms_long_nm$M2_5*loading[19]), (sms_long_nm$M3_5*loading[20])))

sms_long_nm$intrinsic <- rowMeans(cbind((sms_long_nm$M1_1*loading[21]), (sms_long_nm$M1_6*loading[22]), (sms_long_nm$M2_6*loading[23]), (sms_long_nm$M3_2*loading[24])))

```

<br>

----

## 3. Descriptives

Let's describe our weighted factor scores over time. 

```{r}
library(crosstable)

input <- sms_long_nm %>% #get factor scores and timepoint as grouping variable
  select(27:32, 2)

# integrate wave number and n in header
n <- as.vector(table(input$Timepoint))
x <- paste(levels(as.factor(input$Timepoint)), " (N=", n, ")", sep="")
input$Timepoint <- as.factor(input$Timepoint)
levels(input$Timepoint) <- x

#flextable
crosstable(input, by=Timepoint,
           funs=c("Mean" = mean, "Std. dev." = sd, "Min" = min, "Max" = max), funs_arg=list(digits=3)) %>%
  as_flextable(by_header = "Wave")
```

At face value, respondents seem to be pretty high in all types of motivation (e.g., compared with the sample of [Emm-Collison and colleagues](https://www.sciencedirect.com/science/article/pii/S1469029219303851) - though these were sum scores).


<br>

----

# LPA  

## Step 1 

<br>

### Model-based clustering {.tabset .tabset-fade}

As a first step for the LPA, we carefully select a measurement model that accurately captures the construct of motivational profile, in each wave. 

<br>

#### Wave 1

We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).

```{r}
sms_w1 <- sms_long_nm[sms_long_nm$Timepoint==1, ] %>%
  select(-Timepoint, -id) %>% # subset W1
  select(25:30) %>% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
sms_w1$id <- sms_long_nm[sms_long_nm$Timepoint==1, ]$id #add id again
```

We then compute the model-based clustering, and ask for a summary.
```{r}
library(mclust)
mc <- Mclust(sms_w1 %>%
               select(-id))
summary(mc)                 
```

For this wave, Mclust selected a model with 7 profiles; the optimal selected model is VEV, i.e., the profiles are ellipsoidal with equal shape (see [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/)).

Now we will access to the results and visualize the model. To visualize, we will use a new package (*factoextra*), to create nicer plots based on ggplot2.

```{r}
library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, "BIC", palette = "jco")
```

#### Wave 2

We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).

```{r}
sms_w2 <- sms_long_nm[sms_long_nm$Timepoint==2, ] %>%
  select(-Timepoint, -id) %>% # subset W1
  select(25:30) %>% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
sms_w2$id <- sms_long_nm[sms_long_nm$Timepoint==2, ]$id #add id again
```

We then compute the model-based clustering, and ask for a summary.
```{r}
library(mclust)
mc <- Mclust(sms_w2 %>%
               select(-id))
summary(mc)                 
```

For this wave, Mclust selected a model with 9 (!) profiles; the optimal selected model is EEV, i.e., the profiles are ellipsoidal with equal volume and shape (see [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/)).

Now we will access to the results and visualize the model. To visualize, we will use a new package (*factoextra*), to create nicer plots based on ggplot2. Note, that overall the VEV is best, and that VEV,5 is not far behind.

```{r}
library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, "BIC", palette = "jco")
```

#### Wave 3

We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).

```{r}
sms_w3 <- sms_long_nm[sms_long_nm$Timepoint==3, ] %>%
  select(-Timepoint, -id) %>% # subset W1
  select(25:30) %>% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
sms_w3$id <- sms_long_nm[sms_long_nm$Timepoint==3, ]$id #add id again
```

We then compute the model-based clustering, and ask for a summary.
```{r}
library(mclust)
mc <- Mclust(sms_w3 %>%
               select(-id))
summary(mc)                 
```

For this wave, Mclust selected a model with 9 (!) profiles; the optimal selected model is EEV, i.e., the profiles are ellipsoidal with equal volume and shape (see [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/)). 

Now we will access to the results and visualize the model. To visualize, we will use a new package (*factoextra*), to create nicer plots based on ggplot2. Note, that overall the VEV is best, and that VEV,4 is not far behind.

```{r}
library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, "BIC", palette = "jco")
```

<br>


### Exploring models {.tabset .tabset-fade}

We will fit a series of measurement models for each wave to determine which model provides the best fit at each wave (following recommendations of [Nylund et al. (2007)](https://srcd.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-8624.2007.01097.x?casa_token=0wyzjh9Ozk0AAAAA:iasgTYid_gJ5kGH42Jyys61DsBhEDl0zxVrukoJdaeX2e2MGOlm1nfyooEUc1v5SaB3lFYyX1wqVLGNOvQ) and similar to the article by [Martinent & Decret (2015)](https://www.tandfonline.com/doi/pdf/10.1080/10413200.2014.993485?casa_token=CsBgfG9lbtgAAAAA:CMEXxc96xNC-rF6Sowi7X2X0qvXlxI9MuODWtQ1Db92UyZUeLZcWJem1jhhympbi8dBboyrA282A5Ns)).

We will examine a sequence of models, with an increasing number of profiles from 2 to 6, to ascertain whether more complex (i.e. more profiles) or parsimonious (i.e. fewer profiles) models provided the best description of the data. We will use the VEV model (varying volume, equal shape, varying orientation), as this model provided the best fit (at least for relatively parsimonious models, which we want).

We will plot the profile means, the clustering and the clustering uncertainty. If the data contain more than two variables (which is the case in our data), the *fviz_mclust()*-function will use PCA to reduce the dimensionality of the data. The first two principal components are used to produce a scatter plot of the data. If we want to plot the data using only two variables (e.g., *external regulation* and *intrinsic motivation*), we can specify that in the function using the argument *choose.vars = c("external", "intrinsic")*. Note that, in the uncertainty plot, larger symbols indicate the more uncertain observations.

<br>

#### Wave 1

##### {.tabset .tabset-fade}

###### 2 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1 %>%
                   select(-id))
m2 <- Mclust(sms_w1 %>%
               select(-id), modelNames = "VEV", G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m2, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m2, "uncertainty", palette = "jco")
```

###### 3 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1 %>%
                   select(-id))
m3 <- Mclust(sms_w1 %>%
               select(-id), modelNames = "VEV", G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m3, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m3, "uncertainty", palette = "jco")

# save solution
#save(m3, file = "3profile_w1.RData")
```

###### 4 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1 %>%
                   select(-id)) 
m4 <- Mclust(sms_w1 %>%
               select(-id), modelNames = "VEV", G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m4, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m4, "uncertainty", palette = "jco")
```

###### 5 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1 %>%
                   select(-id))
m5 <- Mclust(sms_w1 %>%
               select(-id), modelNames = "VEV", G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m5, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m5, "uncertainty", palette = "jco")
```

###### 6 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1 %>%
                   select(-id))
m6 <- Mclust(sms_w1 %>%
               select(-id), modelNames = "VEV", G = 6, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m6$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m6, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m6, "uncertainty", palette = "jco")
```

#### Wave 2

##### {.tabset .tabset-fade}

###### 2 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2 %>%
                   select(-id)) 
m2 <- Mclust(sms_w2 %>%
               select(-id), modelNames = "VEV", G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m2, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m2, "uncertainty", palette = "jco")
```

###### 3 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2 %>%
                   select(-id)) 
m3 <- Mclust(sms_w2 %>%
               select(-id), modelNames = "VEV", G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m3, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m3, "uncertainty", palette = "jco")

# save solution
#save(m3, file = "3profile_w2.RData")
```

###### 4 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2 %>%
                   select(-id))
m4 <- Mclust(sms_w2 %>%
               select(-id), modelNames = "VEV", G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m4, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m4, "uncertainty", palette = "jco")
```

###### 5 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2 %>%
                   select(-id))
m5 <- Mclust(sms_w2 %>%
               select(-id), modelNames = "VEV", G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m5, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m5, "uncertainty", palette = "jco")
```

###### 6 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2 %>%
                   select(-id))
m6 <- Mclust(sms_w2 %>%
               select(-id), modelNames = "VEV", G = 6, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m6$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m6, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m6, "uncertainty", palette = "jco")
```

#### Wave 3

##### {.tabset .tabset-fade}

###### 2 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3 %>%
                   select(-id)) 
m2 <- Mclust(sms_w3 %>%
               select(-id), modelNames = "VEV", G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m2, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m2, "uncertainty", palette = "jco")
```

###### 3 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3 %>%
                   select(-id))
m3 <- Mclust(sms_w3 %>%
               select(-id), modelNames = "VEV", G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m3, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m3, "uncertainty", palette = "jco")

# save solution
#save(m3, file = "3profile_w3.RData")
```

###### 4 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3 %>%
                   select(-id)) 
m4 <- Mclust(sms_w3 %>%
               select(-id), modelNames = "VEV", G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m4, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m4, "uncertainty", palette = "jco")
```

###### 5 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3 %>%
                   select(-id))
m5 <- Mclust(sms_w3 %>%
               select(-id), modelNames = "VEV", G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m5, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m5, "uncertainty", palette = "jco")
```

###### 6 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3 %>%
                   select(-id))
m6 <- Mclust(sms_w3 %>%
               select(-id), modelNames = "VEV", G = 6, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m6$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2),
         Mean = ifelse(Mean > 1.5, 1.5, Mean), #trim values greater exceeding + 1.5
         Mean = ifelse(Mean < -1, -1, Mean))   #and -1

# Plot showing the standardized means
p <- means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_point(size = 3) + 
  geom_line(size = 1.5) +  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#E69F00", "#56B4E9", "#000000", "#009E73", "#F0E442", "#0072B2")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

p <- p + scale_y_continuous(limits=c(-1, 1.5)) # fix scale

print(p)

library(factoextra)
# Plot showing the clustering
fviz_mclust(m6, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m6, "uncertainty", palette = "jco")
```


### Interpretation

Based on statistical criteria (i.c. BIC), complex models were more appropriate (note-to-self: also check SSA_BIC, which adjusts for sample size, or ICL, which penalizes on entropy). However, more complex models did not necessarily mean more meaningful models, guided by SDT. In all waves we found that the 3-class solution provided meaningfull profiles. We have re-ordened the profiles to match the motivational continuum proposed from SDT:

1. **Amotivated**: primarily amotivation, and about average (or somewhat above average) on all other forms of behavioral regulation.
2. **Low in motivation**: low levels (i.c., ~ -0.5 SD) of all types of behavioral regulation.
3. **High in motivation**: high in autonomous forms of motivation (i.e. intrinsic, integrated, identified), and also in controlled forms (i.e. external, introjected), but low in amotivation. 

The fourth profile provided an extra (read: interpretable) profile in Wave 1 (i.e., high in introjected), and Wave 3 (i.e., moderate on all, low in amotivation), but not in Wave 2 (where profiles seemed to differ only quantitatively). The addition of this fourth profile makes longitudinal comparison very difficult. Therefore, we chose the 3-class solution.  

<br>

### Membership probabilities {.tabset .tabset-fade}

We also checked the profile sizes and the (average posterior) profile membership probabilities to assess if the 3-profile solution is problematic. (Note that we saved the 3-profile solution in each wave.) The table below supports the three-class solution, with high probabilities that athletes belong to their assigned profiles (albeit slight overlap) - average posterior probabilities in all waves above .89. Moreover, the relative proportion of the classes did not change substantially across time.

#### Wave 1

```{r class.source = 'fold-hide'}
load(file = "3profile_w1.RData") #load the model
prob <- as.data.frame(m3$z) #turn probabilities into df
prob$class <- m3$classification #get assigned profiles

c1 <- prob %>% #calculate average posterior probabilities
  filter(class == 1)
c2 <- prob %>%
  filter(class == 2)
c3 <- prob %>%
  filter(class == 3)

df <- as.data.frame(rbind(colMeans(c1), colMeans(c2), colMeans(c3))) #make df for posterior probability table
colnames(df) <- c("Low", "High", "Amotivation", "class")
df <- df[, c("class", "Low", "High", "Amotivation" )] #reorder

p <- c("Low", "High", "Amotivation")
n <- as.character(c(length(m3$n[m3$classification==1]), length(m3$n[m3$classification==2]), length(m3$n[m3$classification==3]))) #get profile sizes
n2 <- as.character(round(as.numeric(n) / length(m3$classification) * 100))

df$class <- ifelse(df$class == 1, paste(p[1], " (N=", n[1], ", ", n2[1], "%", ")", sep = ""), ifelse(df$class == 2, paste(p[2], " (N=", n[2], ", ", n2[2], "%", ")", sep = ""), paste(p[3], " (N=", n[3], ", ", n2[3], "%", ")", sep = "")))

knitr::kable(df, digits=2, "html", caption="Membership probabilities in Wave 1") %>% #make table
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

#### Wave 2

```{r class.source = 'fold-hide'}
load(file = "3profile_w2.RData") #load the model
prob <- as.data.frame(m3$z) #turn probabilities into df
prob$class <- m3$classification #get assigned profiles

c1 <- prob %>% #calculate average posterior probabilities
  filter(class == 1)
c2 <- prob %>%
  filter(class == 2)
c3 <- prob %>%
  filter(class == 3)

df <- as.data.frame(rbind(colMeans(c1), colMeans(c2), colMeans(c3))) #make df for posterior probability table
colnames(df) <- c("Low", "High", "Amotivation", "class")
df <- df[, c("class", "Low", "High", "Amotivation" )] #reorder

p <- c("Low", "High", "Amotivation")
n <- as.character(c(length(m3$n[m3$classification==1]), length(m3$n[m3$classification==2]), length(m3$n[m3$classification==3]))) #get profile sizes
n2 <- as.character(round(as.numeric(n) / length(m3$classification) * 100))

df$class <- ifelse(df$class == 1, paste(p[1], " (N=", n[1], ", ", n2[1], "%", ")", sep = ""), ifelse(df$class == 2, paste(p[2], " (N=", n[2], ", ", n2[2], "%", ")", sep = ""), paste(p[3], " (N=", n[3], ", ", n2[3], "%", ")", sep = "")))

knitr::kable(df, digits=2, "html", caption="Membership probabilities in Wave 2") %>% #make table
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

#### Wave 3

```{r class.source = 'fold-hide'}
load(file = "3profile_w3.RData") #load the model
prob <- as.data.frame(m3$z) #turn probabilities into df
prob$class <- m3$classification #get assigned profiles

c1 <- prob %>% #calculate average posterior probabilities
  filter(class == 1)
c2 <- prob %>%
  filter(class == 2)
c3 <- prob %>%
  filter(class == 3)

df <- as.data.frame(rbind(colMeans(c1), colMeans(c2), colMeans(c3))) #make df for posterior probability table
colnames(df) <- c("Low", "Amotivation", "High", "class")
df <- df[, c("class", "Low", "Amotivation", "High" )] #reorder

p <- c("Low", "Amotivation", "High")
n <- as.character(c(length(m3$n[m3$classification==1]), length(m3$n[m3$classification==2]), length(m3$n[m3$classification==3]))) #get profile sizes
n2 <- as.character(round(as.numeric(n) / length(m3$classification) * 100))

df$class <- ifelse(df$class == 1, paste(p[1], " (N=", n[1], ", ", n2[1], "%", ")", sep = ""), ifelse(df$class == 2, paste(p[2], " (N=", n[2], ", ", n2[2], "%", ")", sep = ""), paste(p[3], " (N=", n[3], ", ", n2[3], "%", ")", sep = "")))

knitr::kable(df, digits=2, "html", caption="Membership probabilities in Wave 3") %>% #make table
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

<br>

## Step 2 

### Old 3-step approach

As a second step, we assign to each subject their profile membership. Through "the old 3-step approach" each subject's class membership is *determined* by their most likely class membership. However, this approach may be problematic, as it does not account for classification error, and thus may give biased estimates and standard errors with the relationships with other variables, and the transition probabilities (see [new approach](#new)).

```{r}
names(sms_long_nm)
```

### New 3-step approach {#new}
We created a nominal "most likely class" variable *N*, and a latent class variable *z*, which reflects the probability to belong to N. 




----

# LPTA

Given that the motivational profiles observed on the LPAs appeared fairly consistent across the waves, the next step is to use LPTA to describe respondents' change of motivational profiles across time. This allows us to examine the issue of consistency or change from an intraindividual perspective.



</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("lpta.Rmd");
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
