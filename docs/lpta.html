<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Latent Profile Transition Analysis</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
#rmd-source-code {
  display: none;
}
</style>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Motivation</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="lpa1.html">Exploring LPA</a>
</li>
<li>
  <a href="lpa2.html">CFA input</a>
</li>
<li>
  <a href="lpa3.html">Weighted sum scores</a>
</li>
<li>
  <a href="lpta.html">LPTA</a>
</li>
<li>
  <a href="site.html">Sources</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
<li role="separator" class="divider"></li>
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Latent Profile Transition Analysis</h1>

</div>


<p><br></p>
<p><em>Last edited: January 25, 2021</em></p>
<p><br></p>
<p>In the following, we will explore motivational profiles in the context of longitudinal data, using SDT as a theoretical framework. We will explore movement between motivational profiles over time.</p>
<p><br></p>
<div id="approach" class="section level2">
<h2>Approach</h2>
<p>First, we obtain weighted factor-scores for each SMS-subscale with CFA using MLE, as input for our subsequent LPA. Then, we use a three-step approach (see <a href="https://www.tandfonline.com/doi/pdf/10.1080/10705511.2014.915181">this article</a>; or the paper by <a href="https://www.sciencedirect.com/science/article/pii/S1469029219303851">Emm-Collison and colleagues</a> who used the same procedure).</p>
<hr />
</div>
<div id="preliminary-steps" class="section level1">
<h1>Preliminary steps</h1>
<div id="data" class="section level2">
<h2>1. Data</h2>
<p>Let’s get our ‘cleaned’ SMS-data, for each wave.</p>
<pre class="r"><code>library(sjlabelled)
library(dplyr)
library(tidyverse)
library(careless)
library(psych)

load(&quot;data_abs_public_v2.RData&quot;) # load data
data_abs_public &lt;- unlabel(data_abs_public, verbose=F) # unlabel

data_abs_public$id &lt;- 1:nrow(data_abs_public) # add identifier for subsequent LPTA

# subset sms data in each wave
sms_w1 &lt;- data_abs_public %&gt;% select(W1_M1_1, W1_M1_2, W1_M1_3, W1_M1_4, W1_M1_5, W1_M1_6, W1_M1_7, W1_M1_8, W1_M2_1, W1_M2_2, W1_M2_3, W1_M2_4, W1_M2_5, W1_M2_6, W1_M2_7, W1_M2_8, W1_M3_1, W1_M3_2, W1_M3_3, W1_M3_4, W1_M3_5, W1_M3_6, W1_M3_7, W1_M3_8, id)

sms_w2 &lt;- data_abs_public %&gt;% select(W2_M1_1, W2_M1_2, W2_M1_3, W2_M1_4, W2_M1_5, W2_M1_6, W2_M1_7, W2_M1_8, W2_M2_1, W2_M2_2, W2_M2_3, W2_M2_4, W2_M2_5, W2_M2_6, W2_M2_7, W2_M2_8, W2_M3_1, W2_M3_2, W2_M3_3, W2_M3_4, W2_M3_5, W2_M3_6, W2_M3_7, W2_M3_8, id) 

sms_w3 &lt;- data_abs_public %&gt;% select(W3_M1_1, W3_M1_2, W3_M1_3, W3_M1_4, W3_M1_5, W3_M1_6, W3_M1_7, W3_M1_8, W3_M2_1, W3_M2_2, W3_M2_3, W3_M2_4, W3_M2_5, W3_M2_6, W3_M2_7, W3_M2_8, W3_M3_1, W3_M3_2, W3_M3_3, W3_M3_4, W3_M3_5, W3_M3_6, W3_M3_7, W3_M3_8, id)

# make a &#39;string&#39; variable 
sms_w1 &lt;- sms_w1 %&gt;%
  mutate(string_w1 = longstring(.)) %&gt;%
  mutate(md_w1 = outlier(., plot = FALSE))

sms_w2 &lt;- sms_w2 %&gt;%
  mutate(string_w2 = longstring(.)) %&gt;%
  mutate(md_w2 = outlier(., plot = FALSE)) 

sms_w3 &lt;- sms_w3 %&gt;%
  mutate(string_w3 = longstring(.)) %&gt;%
  mutate(md_w3 = outlier(., plot = FALSE)) 

# cap string responding and use MD
cutoff_w1 &lt;- (qchisq(p = 1 - .001, df = (ncol(sms_w1) - 1)))
sms_w1 &lt;- sms_w1 %&gt;%
  filter(string_w1 &lt;= 10,
         md_w1 &lt; cutoff_w1) %&gt;%
  select(-string_w1, -md_w1)

  cutoff_w2 &lt;- (qchisq(p = 1 - .001, df = (ncol(sms_w2) - 1)))
sms_w2 &lt;- sms_w2 %&gt;%
  filter(string_w2 &lt;= 10,
         md_w2 &lt; cutoff_w2) %&gt;%
  select(-string_w2, -md_w2)

cutoff_w3 &lt;- (qchisq(p = 1 - .001, df = (ncol(sms_w3) - 1)))
sms_w3 &lt;- sms_w3 %&gt;%
  filter(string_w3 &lt;= 10,
         md_w3 &lt; cutoff_w3) %&gt;%
  select(-string_w3, -md_w3)</code></pre>
<p>Next, we are going to make a long file of the SMS data.</p>
<pre class="r"><code># first, make a wide format
sms_wide &lt;- merge(sms_w1, sms_w2, by = &quot;id&quot;) # first wave 1 and 2
sms_wide &lt;- merge(sms_wide, sms_w3, by = &quot;id&quot;) # add wave 3

# then transform into long shape
library(reshape2)
sms_long &lt;- reshape(sms_wide,
                    direction = &quot;long&quot;,
                    varying = c(list(names(sms_wide)[c(2, 26, 50)]),
                                     list(names(sms_wide)[c(3, 27, 51)]),
                                     list(names(sms_wide)[c(4, 28, 52)]),
                                     list(names(sms_wide)[c(5, 29, 53)]),
                                     list(names(sms_wide)[c(6, 30, 54)]),
                                     list(names(sms_wide)[c(7, 31, 55)]),
                                     list(names(sms_wide)[c(8, 32, 56)]),
                                     list(names(sms_wide)[c(9, 33, 57)]),
                                     list(names(sms_wide)[c(10, 34, 58)]),
                                     list(names(sms_wide)[c(11, 35, 59)]),
                                     list(names(sms_wide)[c(12, 36, 60)]),
                                     list(names(sms_wide)[c(13, 37, 61)]),
                                     list(names(sms_wide)[c(14, 38, 62)]),
                                     list(names(sms_wide)[c(15, 39, 63)]),
                                     list(names(sms_wide)[c(16, 40, 64)]),
                                     list(names(sms_wide)[c(17, 41, 65)]),
                                     list(names(sms_wide)[c(18, 42, 66)]),
                                     list(names(sms_wide)[c(19, 43, 67)]),
                                     list(names(sms_wide)[c(20, 44, 68)]),
                                     list(names(sms_wide)[c(21, 45, 69)]),
                                     list(names(sms_wide)[c(22, 46, 70)]),
                                     list(names(sms_wide)[c(23, 47, 71)]),
                                     list(names(sms_wide)[c(24, 48, 72)]),
                                     list(names(sms_wide)[c(25, 49, 73)])),
                    v.names = c(&quot;M1_1&quot;, &quot;M1_2&quot;, &quot;M1_3&quot;,&quot;M1_4&quot;, &quot;M1_5&quot;, &quot;M1_6&quot;, &quot;M1_7&quot;, &quot;M1_8&quot;, &quot;M2_1&quot;, &quot;M2_2&quot;, &quot;M2_3&quot;,&quot;M2_4&quot;, &quot;M2_5&quot;, &quot;M2_6&quot;, &quot;M2_7&quot;, &quot;M2_8&quot;, &quot;M3_1&quot;, &quot;M3_2&quot;, &quot;M3_3&quot;,&quot;M3_4&quot;, &quot;M3_5&quot;, &quot;M3_6&quot;, &quot;M3_7&quot;, &quot;M3_8&quot;),
                    idvar = &quot;id&quot;,
                    timevar = &quot;Timepoint&quot;,
                    times = 1:3)
# Reorder
sms_long  &lt;- sms_long [(order(sms_long$id)), ]
# fix(sms_long) to check data structure

sms_long_nm &lt;- sms_long %&gt;%
  na.omit() # listwise deletion</code></pre>
<p><br></p>
<hr />
</div>
<div id="cfa" class="section level2">
<h2>2. CFA</h2>
<p>First, confirmatory factor analysis using maximum likelihood estimation was conducted to obtain weighted factor scores for each SMS subscale. We first conduct CFA on the stacked data (hence assuming observations to be independent of each other). We will assess model fit using multiple indices. Afterwards, we will assess longitudinal invariance of the measurement model via a series of increasingly constraining models, indicating invariance by a change of CFI of ≤0.01.</p>
<div id="lavaan" class="section level3">
<h3>Lavaan</h3>
<p>Tell Lavaan the confirmatory structure.</p>
<pre class="r"><code>library(lavaan)

motivation_model &lt;- &quot;
amotivation =~ M1_5 + M2_4 + M3_1 + M3_6
external    =~ M1_4 + M2_3 + M3_3 + M3_8
introjected =~ M1_7 + M2_2 + M2_8 + M3_7
identified  =~ M1_3 + M1_8 + M2_7 + M3_4
integrated  =~ M1_2 + M2_1 + M2_5 + M3_5
intrinsic   =~ M1_1 + M1_6 + M2_6 + M3_2
&quot;</code></pre>
<p>Now let’s inspect the model. We will get the fit of the model, the (standardized) factor loadings, item averages (intercepts), error variances, and R-square scores. We will also make a table of the various fit indices.</p>
<pre class="r"><code># examine overall fit
overall.fit &lt;- cfa(model = motivation_model, data = sms_long_nm,
           meanstructure = TRUE,  # gives us the means
           std.lv = TRUE) 

summary(overall.fit, standardized = TRUE, rsquare = TRUE, fit.measure = TRUE)</code></pre>
<pre><code>## lavaan 0.6-7 ended normally after 35 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of free parameters                         87
##                                                       
##   Number of observations                          1613
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                              2288.748
##   Degrees of freedom                               237
##   P-value (Chi-square)                           0.000
## 
## Model Test Baseline Model:
## 
##   Test statistic                             15893.932
##   Degrees of freedom                               276
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    0.869
##   Tucker-Lewis Index (TLI)                       0.847
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)             -61124.030
##   Loglikelihood unrestricted model (H1)     -59979.656
##                                                       
##   Akaike (AIC)                              122422.060
##   Bayesian (BIC)                            122890.629
##   Sample-size adjusted Bayesian (BIC)       122614.246
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.073
##   90 Percent confidence interval - lower         0.071
##   90 Percent confidence interval - upper         0.076
##   P-value RMSEA &lt;= 0.05                          0.000
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.052
## 
## Parameter Estimates:
## 
##   Standard errors                             Standard
##   Information                                 Expected
##   Information saturated (h1) model          Structured
## 
## Latent Variables:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   amotivation =~                                                        
##     M1_5              0.350    0.013   26.464    0.000    0.350    0.693
##     M2_4              0.518    0.021   24.459    0.000    0.518    0.644
##     M3_1              0.332    0.013   25.136    0.000    0.332    0.661
##     M3_6              0.561    0.028   20.035    0.000    0.561    0.539
##   external =~                                                           
##     M1_4              1.038    0.034   30.211    0.000    1.038    0.711
##     M2_3              1.047    0.032   32.358    0.000    1.047    0.749
##     M3_3              0.982    0.040   24.700    0.000    0.982    0.606
##     M3_8              1.008    0.031   32.608    0.000    1.008    0.754
##   introjected =~                                                        
##     M1_7              0.890    0.032   27.633    0.000    0.890    0.659
##     M2_2              1.233    0.039   31.526    0.000    1.233    0.730
##     M2_8              1.195    0.036   33.425    0.000    1.195    0.762
##     M3_7              1.201    0.039   30.451    0.000    1.201    0.711
##   identified =~                                                         
##     M1_3              1.064    0.042   25.577    0.000    1.064    0.615
##     M1_8              1.132    0.041   27.594    0.000    1.132    0.655
##     M2_7              0.805    0.040   20.039    0.000    0.805    0.499
##     M3_4              1.005    0.039   25.644    0.000    1.005    0.617
##   integrated =~                                                         
##     M1_2              0.977    0.034   29.105    0.000    0.977    0.677
##     M2_1              1.256    0.039   31.990    0.000    1.256    0.726
##     M2_5              1.281    0.042   30.390    0.000    1.281    0.699
##     M3_5              1.353    0.036   37.316    0.000    1.353    0.811
##   intrinsic =~                                                          
##     M1_1              0.957    0.043   22.362    0.000    0.957    0.551
##     M1_6              1.242    0.041   30.076    0.000    1.242    0.699
##     M2_6              1.372    0.039   35.359    0.000    1.372    0.787
##     M3_2              1.301    0.039   33.388    0.000    1.301    0.755
## 
## Covariances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##   amotivation ~~                                                        
##     external          0.177    0.032    5.626    0.000    0.177    0.177
##     introjected       0.041    0.032    1.263    0.207    0.041    0.041
##     identified        0.020    0.035    0.576    0.564    0.020    0.020
##     integrated       -0.144    0.031   -4.582    0.000   -0.144   -0.144
##     intrinsic        -0.108    0.032   -3.398    0.001   -0.108   -0.108
##   external ~~                                                           
##     introjected       0.429    0.026   16.280    0.000    0.429    0.429
##     identified        0.746    0.021   36.077    0.000    0.746    0.746
##     integrated        0.511    0.024   21.147    0.000    0.511    0.511
##     intrinsic         0.595    0.022   26.691    0.000    0.595    0.595
##   introjected ~~                                                        
##     identified        0.626    0.024   25.966    0.000    0.626    0.626
##     integrated        0.766    0.017   46.429    0.000    0.766    0.766
##     intrinsic         0.508    0.024   20.749    0.000    0.508    0.508
##   identified ~~                                                         
##     integrated        0.788    0.019   41.754    0.000    0.788    0.788
##     intrinsic         0.898    0.016   56.925    0.000    0.898    0.898
##   integrated ~~                                                         
##     intrinsic         0.668    0.020   33.928    0.000    0.668    0.668
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .M1_5              1.153    0.013   91.727    0.000    1.153    2.284
##    .M2_4              1.353    0.020   67.608    0.000    1.353    1.683
##    .M3_1              1.162    0.013   92.890    0.000    1.162    2.313
##    .M3_6              1.464    0.026   56.517    0.000    1.464    1.407
##    .M1_4              2.382    0.036   65.537    0.000    2.382    1.632
##    .M2_3              2.033    0.035   58.449    0.000    2.033    1.455
##    .M3_3              2.569    0.040   63.703    0.000    2.569    1.586
##    .M3_8              2.049    0.033   61.509    0.000    2.049    1.532
##    .M1_7              5.399    0.034  160.581    0.000    5.399    3.998
##    .M2_2              4.623    0.042  109.890    0.000    4.623    2.736
##    .M2_8              5.270    0.039  134.943    0.000    5.270    3.360
##    .M3_7              4.806    0.042  114.194    0.000    4.806    2.843
##    .M1_3              3.098    0.043   71.912    0.000    3.098    1.791
##    .M1_8              3.565    0.043   82.885    0.000    3.565    2.064
##    .M2_7              2.466    0.040   61.357    0.000    2.466    1.528
##    .M3_4              4.467    0.041  110.087    0.000    4.467    2.741
##    .M1_2              5.154    0.036  143.373    0.000    5.154    3.570
##    .M2_1              4.333    0.043  100.582    0.000    4.333    2.504
##    .M2_5              3.272    0.046   71.684    0.000    3.272    1.785
##    .M3_5              4.975    0.042  119.695    0.000    4.975    2.980
##    .M1_1              3.996    0.043   92.388    0.000    3.996    2.300
##    .M1_6              3.805    0.044   85.993    0.000    3.805    2.141
##    .M2_6              4.084    0.043   94.103    0.000    4.084    2.343
##    .M3_2              3.493    0.043   81.460    0.000    3.493    2.028
##     amotivation       0.000                               0.000    0.000
##     external          0.000                               0.000    0.000
##     introjected       0.000                               0.000    0.000
##     identified        0.000                               0.000    0.000
##     integrated        0.000                               0.000    0.000
##     intrinsic         0.000                               0.000    0.000
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all
##    .M1_5              0.132    0.007   19.008    0.000    0.132    0.520
##    .M2_4              0.378    0.018   21.206    0.000    0.378    0.585
##    .M3_1              0.142    0.007   20.527    0.000    0.142    0.564
##    .M3_6              0.767    0.032   24.329    0.000    0.767    0.709
##    .M1_4              1.054    0.047   22.430    0.000    1.054    0.495
##    .M2_3              0.856    0.041   20.893    0.000    0.856    0.439
##    .M3_3              1.659    0.066   25.051    0.000    1.659    0.633
##    .M3_8              0.773    0.037   20.689    0.000    0.773    0.432
##    .M1_7              1.030    0.042   24.252    0.000    1.030    0.565
##    .M2_2              1.335    0.060   22.209    0.000    1.335    0.468
##    .M2_8              1.031    0.049   20.844    0.000    1.031    0.419
##    .M3_7              1.413    0.062   22.861    0.000    1.413    0.495
##    .M1_3              1.860    0.073   25.501    0.000    1.860    0.621
##    .M1_8              1.703    0.069   24.647    0.000    1.703    0.571
##    .M2_7              1.958    0.073   26.966    0.000    1.958    0.751
##    .M3_4              1.646    0.065   25.476    0.000    1.646    0.620
##    .M1_2              1.130    0.046   24.794    0.000    1.130    0.542
##    .M2_1              1.415    0.060   23.596    0.000    1.415    0.473
##    .M2_5              1.718    0.071   24.304    0.000    1.718    0.511
##    .M3_5              0.954    0.048   20.023    0.000    0.954    0.343
##    .M1_1              2.101    0.080   26.314    0.000    2.101    0.696
##    .M1_6              1.616    0.068   23.768    0.000    1.616    0.512
##    .M2_6              1.154    0.057   20.357    0.000    1.154    0.380
##    .M3_2              1.274    0.058   21.886    0.000    1.274    0.430
##     amotivation       1.000                               1.000    1.000
##     external          1.000                               1.000    1.000
##     introjected       1.000                               1.000    1.000
##     identified        1.000                               1.000    1.000
##     integrated        1.000                               1.000    1.000
##     intrinsic         1.000                               1.000    1.000
## 
## R-Square:
##                    Estimate
##     M1_5              0.480
##     M2_4              0.415
##     M3_1              0.436
##     M3_6              0.291
##     M1_4              0.505
##     M2_3              0.561
##     M3_3              0.367
##     M3_8              0.568
##     M1_7              0.435
##     M2_2              0.532
##     M2_8              0.581
##     M3_7              0.505
##     M1_3              0.379
##     M1_8              0.429
##     M2_7              0.249
##     M3_4              0.380
##     M1_2              0.458
##     M2_1              0.527
##     M2_5              0.489
##     M3_5              0.657
##     M1_1              0.304
##     M1_6              0.488
##     M2_6              0.620
##     M3_2              0.570</code></pre>
<pre class="r"><code># make table of fit indices
table_fit &lt;- matrix(NA, nrow = 11, ncol = 6)
colnames(table_fit) &lt;- c(&quot;Model&quot;, &quot;X2&quot;, &quot;df&quot;, &quot;CFI&quot;, &quot;RMSEA&quot;, &quot;SRMR&quot;)
table_fit[1, ] &lt;- c(&quot;Overall Model&quot;, round(fitmeasures(overall.fit, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))</code></pre>
<p><br></p>
<p>To check the confirmatory structure of our model, we will also create a picture of the standardized solution (quick and dirty; it can be edited…). The triangles depict the (standardized) intercepts, the arrows depic the variance (i.e. the loops) and (standardized) factor loadings.</p>
<pre class="r"><code>library(semPlot)
semPaths(overall.fit, whatLabels = &quot;std&quot;, layout = &quot;tree&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
<div id="longitudinal-invariance" class="section level3 tabset tabset-fade">
<h3>Longitudinal invariance</h3>
<p>Since we are dealing with panel data, and we want to explore movement over time in motivations, we should investigate to what extent our CFA solution is invariant over time (because we don’t want to compare apples with oranges). We will compare the SMS data of W1-W3 and compare them in CFA for configural, metric, scalar, and strict residual invariance (see e.g., <a href="https://www.tandfonline.com/doi/pdf/10.1207/S15328007SEM0902_5?casa_token=scyVPZRkncQAAAAA:PDDawXxC0BMvLu-kjcvtaFcHseZnO3rkwX4nJGtd8OrK-nuTq4B1Mk571ajpjaq3JQhasVHnyXtofdg">Cheung &amp; Rensvold 2002</a>).</p>
<p>We will use a new package for this. Apparently, this package only allows for multi-group equivalence testing for two groups (in Lavaan multiple groups can be compared); therefore, I will run the same procedure for each pair (i.e., W1 vs. W2, W2 vs. W3, and W1 vs. W3).</p>
<p>First, we will subset dataframes that only include two groups (i.e. waves) for comparison, for subsequent equivalence tests.</p>
<pre class="r"><code>W1_2 &lt;- ifelse(sms_long_nm$Timepoint == 1, 0, ifelse(sms_long_nm$Timepoint == 2, 1, NA))
sms12 &lt;- sms_long_nm[!is.na(W1_2), ] # compare w1 and w2

W2_3 &lt;- ifelse(sms_long_nm$Timepoint == 2, 0, ifelse(sms_long_nm$Timepoint == 3, 1, NA))
sms23 &lt;- sms_long_nm[!is.na(W2_3), ] # compare w2 and w3

W1_3 &lt;- ifelse(sms_long_nm$Timepoint == 1, 0, ifelse(sms_long_nm$Timepoint == 3, 1, NA))
sms13 &lt;- sms_long_nm[!is.na(W1_3), ] # compare w1 and w3</code></pre>
<p><br></p>
<div id="comparing-wave-1-and-wave-2" class="section level4">
<h4>Comparing Wave 1 and Wave 2</h4>
<pre class="r"><code>library(equaltestMI) #install package

# estimate the multi-group model
MG.model &lt;- eqMI.main(model = motivation_model, 
                      data = sms12, 
                      group = &quot;Timepoint&quot;, #comparing wave 1 and wave 2
                      meanstructure = TRUE, #include the means
                      output = &quot;both&quot;, #means, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, #test equality of latent factor means (even when equality of intercepts does not hold)
                      bootstrap = FALSE,
                      quiet = TRUE)</code></pre>
<p>Now we will summarize the results of the multi-group model, and add them to our previously made kable-table.</p>
<pre class="r"><code>table_fit[2, ] &lt;- c(&quot;W1 Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g1, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3)) # group 1: Wave 1
table_fit[3, ] &lt;- c(&quot;W2 Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g2, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3)) # group 2: Wave 2</code></pre>
<p>And to test for configural invariance - is the ‘picture’/structure of the model the same for both groups (i.e. waves), we stack the groups together.</p>
<pre class="r"><code>library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

table_fit[4, ] &lt;- c(&quot;Configural Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.combine.groups, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:4, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W2 Model
</td>
<td style="text-align:left;">
942.671
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.87
</td>
<td style="text-align:left;">
0.078
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1970.471
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.86
</td>
<td style="text-align:left;">
0.076
</td>
<td style="text-align:left;">
0.056
</td>
</tr>
</tbody>
</table>
<p>This is the model against which we will test the next model. So, we will conduct a sequential testing analysis. Next, we will assess metric invariance, by constraining the factor loadings to be equal across the waves. In the configural model, factor loadings were “freely” estimated in both waves; now, only 1 loading gets estimated for both groups. Let’s see what happens to the model.</p>
<pre class="r"><code>table_fit[5, ] &lt;- c(&quot;Metric Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.metric, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:5, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W2 Model
</td>
<td style="text-align:left;">
942.671
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.87
</td>
<td style="text-align:left;">
0.078
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1970.471
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.86
</td>
<td style="text-align:left;">
0.076
</td>
<td style="text-align:left;">
0.056
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
2000.526
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.859
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
</tbody>
</table>
<p>The metric model seems to be invariant in comparison to the configural model: the CFI difference is smaller than .01, hence assuming invariance (same holds for RMSEA/SRMR). Conclusion: the metric model holds: the loadings are equal (or close enough).</p>
<p><br></p>
<p>We have constrained our model to contain the same structure, the same loadings; now let’s test for scalar invariance, to see if the intercepts are the same across waves.</p>
<pre class="r"><code>table_fit[6, ] &lt;- c(&quot;Scalar Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.scalar, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:6, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W2 Model
</td>
<td style="text-align:left;">
942.671
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.87
</td>
<td style="text-align:left;">
0.078
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1970.471
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.86
</td>
<td style="text-align:left;">
0.076
</td>
<td style="text-align:left;">
0.056
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
2000.526
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.859
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
2058.927
</td>
<td style="text-align:left;">
510
</td>
<td style="text-align:left;">
0.855
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
</tbody>
</table>
<p>The intercepts are equal on the scale between the waves.</p>
<p><br></p>
<p>Last, we constrain the model to the strict model, to check for strict residual invariance. It will inform whether the variance around items is the same across time.</p>
<pre class="r"><code>table_fit[7, ] &lt;- c(&quot;Strict Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:7, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W2 Model
</td>
<td style="text-align:left;">
942.671
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.87
</td>
<td style="text-align:left;">
0.078
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1970.471
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.86
</td>
<td style="text-align:left;">
0.076
</td>
<td style="text-align:left;">
0.056
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
2000.526
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.859
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
2058.927
</td>
<td style="text-align:left;">
510
</td>
<td style="text-align:left;">
0.855
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
2244.226
</td>
<td style="text-align:left;">
534
</td>
<td style="text-align:left;">
0.84
</td>
<td style="text-align:left;">
0.076
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
</tbody>
</table>
<p>From here it goes downwards… CFI dropped more than 0.01, suggesting that the residuals vary between the waves. We could estimate partial invariance, to investigate where the problem is and subsequently update the model to fix it. We are going to do so by freeing the variances of item residuals, one at a time, to figure out which equality constaint(s) is/are causing the problem. We will use the following loop for this.</p>
<pre class="r"><code># write out partial codes
partial_syntax &lt;- paste(colnames(sms12)[3:26], #all sms columns
                        &quot;~~&quot;, #residuals
                        colnames(sms12)[3:26]) #all columns again

CFI_list &lt;- 1:length(partial_syntax)
names(CFI_list) &lt;- partial_syntax 

for (i in 1:length(partial_syntax)){
  
  temp &lt;- cfa(model = motivation_model,
              data = sms12,
              meanstructure = TRUE,
              group = &quot;Timepoint&quot;,
              group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;),
              group.partial = partial_syntax[i])
  
  CFI_list[i] &lt;- fitmeasures(temp, &quot;cfi&quot;)
}


# now figure out which parameters to &quot;free&quot;
options(scipen = 999)
sort(CFI_list - fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, &quot;cfi&quot;, decreasing = T))</code></pre>
<pre><code>##    M3_6 ~~ M3_6    M2_7 ~~ M2_7    M2_5 ~~ M2_5    M1_4 ~~ M1_4    M2_3 ~~ M2_3 
## -0.000082290662 -0.000058960801 -0.000032832743 -0.000032541893 -0.000005183615 
##    M2_2 ~~ M2_2    M1_3 ~~ M1_3    M3_3 ~~ M3_3    M1_2 ~~ M1_2    M3_7 ~~ M3_7 
##  0.000059935949  0.000097552492  0.000169704013  0.000197347141  0.000403961976 
##    M3_8 ~~ M3_8    M2_8 ~~ M2_8    M3_2 ~~ M3_2    M1_1 ~~ M1_1    M3_1 ~~ M3_1 
##  0.000470764870  0.000494901161  0.000508918212  0.000528129682  0.000583019923 
##    M3_4 ~~ M3_4    M2_6 ~~ M2_6    M1_8 ~~ M1_8    M1_5 ~~ M1_5    M3_5 ~~ M3_5 
##  0.000758607698  0.000785984138  0.000820321729  0.000832645274  0.001110952309 
##    M2_1 ~~ M2_1    M2_4 ~~ M2_4    M1_7 ~~ M1_7    M1_6 ~~ M1_6 
##  0.001114316894  0.001721097109  0.001819401556  0.003353923608</code></pre>
<p>Let’s free up those parameters. Starting with the one that increases CFI to the greatest extent. We will re-run the whole model for this</p>
<pre class="r"><code>MG.model_2 &lt;- eqMI.main(model = motivation_model, 
                      data = sms12, 
                      group = &quot;Timepoint&quot;, #comparing wave 1 and wave 2
                      meanstructure = TRUE,
                      group.partial = c(&quot;M1_6~~M1_6&quot;), #free this parameter
                      output = &quot;both&quot;, #mean, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, 
                      bootstrap = FALSE,
                      quiet = TRUE)

# check summary to see if the equality constraint is gone.
# summary(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals,
#        standardized = TRUE, rsquare = TRUE, fit.measure = TRUE)


table_fit[8, ] &lt;- c(&quot;Strict Model M1_6&quot;, round(fitmeasures(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:8, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W2 Model
</td>
<td style="text-align:left;">
942.671
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.87
</td>
<td style="text-align:left;">
0.078
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1970.471
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.86
</td>
<td style="text-align:left;">
0.076
</td>
<td style="text-align:left;">
0.056
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
2000.526
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.859
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
2058.927
</td>
<td style="text-align:left;">
510
</td>
<td style="text-align:left;">
0.855
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
2244.226
</td>
<td style="text-align:left;">
534
</td>
<td style="text-align:left;">
0.84
</td>
<td style="text-align:left;">
0.076
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model M1_6
</td>
<td style="text-align:left;">
2207.4
</td>
<td style="text-align:left;">
533
</td>
<td style="text-align:left;">
0.843
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
</tbody>
</table>
<p>CFI improved, but the difference with the baseline scalar model is still greater than .01. Thus, we still need to free (at least) one more, to achieve “partial” invariance.</p>
<pre class="r"><code>MG.model_3 &lt;- eqMI.main(model = motivation_model, 
                        data = sms12, 
                        group = &quot;Timepoint&quot;, #comparing wave 1 and wave 2
                        meanstructure = TRUE,
                        group.partial = c(&quot;M1_6~~M1_6&quot;, &quot;M1_7~~M1_7&quot;), #free these parameters
                        output = &quot;both&quot;, #mean, covariance, both
                        equivalence.test = FALSE, 
                        adjRMSEA = TRUE,
                        projection = TRUE, 
                        bootstrap = FALSE,
                        quiet = TRUE)

table_fit[9, ] &lt;- c(&quot;Strict Model M1_6 + M1_7&quot;, round(fitmeasures(MG.model_3$convention.sem$LavaanOut$fit.strict.residuals, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:9, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W2 Model
</td>
<td style="text-align:left;">
942.671
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.87
</td>
<td style="text-align:left;">
0.078
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1970.471
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.86
</td>
<td style="text-align:left;">
0.076
</td>
<td style="text-align:left;">
0.056
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
2000.526
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.859
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
2058.927
</td>
<td style="text-align:left;">
510
</td>
<td style="text-align:left;">
0.855
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
2244.226
</td>
<td style="text-align:left;">
534
</td>
<td style="text-align:left;">
0.84
</td>
<td style="text-align:left;">
0.076
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model M1_6
</td>
<td style="text-align:left;">
2207.4
</td>
<td style="text-align:left;">
533
</td>
<td style="text-align:left;">
0.843
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model M1_6 + M1_7
</td>
<td style="text-align:left;">
2186.956
</td>
<td style="text-align:left;">
532
</td>
<td style="text-align:left;">
0.845
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
</tbody>
</table>
</div>
<div id="comparing-wave-2-and-wave-3" class="section level4">
<h4>Comparing Wave 2 and Wave 3</h4>
<pre class="r"><code>library(equaltestMI) #install package

# estimate the multi-group model
MG.model &lt;- eqMI.main(model = motivation_model, 
                      data = sms23, 
                      group = &quot;Timepoint&quot;, #comparing wave 2 and wave 3
                      meanstructure = TRUE, #include the means
                      output = &quot;both&quot;, #means, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, #test equality of latent factor means (even when equality of intercepts does not hold)
                      bootstrap = FALSE,
                      quiet = TRUE)</code></pre>
<p>Now we will summarize the results of the multi-group model, and add them to our previously made kable-table.</p>
<pre class="r"><code>table_fit[2, ] &lt;- c(&quot;W2 Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g1, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3)) # group 1: Wave 2
table_fit[3, ] &lt;- c(&quot;W3 Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g2, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3)) # group 2: Wave 3</code></pre>
<p>And to test for configural invariance - is the ‘picture’/structure of the model the same for both groups (i.e. waves), we stack the groups together.</p>
<pre class="r"><code>library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

table_fit[4, ] &lt;- c(&quot;Configural Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.combine.groups, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:4, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W2 Model
</td>
<td style="text-align:left;">
942.671
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.87
</td>
<td style="text-align:left;">
0.078
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
W3 Model
</td>
<td style="text-align:left;">
815.651
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.883
</td>
<td style="text-align:left;">
0.069
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1758.323
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.876
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
</tbody>
</table>
<p>This is the model against which we will test the next model. So, we will conduct a sequential testing analysis. Next, we will assess metric invariance, by constraining the factor loadings to be equal across the waves. In the configural model, factor loadings were “freely” estimated in both waves; now, only 1 loading gets estimated for both groups. Let’s see what happens to the model.</p>
<pre class="r"><code>table_fit[5, ] &lt;- c(&quot;Metric Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.metric, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:5, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W2 Model
</td>
<td style="text-align:left;">
942.671
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.87
</td>
<td style="text-align:left;">
0.078
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
W3 Model
</td>
<td style="text-align:left;">
815.651
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.883
</td>
<td style="text-align:left;">
0.069
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1758.323
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.876
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
1849.122
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
</tbody>
</table>
<p>The metric model seems to be invariant in comparison to the configural model: the CFI difference is smaller than .01, hence assuming invariance (same holds for RMSEA/SRMR). Conclusion: the metric model holds: the loadings are equal (or close enough).</p>
<p><br></p>
<p>We have constrained our model to contain the same structure, the same loadings; now let’s test for scalar invariance, to see if the intercepts are the same across waves.</p>
<pre class="r"><code>table_fit[6, ] &lt;- c(&quot;Scalar Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.scalar, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:6, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W2 Model
</td>
<td style="text-align:left;">
942.671
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.87
</td>
<td style="text-align:left;">
0.078
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
W3 Model
</td>
<td style="text-align:left;">
815.651
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.883
</td>
<td style="text-align:left;">
0.069
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1758.323
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.876
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
1849.122
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
1877.602
</td>
<td style="text-align:left;">
510
</td>
<td style="text-align:left;">
0.868
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.062
</td>
</tr>
</tbody>
</table>
<p>The intercepts are equal on the scale between the waves.</p>
<p><br></p>
<p>Last, we constrain the model to the strict model, to check for strict residual invariance. It will inform whether the variance around items is the same across time.</p>
<pre class="r"><code>table_fit[7, ] &lt;- c(&quot;Strict Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:7, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W2 Model
</td>
<td style="text-align:left;">
942.671
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.87
</td>
<td style="text-align:left;">
0.078
</td>
<td style="text-align:left;">
0.058
</td>
</tr>
<tr>
<td style="text-align:left;">
W3 Model
</td>
<td style="text-align:left;">
815.651
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.883
</td>
<td style="text-align:left;">
0.069
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1758.323
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.876
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
1849.122
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.075
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
1877.602
</td>
<td style="text-align:left;">
510
</td>
<td style="text-align:left;">
0.868
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.062
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
1962.388
</td>
<td style="text-align:left;">
534
</td>
<td style="text-align:left;">
0.863
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.064
</td>
</tr>
</tbody>
</table>
</div>
<div id="comparing-wave-1-and-wave-3" class="section level4">
<h4>Comparing Wave 1 and Wave 3</h4>
<pre class="r"><code>library(equaltestMI) #install package

# estimate the multi-group model
MG.model &lt;- eqMI.main(model = motivation_model, 
                      data = sms13, 
                      group = &quot;Timepoint&quot;, #comparing wave 1 and wave 3
                      meanstructure = TRUE, #include the means
                      output = &quot;both&quot;, #means, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, #test equality of latent factor means (even when equality of intercepts does not hold)
                      bootstrap = FALSE,
                      quiet = TRUE)</code></pre>
<p>Now we will summarize the results of the multi-group model, and add them to our previously made kable-table.</p>
<pre class="r"><code>table_fit[2, ] &lt;- c(&quot;W1 Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g1, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3)) # group 1: Wave 1
table_fit[3, ] &lt;- c(&quot;W3 Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g2, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3)) # group 2: Wave 3</code></pre>
<p>And to test for configural invariance - is the ‘picture’/structure of the model the same for both groups (i.e. waves), we stack the groups together.</p>
<pre class="r"><code>library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

table_fit[4, ] &lt;- c(&quot;Configural Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.combine.groups, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:4, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W3 Model
</td>
<td style="text-align:left;">
815.651
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.883
</td>
<td style="text-align:left;">
0.069
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1843.45
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.866
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
</tbody>
</table>
<p>This is the model against which we will test the next model. So, we will conduct a sequential testing analysis. Next, we will assess metric invariance, by constraining the factor loadings to be equal across the waves. In the configural model, factor loadings were “freely” estimated in both waves; now, only 1 loading gets estimated for both groups. Let’s see what happens to the model.</p>
<pre class="r"><code>table_fit[5, ] &lt;- c(&quot;Metric Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.metric, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:5, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W3 Model
</td>
<td style="text-align:left;">
815.651
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.883
</td>
<td style="text-align:left;">
0.069
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1843.45
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.866
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
1928.678
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.859
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
</tbody>
</table>
<p>The metric model seems to be invariant in comparison to the configural model: the CFI difference is smaller than .01, hence assuming invariance (same holds for RMSEA/SRMR). Conclusion: the metric model holds: the loadings are equal (or close enough).</p>
<p><br></p>
<p>We have constrained our model to contain the same structure, the same loadings; now let’s test for scalar invariance, to see if the intercepts are the same across waves.</p>
<pre class="r"><code>table_fit[6, ] &lt;- c(&quot;Scalar Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.scalar, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:6, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W3 Model
</td>
<td style="text-align:left;">
815.651
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.883
</td>
<td style="text-align:left;">
0.069
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1843.45
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.866
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
1928.678
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.859
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
1992.647
</td>
<td style="text-align:left;">
510
</td>
<td style="text-align:left;">
0.855
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
</tbody>
</table>
<p>The intercepts are equal on the scale between the waves.</p>
<p><br></p>
<p>Last, we constrain the model to the strict model, to check for strict residual invariance. It will inform whether the variance around items is the same across time.</p>
<pre class="r"><code>table_fit[7, ] &lt;- c(&quot;Strict Model&quot;, round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:7, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W3 Model
</td>
<td style="text-align:left;">
815.651
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.883
</td>
<td style="text-align:left;">
0.069
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1843.45
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.866
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
1928.678
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.859
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
1992.647
</td>
<td style="text-align:left;">
510
</td>
<td style="text-align:left;">
0.855
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
2192.247
</td>
<td style="text-align:left;">
534
</td>
<td style="text-align:left;">
0.838
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.063
</td>
</tr>
</tbody>
</table>
<p>From here it goes downwards… CFI dropped more than 0.01, suggesting that the residuals vary between the waves. We could estimate partial invariance, to investigate where the problem is and subsequently update the model to fix it. We are going to do so by freeing the variances of item residuals, one at a time, to figure out which equality constaint(s) is/are causing the problem. We will use the following loop for this.</p>
<pre class="r"><code># write out partial codes
partial_syntax &lt;- paste(colnames(sms12)[3:26], #all sms columns
                        &quot;~~&quot;, #residuals
                        colnames(sms12)[3:26]) #all columns again

CFI_list &lt;- 1:length(partial_syntax)
names(CFI_list) &lt;- partial_syntax 

for (i in 1:length(partial_syntax)){
  
  temp &lt;- cfa(model = motivation_model,
              data = sms13,
              meanstructure = TRUE,
              group = &quot;Timepoint&quot;,
              group.equal = c(&quot;loadings&quot;, &quot;intercepts&quot;, &quot;residuals&quot;),
              group.partial = partial_syntax[i])
  
  CFI_list[i] &lt;- fitmeasures(temp, &quot;cfi&quot;)
}


# now figure out which parameters to &quot;free&quot;
options(scipen = 999)
sort(CFI_list - fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, &quot;cfi&quot;, decreasing = T))</code></pre>
<pre><code>##   M2_5 ~~ M2_5   M3_3 ~~ M3_3   M3_6 ~~ M3_6   M1_4 ~~ M1_4   M3_1 ~~ M3_1 
## -0.00008888957 -0.00006838485  0.00005127295  0.00006502869  0.00008372676 
##   M2_2 ~~ M2_2   M1_3 ~~ M1_3   M3_2 ~~ M3_2   M2_6 ~~ M2_6   M3_4 ~~ M3_4 
##  0.00013271294  0.00013945684  0.00014934295  0.00015002670  0.00018039173 
##   M2_7 ~~ M2_7   M2_3 ~~ M2_3   M3_8 ~~ M3_8   M1_1 ~~ M1_1   M3_7 ~~ M3_7 
##  0.00020506906  0.00020557911  0.00047290405  0.00057689755  0.00071190877 
##   M2_4 ~~ M2_4   M1_6 ~~ M1_6   M1_8 ~~ M1_8   M2_8 ~~ M2_8   M2_1 ~~ M2_1 
##  0.00082523798  0.00089462803  0.00092105420  0.00112432933  0.00122973447 
##   M1_2 ~~ M1_2   M1_5 ~~ M1_5   M3_5 ~~ M3_5   M1_7 ~~ M1_7 
##  0.00124553362  0.00183641423  0.00269219514  0.00393475648</code></pre>
<p>Let’s free up those parameters. Starting with the one that increases CFI to the greatest extent. We will re-run the whole model for this</p>
<pre class="r"><code>MG.model_2 &lt;- eqMI.main(model = motivation_model, 
                      data = sms13, 
                      group = &quot;Timepoint&quot;, #comparing wave 1 and wave 3
                      meanstructure = TRUE,
                      group.partial = c(&quot;M1_7~~M1_7&quot;), #free this parameter
                      output = &quot;both&quot;, #mean, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, 
                      bootstrap = FALSE,
                      quiet = TRUE)

# check summary to see if the equality constraint is gone.
# summary(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals,
#        standardized = TRUE, rsquare = TRUE, fit.measure = TRUE)


table_fit[8, ] &lt;- c(&quot;Strict Model M1_7&quot;, round(fitmeasures(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit[1:8, ] 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W3 Model
</td>
<td style="text-align:left;">
815.651
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.883
</td>
<td style="text-align:left;">
0.069
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1843.45
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.866
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
1928.678
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.859
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
1992.647
</td>
<td style="text-align:left;">
510
</td>
<td style="text-align:left;">
0.855
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
2192.247
</td>
<td style="text-align:left;">
534
</td>
<td style="text-align:left;">
0.838
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.063
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model M1_7
</td>
<td style="text-align:left;">
2151.056
</td>
<td style="text-align:left;">
533
</td>
<td style="text-align:left;">
0.842
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.062
</td>
</tr>
</tbody>
</table>
<p>CFI improved, but the difference with the baseline scalar model is still greater than .01. Thus, we still need to free (at least) one more, to achieve “partial” invariance.</p>
<pre class="r"><code>MG.model_3 &lt;- eqMI.main(model = motivation_model, 
                        data = sms13, 
                        group = &quot;Timepoint&quot;, #comparing wave 1 and wave 3
                        meanstructure = TRUE,
                        group.partial = c(&quot;M1_7~~M1_7&quot;, &quot;M3_5~~M3_5&quot;), #free these parameters
                        output = &quot;both&quot;, #mean, covariance, both
                        equivalence.test = FALSE, 
                        adjRMSEA = TRUE,
                        projection = TRUE, 
                        bootstrap = FALSE,
                        quiet = TRUE)

table_fit[9, ] &lt;- c(&quot;Strict Model M1_7 + M3_5&quot;, round(fitmeasures(MG.model_3$convention.sem$LavaanOut$fit.strict.residuals, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W3 Model
</td>
<td style="text-align:left;">
815.651
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.883
</td>
<td style="text-align:left;">
0.069
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1843.45
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.866
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
1928.678
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.859
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
1992.647
</td>
<td style="text-align:left;">
510
</td>
<td style="text-align:left;">
0.855
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
2192.247
</td>
<td style="text-align:left;">
534
</td>
<td style="text-align:left;">
0.838
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.063
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model M1_7
</td>
<td style="text-align:left;">
2151.056
</td>
<td style="text-align:left;">
533
</td>
<td style="text-align:left;">
0.842
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.062
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model M1_7 + M3_5
</td>
<td style="text-align:left;">
2122.571
</td>
<td style="text-align:left;">
532
</td>
<td style="text-align:left;">
0.844
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.062
</td>
</tr>
</tbody>
</table>
<p>Ditto</p>
<pre class="r"><code>MG.model_4 &lt;- eqMI.main(model = motivation_model, 
                        data = sms13, 
                        group = &quot;Timepoint&quot;, #comparing wave 1 and wave 3
                        meanstructure = TRUE,
                        group.partial = c(&quot;M1_7~~M1_7&quot;, &quot;M3_5~~M3_5&quot;, &quot;M1_5~~M1_5&quot;), #free these parameters
                        output = &quot;both&quot;, #mean, covariance, both
                        equivalence.test = FALSE, 
                        adjRMSEA = TRUE,
                        projection = TRUE, 
                        bootstrap = FALSE,
                        quiet = TRUE)

table_fit[9, ] &lt;- c(&quot;Strict Model M1_7 + M3_5 + M1_5&quot;, round(fitmeasures(MG.model_4$convention.sem$LavaanOut$fit.strict.residuals, c(&quot;chisq&quot;, &quot;df&quot;, &quot;cfi&quot;, &quot;rmsea&quot;, &quot;srmr&quot;)),3))

input &lt;- table_fit 
knitr::kable(input, digits=2, &quot;html&quot;, caption=&quot;&quot;) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Model
</th>
<th style="text-align:left;">
X2
</th>
<th style="text-align:left;">
df
</th>
<th style="text-align:left;">
CFI
</th>
<th style="text-align:left;">
RMSEA
</th>
<th style="text-align:left;">
SRMR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Overall Model
</td>
<td style="text-align:left;">
2288.748
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.869
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.052
</td>
</tr>
<tr>
<td style="text-align:left;">
W1 Model
</td>
<td style="text-align:left;">
1027.799
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.849
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.055
</td>
</tr>
<tr>
<td style="text-align:left;">
W3 Model
</td>
<td style="text-align:left;">
815.651
</td>
<td style="text-align:left;">
237
</td>
<td style="text-align:left;">
0.883
</td>
<td style="text-align:left;">
0.069
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Configural Model
</td>
<td style="text-align:left;">
1843.45
</td>
<td style="text-align:left;">
474
</td>
<td style="text-align:left;">
0.866
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.057
</td>
</tr>
<tr>
<td style="text-align:left;">
Metric Model
</td>
<td style="text-align:left;">
1928.678
</td>
<td style="text-align:left;">
492
</td>
<td style="text-align:left;">
0.859
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.059
</td>
</tr>
<tr>
<td style="text-align:left;">
Scalar Model
</td>
<td style="text-align:left;">
1992.647
</td>
<td style="text-align:left;">
510
</td>
<td style="text-align:left;">
0.855
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.06
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model
</td>
<td style="text-align:left;">
2192.247
</td>
<td style="text-align:left;">
534
</td>
<td style="text-align:left;">
0.838
</td>
<td style="text-align:left;">
0.074
</td>
<td style="text-align:left;">
0.063
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model M1_7
</td>
<td style="text-align:left;">
2151.056
</td>
<td style="text-align:left;">
533
</td>
<td style="text-align:left;">
0.842
</td>
<td style="text-align:left;">
0.073
</td>
<td style="text-align:left;">
0.062
</td>
</tr>
<tr>
<td style="text-align:left;">
Strict Model M1_7 + M3_5 + M1_5
</td>
<td style="text-align:left;">
2102.913
</td>
<td style="text-align:left;">
531
</td>
<td style="text-align:left;">
0.846
</td>
<td style="text-align:left;">
0.072
</td>
<td style="text-align:left;">
0.061
</td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<p>We can conclude that the SMS is mostly invariant - the structure, factor loadings, intercepts, and most of the error variances were equal across time.</p>
<p><br></p>
</div>
<div id="weighted-factor-scores" class="section level3">
<h3>Weighted factor-scores</h3>
<p>Now we use the invariant measurement model to generate (weighted) factor scores as input variables for the subsequent LPA. Weighted factor scores are computed by multiplying the factor loading of each item to the scaled score for each item before summing (see <a href="https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1226&amp;context=pare">DiStefano et al. (2009)</a>).</p>
<p>We will first fit the CFA, fixing the loading of the first variable of each variable to 1. Then we will extract the loadings, and calculate the weighted sum scores.</p>
<p><strong>Note</strong>: we now assumed strict measurement invariance (instead of strong), so we may want to free some parameters…</p>
<pre class="r"><code>fit &lt;- cfa(model = motivation_model, data = sms_long_nm,
           std.lv = FALSE) # default: not standardized but fixing the first loading on each latent variable to 1.
 
loading &lt;- parameterEstimates(fit)$est[1:24] # extract factor loadings

# calculate weighted sum scores
sms_long_nm$amotivation &lt;- rowMeans(cbind((sms_long_nm$M1_5*loading[1]), (sms_long_nm$M2_4*loading[2]), (sms_long_nm$M3_1*loading[3]), (sms_long_nm$M3_6*loading[4])))

sms_long_nm$external &lt;- rowMeans(cbind((sms_long_nm$M1_4*loading[5]), (sms_long_nm$M2_3*loading[6]), (sms_long_nm$M3_3*loading[7]),   (sms_long_nm$M3_8*loading[8])))

sms_long_nm$introjected &lt;- rowMeans(cbind((sms_long_nm$M1_7*loading[9]), (sms_long_nm$M2_2*loading[10]), (sms_long_nm$M2_8*loading[11]), (sms_long_nm$M3_7*loading[12])))

sms_long_nm$identified &lt;- rowMeans(cbind((sms_long_nm$M1_3*loading[13]), (sms_long_nm$M1_8*loading[14]), (sms_long_nm$M2_7*loading[15]), (sms_long_nm$M3_4*loading[16])))

sms_long_nm$integrated &lt;- rowMeans(cbind((sms_long_nm$M1_2*loading[17]), (sms_long_nm$M2_1*loading[18]), (sms_long_nm$M2_5*loading[19]), (sms_long_nm$M3_5*loading[20])))

sms_long_nm$intrinsic &lt;- rowMeans(cbind((sms_long_nm$M1_1*loading[21]), (sms_long_nm$M1_6*loading[22]), (sms_long_nm$M2_6*loading[23]), (sms_long_nm$M3_2*loading[24])))</code></pre>
<p><br></p>
<hr />
</div>
</div>
<div id="descriptives" class="section level2">
<h2>3. Descriptives</h2>
<p>Let’s describe our weighted factor scores over time.</p>
<pre class="r"><code>library(crosstable)

input &lt;- sms_long_nm %&gt;% #get factor scores and timepoint as grouping variable
  select(27:32, 2)

crosstable(input, by=Timepoint,
           funs=c(&quot;Mean&quot; = mean, &quot;Std. dev.&quot; = sd, &quot;Min&quot; = min, &quot;Max&quot; = max), funs_arg=list(digits=3)) %&gt;%
  as_flextable(by_header = &quot;Wave&quot;)</code></pre>
<template id="72d6d466-5b5c-4946-8e0a-d07bfc458b15"><style>
.tabwid table{
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  margin-top: 1.275em;
  margin-bottom: 1.275em;
  border-spacing: 0;
  border-color: transparent;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
</style><div class="tabwid"><style>.cl-6b9b9f18{border-collapse:collapse;}.cl-6b8713ae{font-family:'Arial';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6b8713af{font-family:'Arial';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6b873ab4{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-6b873ab5{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-6b87fdd2{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b87fdd3{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b87fdd4{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b87fdd5{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b87fdd6{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b87fdd7{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b87fdd8{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b87fdd9{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b87fdda{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b87fddb{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b87fddc{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8824ce{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8824cf{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8824d0{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8824d1{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8824d2{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8824d3{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8824d4{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8824d5{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8824d6{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8824d7{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8824d8{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8849ea{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8849eb{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8849ec{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8849ed{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8849ee{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8849ef{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8849f0{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8849f1{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8849f2{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8849f3{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8849f4{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8872da{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8872db{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8872dc{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8872dd{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8872de{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8872df{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8872e0{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1pt solid rgba(0, 0, 0, 1.00);border-top: 1pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8872e1{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8872e2{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8872e3{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b8872e4{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b88994a{width:48.1pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b88994b{width:63.9pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b88994c{width:49.3pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6b88994d{width:76.8pt;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}caption {color: #777;margin-top: 10px;margin-bottom: 10px;text-align: center;}</style><table class='cl-6b9b9f18'><thead><tr style="overflow-wrap:break-word;"><td  rowspan="2"class="cl-6b8872e3"><p class="cl-6b873ab4"><span class="cl-6b8713ae">label</span></p></td><td  rowspan="2"class="cl-6b8872e1"><p class="cl-6b873ab4"><span class="cl-6b8713ae">variable</span></p></td><td  colspan="3"class="cl-6b8872e4"><p class="cl-6b873ab4"><span class="cl-6b8713ae">Wave</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b88994c"><p class="cl-6b873ab5"><span class="cl-6b8713ae">1</span></p></td><td class="cl-6b88994a"><p class="cl-6b873ab5"><span class="cl-6b8713ae">2</span></p></td><td class="cl-6b88994a"><p class="cl-6b873ab5"><span class="cl-6b8713ae">3</span></p></td></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-6b87fdd3"><p class="cl-6b873ab5"><span class="cl-6b8713af">amotivation</span></p></td><td class="cl-6b87fdd4"><p class="cl-6b873ab5"><span class="cl-6b8713af">Mean</span></p></td><td class="cl-6b87fdd5"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.584</span></p></td><td class="cl-6b87fdd2"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.655</span></p></td><td class="cl-6b87fdd2"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.730</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b87fdd8"><p class="cl-6b873ab5"><span class="cl-6b8713af">Std. dev.</span></p></td><td class="cl-6b87fdd7"><p class="cl-6b873ab5"><span class="cl-6b8713af">0.657</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">0.736</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">0.808</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b87fdda"><p class="cl-6b873ab5"><span class="cl-6b8713af">Min</span></p></td><td class="cl-6b8824ce"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.258</span></p></td><td class="cl-6b87fddc"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.258</span></p></td><td class="cl-6b87fddc"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.258</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b8872dd"><p class="cl-6b873ab5"><span class="cl-6b8713af">Max</span></p></td><td class="cl-6b8872df"><p class="cl-6b873ab5"><span class="cl-6b8713af">5.833</span></p></td><td class="cl-6b8872de"><p class="cl-6b873ab5"><span class="cl-6b8713af">5.346</span></p></td><td class="cl-6b8872de"><p class="cl-6b873ab5"><span class="cl-6b8713af">5.609</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-6b8872e0"><p class="cl-6b873ab5"><span class="cl-6b8713af">external</span></p></td><td class="cl-6b8849ed"><p class="cl-6b873ab5"><span class="cl-6b8713af">Mean</span></p></td><td class="cl-6b8849ef"><p class="cl-6b873ab5"><span class="cl-6b8713af">2.058</span></p></td><td class="cl-6b8849ec"><p class="cl-6b873ab5"><span class="cl-6b8713af">2.291</span></p></td><td class="cl-6b8849ec"><p class="cl-6b873ab5"><span class="cl-6b8713af">2.328</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b87fdd8"><p class="cl-6b873ab5"><span class="cl-6b8713af">Std. dev.</span></p></td><td class="cl-6b87fdd7"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.029</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.147</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.166</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b87fdda"><p class="cl-6b873ab5"><span class="cl-6b8713af">Min</span></p></td><td class="cl-6b8824ce"><p class="cl-6b873ab5"><span class="cl-6b8713af">0.981</span></p></td><td class="cl-6b87fddc"><p class="cl-6b873ab5"><span class="cl-6b8713af">0.981</span></p></td><td class="cl-6b87fddc"><p class="cl-6b873ab5"><span class="cl-6b8713af">0.981</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b8872dd"><p class="cl-6b873ab5"><span class="cl-6b8713af">Max</span></p></td><td class="cl-6b8872df"><p class="cl-6b873ab5"><span class="cl-6b8713af">5.646</span></p></td><td class="cl-6b8872de"><p class="cl-6b873ab5"><span class="cl-6b8713af">5.889</span></p></td><td class="cl-6b8872de"><p class="cl-6b873ab5"><span class="cl-6b8713af">6.132</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-6b8849eb"><p class="cl-6b873ab5"><span class="cl-6b8713af">introjected</span></p></td><td class="cl-6b8824d8"><p class="cl-6b873ab5"><span class="cl-6b8713af">Mean</span></p></td><td class="cl-6b8849ea"><p class="cl-6b873ab5"><span class="cl-6b8713af">6.109</span></p></td><td class="cl-6b8824d7"><p class="cl-6b873ab5"><span class="cl-6b8713af">6.329</span></p></td><td class="cl-6b8824d7"><p class="cl-6b873ab5"><span class="cl-6b8713af">6.633</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b87fdd8"><p class="cl-6b873ab5"><span class="cl-6b8713af">Std. dev.</span></p></td><td class="cl-6b87fdd7"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.693</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.633</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.468</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b87fdda"><p class="cl-6b873ab5"><span class="cl-6b8713af">Min</span></p></td><td class="cl-6b8824ce"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.519</span></p></td><td class="cl-6b87fddc"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.519</span></p></td><td class="cl-6b87fddc"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.519</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b8824d0"><p class="cl-6b873ab5"><span class="cl-6b8713af">Max</span></p></td><td class="cl-6b8824d1"><p class="cl-6b873ab5"><span class="cl-6b8713af">8.884</span></p></td><td class="cl-6b8824cf"><p class="cl-6b873ab5"><span class="cl-6b8713af">8.884</span></p></td><td class="cl-6b8824cf"><p class="cl-6b873ab5"><span class="cl-6b8713af">8.884</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-6b8824d5"><p class="cl-6b873ab5"><span class="cl-6b8713af">identified</span></p></td><td class="cl-6b8824d3"><p class="cl-6b873ab5"><span class="cl-6b8713af">Mean</span></p></td><td class="cl-6b8824d6"><p class="cl-6b873ab5"><span class="cl-6b8713af">3.064</span></p></td><td class="cl-6b8824d4"><p class="cl-6b873ab5"><span class="cl-6b8713af">3.355</span></p></td><td class="cl-6b8824d4"><p class="cl-6b873ab5"><span class="cl-6b8713af">3.354</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b87fdd8"><p class="cl-6b873ab5"><span class="cl-6b8713af">Std. dev.</span></p></td><td class="cl-6b87fdd7"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.131</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.190</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.107</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b87fdda"><p class="cl-6b873ab5"><span class="cl-6b8713af">Min</span></p></td><td class="cl-6b8824ce"><p class="cl-6b873ab5"><span class="cl-6b8713af">0.941</span></p></td><td class="cl-6b87fddc"><p class="cl-6b873ab5"><span class="cl-6b8713af">0.941</span></p></td><td class="cl-6b87fddc"><p class="cl-6b873ab5"><span class="cl-6b8713af">0.941</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b8824d0"><p class="cl-6b873ab5"><span class="cl-6b8713af">Max</span></p></td><td class="cl-6b8824d1"><p class="cl-6b873ab5"><span class="cl-6b8713af">6.587</span></p></td><td class="cl-6b8824cf"><p class="cl-6b873ab5"><span class="cl-6b8713af">6.587</span></p></td><td class="cl-6b8824cf"><p class="cl-6b873ab5"><span class="cl-6b8713af">6.587</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-6b8849eb"><p class="cl-6b873ab5"><span class="cl-6b8713af">integrated</span></p></td><td class="cl-6b8824d8"><p class="cl-6b873ab5"><span class="cl-6b8713af">Mean</span></p></td><td class="cl-6b8849ea"><p class="cl-6b873ab5"><span class="cl-6b8713af">5.162</span></p></td><td class="cl-6b8824d7"><p class="cl-6b873ab5"><span class="cl-6b8713af">5.613</span></p></td><td class="cl-6b8824d7"><p class="cl-6b873ab5"><span class="cl-6b8713af">5.737</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b87fdd8"><p class="cl-6b873ab5"><span class="cl-6b8713af">Std. dev.</span></p></td><td class="cl-6b87fdd7"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.701</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.704</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.619</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b87fdda"><p class="cl-6b873ab5"><span class="cl-6b8713af">Min</span></p></td><td class="cl-6b8824ce"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.246</span></p></td><td class="cl-6b87fddc"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.592</span></p></td><td class="cl-6b87fddc"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.246</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b8824d0"><p class="cl-6b873ab5"><span class="cl-6b8713af">Max</span></p></td><td class="cl-6b8824d1"><p class="cl-6b873ab5"><span class="cl-6b8713af">8.722</span></p></td><td class="cl-6b8824cf"><p class="cl-6b873ab5"><span class="cl-6b8713af">8.722</span></p></td><td class="cl-6b8824cf"><p class="cl-6b873ab5"><span class="cl-6b8713af">8.722</span></p></td></tr><tr style="overflow-wrap:break-word;"><td  rowspan="4"class="cl-6b8849ee"><p class="cl-6b873ab5"><span class="cl-6b8713af">intrinsic</span></p></td><td class="cl-6b8849ed"><p class="cl-6b873ab5"><span class="cl-6b8713af">Mean</span></p></td><td class="cl-6b8849ef"><p class="cl-6b873ab5"><span class="cl-6b8713af">4.623</span></p></td><td class="cl-6b8849ec"><p class="cl-6b873ab5"><span class="cl-6b8713af">5.025</span></p></td><td class="cl-6b8849ec"><p class="cl-6b873ab5"><span class="cl-6b8713af">5.066</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b87fdd8"><p class="cl-6b873ab5"><span class="cl-6b8713af">Std. dev.</span></p></td><td class="cl-6b87fdd7"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.762</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.770</span></p></td><td class="cl-6b87fdd6"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.678</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b8849f1"><p class="cl-6b873ab5"><span class="cl-6b8713af">Min</span></p></td><td class="cl-6b8849f3"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.272</span></p></td><td class="cl-6b8849f0"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.272</span></p></td><td class="cl-6b8849f0"><p class="cl-6b873ab5"><span class="cl-6b8713af">1.272</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6b8872da"><p class="cl-6b873ab5"><span class="cl-6b8713af">Max</span></p></td><td class="cl-6b8872dc"><p class="cl-6b873ab5"><span class="cl-6b8713af">8.906</span></p></td><td class="cl-6b8849f4"><p class="cl-6b873ab5"><span class="cl-6b8713af">8.906</span></p></td><td class="cl-6b8849f4"><p class="cl-6b873ab5"><span class="cl-6b8713af">8.582</span></p></td></tr></tbody></table></div></template>
<div id="5ebd4924-6c0f-4d85-a7a5-b317b2b242e6"></div>
<script>
var dest = document.getElementById("5ebd4924-6c0f-4d85-a7a5-b317b2b242e6");
var template = document.getElementById("72d6d466-5b5c-4946-8e0a-d07bfc458b15");
var caption = template.content.querySelector("caption");
if(caption) {
  caption.style.cssText = "display:block;text-align:center;";
  var newcapt = document.createElement("p");
  newcapt.appendChild(caption)
  dest.parentNode.insertBefore(newcapt, dest.previousSibling);
}
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
</script>

<p>And let’s see how many respondents we have in each wave (<strong>note-to-self</strong>: integrate in previous table…).</p>
<pre class="r"><code>knitr::kable(table(sms_long_nm$Timepoint), &quot;html&quot;, caption=&quot;Number of respondents in each wave&quot;, col.names = c(&quot;Wave&quot;, &quot;N&quot;), align = &#39;l&#39; ) %&gt;% 
  kableExtra::kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;))</code></pre>
<table class="table table-striped table-hover" style="margin-left: auto; margin-right: auto;">
<caption>
Number of respondents in each wave
</caption>
<thead>
<tr>
<th style="text-align:left;">
Wave
</th>
<th style="text-align:left;">
N
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
621
</td>
</tr>
<tr>
<td style="text-align:left;">
2
</td>
<td style="text-align:left;">
486
</td>
</tr>
<tr>
<td style="text-align:left;">
3
</td>
<td style="text-align:left;">
506
</td>
</tr>
</tbody>
</table>
<p>At face value, respondents seem to be pretty high in all types of motivation (e.g., compared with the sample of <a href="https://www.sciencedirect.com/science/article/pii/S1469029219303851">Emm-Collison and colleagues</a> - though these were sum scores).</p>
<p><br></p>
<hr />
</div>
</div>
<div id="lpa" class="section level1">
<h1>LPA</h1>
<div id="step-1" class="section level2">
<h2>Step 1</h2>
<div id="section" class="section level3 tabset tabset-fade">
<h3></h3>
<p>As a first step for the LPA, we carefully select a measurement model that accurately captures the construct of motivational profile. We will fit a series of measurement models for each wave to determine which model provides the best fit at each wave (following recommendations of <a href="https://srcd.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-8624.2007.01097.x?casa_token=0wyzjh9Ozk0AAAAA:iasgTYid_gJ5kGH42Jyys61DsBhEDl0zxVrukoJdaeX2e2MGOlm1nfyooEUc1v5SaB3lFYyX1wqVLGNOvQ">Nylund et al. (2007)</a> and similar to the article by <a href="https://www.tandfonline.com/doi/pdf/10.1080/10413200.2014.993485?casa_token=CsBgfG9lbtgAAAAA:CMEXxc96xNC-rF6Sowi7X2X0qvXlxI9MuODWtQ1Db92UyZUeLZcWJem1jhhympbi8dBboyrA282A5Ns">Martinent &amp; Decret (2015)</a>).</p>
<p><br></p>
<div id="wave-1" class="section level4">
<h4>Wave 1</h4>
<p>We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).</p>
<pre class="r"><code>sms_w1 &lt;- sms_long_nm[sms_long_nm$Timepoint==1, ] %&gt;%
  select(-Timepoint, -id) %&gt;% # subset W1
  select(25:30) %&gt;% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators</code></pre>
<p>We then compute the model-based clustering, and ask for a summary.</p>
<pre class="r"><code>library(mclust)
mc &lt;- Mclust(sms_w1)
summary(mc)                 </code></pre>
<pre><code>## ---------------------------------------------------- 
## Gaussian finite mixture model fitted by EM algorithm 
## ---------------------------------------------------- 
## 
## Mclust EEV (ellipsoidal, equal volume and shape) model with 9 components: 
## 
##  log-likelihood   n  df       BIC       ICL
##       -3502.994 621 203 -8311.547 -8564.225
## 
## Clustering table:
##   1   2   3   4   5   6   7   8   9 
## 195  52  47  19  29  71  71  87  50</code></pre>
<p>For this wave, Mclust selected a model with 9 (!) profiles; the optimal selected model is EEV, i.e., the profiles are ellipsoidal with equal volume, shape and varying orientation (see <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/">this article</a>). However, note that VEV, 9 is only slightly behind, and that for all solutions with fewer clusters, the VEV model fitted better.</p>
<p>Now we will access to the results and visualize the model. To visualize, we will use a new package (<em>factoextra</em>), to create nicer plots based on ggplot2.</p>
<pre class="r"><code>library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, &quot;BIC&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
</div>
<div id="wave-2" class="section level4">
<h4>Wave 2</h4>
<p>We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).</p>
<pre class="r"><code>sms_w2 &lt;- sms_long_nm[sms_long_nm$Timepoint==2, ] %&gt;%
  select(-Timepoint, -id) %&gt;% # subset W2
  select(25:30) %&gt;% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators</code></pre>
<p>We then compute the model-based clustering, and ask for a summary.</p>
<pre class="r"><code>library(mclust)
mc &lt;- Mclust(sms_w2)
summary(mc)                 </code></pre>
<pre><code>## ---------------------------------------------------- 
## Gaussian finite mixture model fitted by EM algorithm 
## ---------------------------------------------------- 
## 
## Mclust VEV (ellipsoidal, equal shape) model with 7 components: 
## 
##  log-likelihood   n  df       BIC       ICL
##       -2750.539 486 165 -6521.803 -6588.722
## 
## Clustering table:
##   1   2   3   4   5   6   7 
##  56 124  59  22 152  45  28</code></pre>
<p>For this wave, Mclust selected a model with 7 (!) profiles; the optimal selected model is VEV, i.e., the profiles are ellipsoidal with equal shape (see <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/">this article</a>).</p>
<p>Now we will access to the results and visualize the model. To visualize, we will use a new package (<em>factoextra</em>), to create nicer plots based on ggplot2.</p>
<pre class="r"><code>library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, &quot;BIC&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
</div>
<div id="wave-3" class="section level4">
<h4>Wave 3</h4>
<p>We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).</p>
<pre class="r"><code>sms_w3 &lt;- sms_long_nm[sms_long_nm$Timepoint==3, ] %&gt;%
  select(-Timepoint, -id) %&gt;% # subset W1
  select(25:30) %&gt;% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators</code></pre>
<p>We then compute the model-based clustering, and ask for a summary.</p>
<pre class="r"><code>library(mclust)
mc &lt;- Mclust(sms_w3)
summary(mc)                 </code></pre>
<pre><code>## ---------------------------------------------------- 
## Gaussian finite mixture model fitted by EM algorithm 
## ---------------------------------------------------- 
## 
## Mclust VEV (ellipsoidal, equal shape) model with 9 components: 
## 
##  log-likelihood   n  df       BIC       ICL
##       -2838.908 506 211 -6991.614 -7076.572
## 
## Clustering table:
##   1   2   3   4   5   6   7   8   9 
##  34  58  43  22  60  34  36 172  47</code></pre>
<p>For this wave, Mclust selected a model with 9 (!) profiles; the optimal selected model is VEV, i.e., the profiles are ellipsoidal with equal shape (see <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/">this article</a>).</p>
<pre class="r"><code>library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, &quot;BIC&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
</div>
</div>
<div id="section-1" class="section level3 tabset tabset-fade">
<h3></h3>
<p>We will examine a sequence of models, with an increasing number of profiles from 2 to …, to ascertain whether more complex (i.e. more profiles) or parsimonious (i.e. fewer profiles) models provided the best description of the data. We will use the VEV model (varying volume, equal shape, varying orientation).</p>
<p>We will plot the profile means, the clustering and the clustering uncertainty. If the data contain more than two variables (which is the case in our data), the <em>fviz_mclust()</em>-function will use PCA to reduce the dimensionality of the data. The first two principal components are used to produce a scatter plot of the data. If we want to plot the data using only two variables (e.g., <em>external regulation</em> and <em>intrinsic motivation</em>), we can specify that in the function using the argument <em>choose.vars = c(“external”, “intrinsic”)</em>. Note that, in the uncertainty plot, larger symbols indicate the more uncertain observations.</p>
<p><br></p>
<div id="wave-1-1" class="section level4">
<h4>Wave 1</h4>
<div id="section-2" class="section level5 tabset tabset-fade">
<h5></h5>
<div id="profiles" class="section level6">
<h6>2 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w1) 
m2 &lt;- Mclust(sms_w1, modelNames = &quot;VEV&quot;, G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m2, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-44-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m2, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-44-3.png" width="672" /></p>
</div>
<div id="profiles-1" class="section level6">
<h6>3 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w1) 
m3 &lt;- Mclust(sms_w1, modelNames = &quot;VEV&quot;, G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-45-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m3, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-45-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m3, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-45-3.png" width="672" /></p>
</div>
<div id="profiles-2" class="section level6">
<h6>4 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w1) 
m4 &lt;- Mclust(sms_w1, modelNames = &quot;VEV&quot;, G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m4, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-46-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m4, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-46-3.png" width="672" /></p>
</div>
<div id="profiles-3" class="section level6">
<h6>5 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w1) 
m5 &lt;- Mclust(sms_w1, modelNames = &quot;VEV&quot;, G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-47-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m5, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-47-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m5, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-47-3.png" width="672" /></p>
</div>
</div>
</div>
<div id="wave-2-1" class="section level4">
<h4>Wave 2</h4>
<div id="section-3" class="section level5 tabset tabset-fade">
<h5></h5>
<div id="profiles-4" class="section level6">
<h6>2 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w2) 
m2 &lt;- Mclust(sms_w2, modelNames = &quot;VEV&quot;, G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m2, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-48-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m2, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-48-3.png" width="672" /></p>
</div>
<div id="profiles-5" class="section level6">
<h6>3 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w2) 
m3 &lt;- Mclust(sms_w2, modelNames = &quot;VEV&quot;, G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m3, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-49-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m3, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-49-3.png" width="672" /></p>
</div>
<div id="profiles-6" class="section level6">
<h6>4 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w2) 
m4 &lt;- Mclust(sms_w2, modelNames = &quot;VEV&quot;, G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m4, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-50-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m4, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-50-3.png" width="672" /></p>
</div>
<div id="profiles-7" class="section level6">
<h6>5 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w2) 
m5 &lt;- Mclust(sms_w2, modelNames = &quot;VEV&quot;, G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m5, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-51-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m5, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-51-3.png" width="672" /></p>
</div>
</div>
</div>
<div id="wave-3-1" class="section level4">
<h4>Wave 3</h4>
<div id="section-4" class="section level5 tabset tabset-fade">
<h5></h5>
<div id="profiles-8" class="section level6">
<h6>2 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w3) 
m2 &lt;- Mclust(sms_w3, modelNames = &quot;VEV&quot;, G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m2, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-52-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m2, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-52-3.png" width="672" /></p>
</div>
<div id="profiles-9" class="section level6">
<h6>3 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w3) 
m3 &lt;- Mclust(sms_w3, modelNames = &quot;VEV&quot;, G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m3, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-53-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m3, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-53-3.png" width="672" /></p>
</div>
<div id="profiles-10" class="section level6">
<h6>4 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w3) 
m4 &lt;- Mclust(sms_w3, modelNames = &quot;VEV&quot;, G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m4, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-54-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m4, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-54-3.png" width="672" /></p>
</div>
<div id="profiles-11" class="section level6">
<h6>5 profiles</h6>
<pre class="r fold-hide"><code>library(mclust)

BIC &lt;- mclustBIC(sms_w3) 
m5 &lt;- Mclust(sms_w3, modelNames = &quot;VEV&quot;, G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means &lt;- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %&gt;%
  rownames_to_column() %&gt;%
  rename(Motivation = rowname) %&gt;%
  melt(id.vars = &quot;Motivation&quot;, variable.name = &quot;Profile&quot;, value.name = &quot;Mean&quot;) %&gt;%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %&gt;%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c(&quot;amotivation&quot;, &quot;external&quot;, &quot;introjected&quot;, &quot;identified&quot;, &quot;integrated&quot;, &quot;intrinsic&quot;)) +
  labs(x = NULL, y = &quot;Standardized mean weighted factor-scores&quot;) +
  scale_colour_manual(values=c(&quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#E69F00&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;)) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;top&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<pre class="r fold-hide"><code>library(factoextra)

# Plot showing the clustering
fviz_mclust(m5, &quot;classification&quot;, geom = &quot;point&quot;,
            pointsize = 1.5, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-55-2.png" width="672" /></p>
<pre class="r fold-hide"><code># Plot showing the clustering uncertainty
fviz_mclust(m5, &quot;uncertainty&quot;, palette = &quot;jco&quot;)</code></pre>
<p><img src="lpta_files/figure-html/unnamed-chunk-55-3.png" width="672" /></p>
</div>
</div>
</div>
</div>
</div>
</div>

<div id="rmd-source-code">---
title: "Latent Profile Transition Analysis"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 3
    code_folding: show
    code_download: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```


<br>

*Last edited: January 25, 2021*

<br>

In the following, we will explore motivational profiles in the context of longitudinal data, using SDT as a theoretical framework. We will explore movement between motivational profiles over time.

<br>

## Approach

First, we obtain weighted factor-scores for each SMS-subscale with CFA using MLE, as input for our subsequent LPA. Then, we use a three-step approach (see [this article](https://www.tandfonline.com/doi/pdf/10.1080/10705511.2014.915181); or the paper by [Emm-Collison and colleagues](https://www.sciencedirect.com/science/article/pii/S1469029219303851) who used the same procedure).


---

# Preliminary steps

## 1. Data

Let's get our 'cleaned' SMS-data, for each wave.

```{r, warning=FALSE, message=FALSE}
library(sjlabelled)
library(dplyr)
library(tidyverse)
library(careless)
library(psych)

load("data_abs_public_v2.RData") # load data
data_abs_public <- unlabel(data_abs_public, verbose=F) # unlabel

data_abs_public$id <- 1:nrow(data_abs_public) # add identifier for subsequent LPTA

# subset sms data in each wave
sms_w1 <- data_abs_public %>% select(W1_M1_1, W1_M1_2, W1_M1_3, W1_M1_4, W1_M1_5, W1_M1_6, W1_M1_7, W1_M1_8, W1_M2_1, W1_M2_2, W1_M2_3, W1_M2_4, W1_M2_5, W1_M2_6, W1_M2_7, W1_M2_8, W1_M3_1, W1_M3_2, W1_M3_3, W1_M3_4, W1_M3_5, W1_M3_6, W1_M3_7, W1_M3_8, id)

sms_w2 <- data_abs_public %>% select(W2_M1_1, W2_M1_2, W2_M1_3, W2_M1_4, W2_M1_5, W2_M1_6, W2_M1_7, W2_M1_8, W2_M2_1, W2_M2_2, W2_M2_3, W2_M2_4, W2_M2_5, W2_M2_6, W2_M2_7, W2_M2_8, W2_M3_1, W2_M3_2, W2_M3_3, W2_M3_4, W2_M3_5, W2_M3_6, W2_M3_7, W2_M3_8, id) 

sms_w3 <- data_abs_public %>% select(W3_M1_1, W3_M1_2, W3_M1_3, W3_M1_4, W3_M1_5, W3_M1_6, W3_M1_7, W3_M1_8, W3_M2_1, W3_M2_2, W3_M2_3, W3_M2_4, W3_M2_5, W3_M2_6, W3_M2_7, W3_M2_8, W3_M3_1, W3_M3_2, W3_M3_3, W3_M3_4, W3_M3_5, W3_M3_6, W3_M3_7, W3_M3_8, id)

# make a 'string' variable 
sms_w1 <- sms_w1 %>%
  mutate(string_w1 = longstring(.)) %>%
  mutate(md_w1 = outlier(., plot = FALSE))

sms_w2 <- sms_w2 %>%
  mutate(string_w2 = longstring(.)) %>%
  mutate(md_w2 = outlier(., plot = FALSE)) 

sms_w3 <- sms_w3 %>%
  mutate(string_w3 = longstring(.)) %>%
  mutate(md_w3 = outlier(., plot = FALSE)) 

# cap string responding and use MD
cutoff_w1 <- (qchisq(p = 1 - .001, df = (ncol(sms_w1) - 1)))
sms_w1 <- sms_w1 %>%
  filter(string_w1 <= 10,
         md_w1 < cutoff_w1) %>%
  select(-string_w1, -md_w1)

  cutoff_w2 <- (qchisq(p = 1 - .001, df = (ncol(sms_w2) - 1)))
sms_w2 <- sms_w2 %>%
  filter(string_w2 <= 10,
         md_w2 < cutoff_w2) %>%
  select(-string_w2, -md_w2)

cutoff_w3 <- (qchisq(p = 1 - .001, df = (ncol(sms_w3) - 1)))
sms_w3 <- sms_w3 %>%
  filter(string_w3 <= 10,
         md_w3 < cutoff_w3) %>%
  select(-string_w3, -md_w3)
```

Next, we are going to make a long file of the SMS data.

```{r}
# first, make a wide format
sms_wide <- merge(sms_w1, sms_w2, by = "id") # first wave 1 and 2
sms_wide <- merge(sms_wide, sms_w3, by = "id") # add wave 3

# then transform into long shape
library(reshape2)
sms_long <- reshape(sms_wide,
                    direction = "long",
                    varying = c(list(names(sms_wide)[c(2, 26, 50)]),
                                     list(names(sms_wide)[c(3, 27, 51)]),
                                     list(names(sms_wide)[c(4, 28, 52)]),
                                     list(names(sms_wide)[c(5, 29, 53)]),
                                     list(names(sms_wide)[c(6, 30, 54)]),
                                     list(names(sms_wide)[c(7, 31, 55)]),
                                     list(names(sms_wide)[c(8, 32, 56)]),
                                     list(names(sms_wide)[c(9, 33, 57)]),
                                     list(names(sms_wide)[c(10, 34, 58)]),
                                     list(names(sms_wide)[c(11, 35, 59)]),
                                     list(names(sms_wide)[c(12, 36, 60)]),
                                     list(names(sms_wide)[c(13, 37, 61)]),
                                     list(names(sms_wide)[c(14, 38, 62)]),
                                     list(names(sms_wide)[c(15, 39, 63)]),
                                     list(names(sms_wide)[c(16, 40, 64)]),
                                     list(names(sms_wide)[c(17, 41, 65)]),
                                     list(names(sms_wide)[c(18, 42, 66)]),
                                     list(names(sms_wide)[c(19, 43, 67)]),
                                     list(names(sms_wide)[c(20, 44, 68)]),
                                     list(names(sms_wide)[c(21, 45, 69)]),
                                     list(names(sms_wide)[c(22, 46, 70)]),
                                     list(names(sms_wide)[c(23, 47, 71)]),
                                     list(names(sms_wide)[c(24, 48, 72)]),
                                     list(names(sms_wide)[c(25, 49, 73)])),
                    v.names = c("M1_1", "M1_2", "M1_3","M1_4", "M1_5", "M1_6", "M1_7", "M1_8", "M2_1", "M2_2", "M2_3","M2_4", "M2_5", "M2_6", "M2_7", "M2_8", "M3_1", "M3_2", "M3_3","M3_4", "M3_5", "M3_6", "M3_7", "M3_8"),
                    idvar = "id",
                    timevar = "Timepoint",
                    times = 1:3)
# Reorder
sms_long  <- sms_long [(order(sms_long$id)), ]
# fix(sms_long) to check data structure

sms_long_nm <- sms_long %>%
  na.omit() # listwise deletion
```

<br>

----

## 2. CFA

First, confirmatory factor analysis using maximum likelihood estimation was conducted to obtain weighted factor scores for each SMS subscale. We first conduct CFA on the stacked data (hence assuming observations to be independent of each other). We will assess model fit using multiple indices. Afterwards, we will assess longitudinal invariance of the measurement model via a series of increasingly constraining models, indicating invariance by a change of CFI of ≤0.01.

### Lavaan

Tell Lavaan the confirmatory structure.

```{r}
library(lavaan)

motivation_model <- "
amotivation =~ M1_5 + M2_4 + M3_1 + M3_6
external    =~ M1_4 + M2_3 + M3_3 + M3_8
introjected =~ M1_7 + M2_2 + M2_8 + M3_7
identified  =~ M1_3 + M1_8 + M2_7 + M3_4
integrated  =~ M1_2 + M2_1 + M2_5 + M3_5
intrinsic   =~ M1_1 + M1_6 + M2_6 + M3_2
"
```

Now let's inspect the model. We will get the fit of the model, the (standardized) factor loadings, item averages (intercepts), error variances, and R-square scores. We will also make a table of the various fit indices. 
 
```{r}
# examine overall fit
overall.fit <- cfa(model = motivation_model, data = sms_long_nm,
           meanstructure = TRUE,  # gives us the means
           std.lv = TRUE) 

summary(overall.fit, standardized = TRUE, rsquare = TRUE, fit.measure = TRUE)

# make table of fit indices
table_fit <- matrix(NA, nrow = 11, ncol = 6)
colnames(table_fit) <- c("Model", "X2", "df", "CFI", "RMSEA", "SRMR")
table_fit[1, ] <- c("Overall Model", round(fitmeasures(overall.fit, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

```

<br>

To check the confirmatory structure of our model, we will also create a picture of the standardized solution (quick and dirty; it can be edited...). The triangles depict the (standardized) intercepts, the arrows depic the variance (i.e. the loops) and (standardized) factor loadings. 

```{r}
library(semPlot)
semPaths(overall.fit, whatLabels = "std", layout = "tree")
```

### Longitudinal invariance {.tabset .tabset-fade}

Since we are dealing with panel data, and we want to explore movement over time in motivations, we should investigate to what extent our CFA solution is invariant over time (because we don't want to compare apples with oranges).
We will compare the SMS data of W1-W3 and compare them in CFA for configural, metric, scalar, and strict residual invariance (see e.g., [Cheung & Rensvold 2002](https://www.tandfonline.com/doi/pdf/10.1207/S15328007SEM0902_5?casa_token=scyVPZRkncQAAAAA:PDDawXxC0BMvLu-kjcvtaFcHseZnO3rkwX4nJGtd8OrK-nuTq4B1Mk571ajpjaq3JQhasVHnyXtofdg)).

We will use a new package for this. Apparently, this package only allows for multi-group equivalence testing for two groups (in Lavaan multiple groups can be compared); therefore, I will run the same procedure for each pair (i.e., W1 vs. W2, W2 vs. W3, and W1 vs. W3).

First, we will subset dataframes that only include two groups (i.e. waves) for comparison, for subsequent equivalence tests. 
```{r}
W1_2 <- ifelse(sms_long_nm$Timepoint == 1, 0, ifelse(sms_long_nm$Timepoint == 2, 1, NA))
sms12 <- sms_long_nm[!is.na(W1_2), ] # compare w1 and w2

W2_3 <- ifelse(sms_long_nm$Timepoint == 2, 0, ifelse(sms_long_nm$Timepoint == 3, 1, NA))
sms23 <- sms_long_nm[!is.na(W2_3), ] # compare w2 and w3

W1_3 <- ifelse(sms_long_nm$Timepoint == 1, 0, ifelse(sms_long_nm$Timepoint == 3, 1, NA))
sms13 <- sms_long_nm[!is.na(W1_3), ] # compare w1 and w3
```

<br>

#### Comparing Wave 1 and Wave 2 

```{r}
library(equaltestMI) #install package

# estimate the multi-group model
MG.model <- eqMI.main(model = motivation_model, 
                      data = sms12, 
                      group = "Timepoint", #comparing wave 1 and wave 2
                      meanstructure = TRUE, #include the means
                      output = "both", #means, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, #test equality of latent factor means (even when equality of intercepts does not hold)
                      bootstrap = FALSE,
                      quiet = TRUE)
```

Now we will summarize the results of the multi-group model, and add them to our previously made kable-table.

```{r}
table_fit[2, ] <- c("W1 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g1, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 1: Wave 1
table_fit[3, ] <- c("W2 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g2, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 2: Wave 2

```

And to test for configural invariance - is the 'picture'/structure of the model the same for both groups (i.e. waves), we stack the groups together.

```{r}
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

table_fit[4, ] <- c("Configural Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.combine.groups, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:4, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

This is the model against which we will test the next model. So, we will conduct a sequential testing analysis. Next, we will assess metric invariance, by constraining the factor loadings to be equal across the waves. In the configural model, factor loadings were "freely" estimated in both waves; now, only 1 loading gets estimated for both groups. Let's see what happens to the model. 

```{r}
table_fit[5, ] <- c("Metric Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.metric, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:5, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

The metric model seems to be invariant in comparison to the configural model: the CFI difference is smaller than .01, hence assuming invariance (same holds for RMSEA/SRMR). Conclusion: the metric model holds: the loadings are equal (or close enough). 

<br>

We have constrained our model to contain the same structure, the same loadings; now let's test for scalar invariance, to see if the intercepts are the same across waves. 

```{r}
table_fit[6, ] <- c("Scalar Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.scalar, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:6, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```


The intercepts are equal on the scale between the waves. 

<br>

Last, we constrain the model to the strict model, to check for strict residual invariance. It will inform whether the variance around items is the same across time.

```{r}
table_fit[7, ] <- c("Strict Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:7, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

From here it goes downwards... CFI dropped more than 0.01, suggesting that the residuals vary between the waves. We could estimate partial invariance, to investigate where the problem is and subsequently update the model to fix it. We are going to do so by freeing the variances of item residuals, one at a time, to figure out which equality constaint(s) is/are causing the problem. We will use the following loop for this. 

```{r}
# write out partial codes
partial_syntax <- paste(colnames(sms12)[3:26], #all sms columns
                        "~~", #residuals
                        colnames(sms12)[3:26]) #all columns again

CFI_list <- 1:length(partial_syntax)
names(CFI_list) <- partial_syntax 

for (i in 1:length(partial_syntax)){
  
  temp <- cfa(model = motivation_model,
              data = sms12,
              meanstructure = TRUE,
              group = "Timepoint",
              group.equal = c("loadings", "intercepts", "residuals"),
              group.partial = partial_syntax[i])
  
  CFI_list[i] <- fitmeasures(temp, "cfi")
}


# now figure out which parameters to "free"
options(scipen = 999)
sort(CFI_list - fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, "cfi", decreasing = T))
```

Let's free up those parameters. Starting with the one that increases CFI to the greatest extent. We will re-run the whole model for this

```{r}
MG.model_2 <- eqMI.main(model = motivation_model, 
                      data = sms12, 
                      group = "Timepoint", #comparing wave 1 and wave 2
                      meanstructure = TRUE,
                      group.partial = c("M1_6~~M1_6"), #free this parameter
                      output = "both", #mean, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, 
                      bootstrap = FALSE,
                      quiet = TRUE)

# check summary to see if the equality constraint is gone.
# summary(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals,
#        standardized = TRUE, rsquare = TRUE, fit.measure = TRUE)


table_fit[8, ] <- c("Strict Model M1_6", round(fitmeasures(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:8, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

CFI improved, but the difference with the baseline scalar model is still greater than .01. Thus, we still need to free (at least) one more, to achieve "partial" invariance. 

```{r}
MG.model_3 <- eqMI.main(model = motivation_model, 
                        data = sms12, 
                        group = "Timepoint", #comparing wave 1 and wave 2
                        meanstructure = TRUE,
                        group.partial = c("M1_6~~M1_6", "M1_7~~M1_7"), #free these parameters
                        output = "both", #mean, covariance, both
                        equivalence.test = FALSE, 
                        adjRMSEA = TRUE,
                        projection = TRUE, 
                        bootstrap = FALSE,
                        quiet = TRUE)

table_fit[9, ] <- c("Strict Model M1_6 + M1_7", round(fitmeasures(MG.model_3$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:9, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```


#### Comparing Wave 2 and Wave 3

```{r}
library(equaltestMI) #install package

# estimate the multi-group model
MG.model <- eqMI.main(model = motivation_model, 
                      data = sms23, 
                      group = "Timepoint", #comparing wave 2 and wave 3
                      meanstructure = TRUE, #include the means
                      output = "both", #means, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, #test equality of latent factor means (even when equality of intercepts does not hold)
                      bootstrap = FALSE,
                      quiet = TRUE)
```

Now we will summarize the results of the multi-group model, and add them to our previously made kable-table.

```{r}
table_fit[2, ] <- c("W2 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g1, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 1: Wave 2
table_fit[3, ] <- c("W3 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g2, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 2: Wave 3

```

And to test for configural invariance - is the 'picture'/structure of the model the same for both groups (i.e. waves), we stack the groups together.

```{r}
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

table_fit[4, ] <- c("Configural Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.combine.groups, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:4, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

This is the model against which we will test the next model. So, we will conduct a sequential testing analysis. Next, we will assess metric invariance, by constraining the factor loadings to be equal across the waves. In the configural model, factor loadings were "freely" estimated in both waves; now, only 1 loading gets estimated for both groups. Let's see what happens to the model. 

```{r}
table_fit[5, ] <- c("Metric Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.metric, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:5, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

The metric model seems to be invariant in comparison to the configural model: the CFI difference is smaller than .01, hence assuming invariance (same holds for RMSEA/SRMR). Conclusion: the metric model holds: the loadings are equal (or close enough). 

<br>

We have constrained our model to contain the same structure, the same loadings; now let's test for scalar invariance, to see if the intercepts are the same across waves. 

```{r}
table_fit[6, ] <- c("Scalar Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.scalar, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:6, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

The intercepts are equal on the scale between the waves. 

<br>

Last, we constrain the model to the strict model, to check for strict residual invariance. It will inform whether the variance around items is the same across time.

```{r}
table_fit[7, ] <- c("Strict Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:7, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

#### Comparing Wave 1 and Wave 3

```{r}
library(equaltestMI) #install package

# estimate the multi-group model
MG.model <- eqMI.main(model = motivation_model, 
                      data = sms13, 
                      group = "Timepoint", #comparing wave 1 and wave 3
                      meanstructure = TRUE, #include the means
                      output = "both", #means, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, #test equality of latent factor means (even when equality of intercepts does not hold)
                      bootstrap = FALSE,
                      quiet = TRUE)
```

Now we will summarize the results of the multi-group model, and add them to our previously made kable-table.

```{r}
table_fit[2, ] <- c("W1 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g1, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 1: Wave 1
table_fit[3, ] <- c("W3 Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.configural.g2, c("chisq", "df", "cfi", "rmsea", "srmr")),3)) # group 2: Wave 3

```

And to test for configural invariance - is the 'picture'/structure of the model the same for both groups (i.e. waves), we stack the groups together.

```{r}
library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)

table_fit[4, ] <- c("Configural Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.combine.groups, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:4, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

This is the model against which we will test the next model. So, we will conduct a sequential testing analysis. Next, we will assess metric invariance, by constraining the factor loadings to be equal across the waves. In the configural model, factor loadings were "freely" estimated in both waves; now, only 1 loading gets estimated for both groups. Let's see what happens to the model. 

```{r}
table_fit[5, ] <- c("Metric Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.metric, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:5, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

The metric model seems to be invariant in comparison to the configural model: the CFI difference is smaller than .01, hence assuming invariance (same holds for RMSEA/SRMR). Conclusion: the metric model holds: the loadings are equal (or close enough). 

<br>

We have constrained our model to contain the same structure, the same loadings; now let's test for scalar invariance, to see if the intercepts are the same across waves. 

```{r}
table_fit[6, ] <- c("Scalar Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.scalar, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:6, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```


The intercepts are equal on the scale between the waves. 

<br>

Last, we constrain the model to the strict model, to check for strict residual invariance. It will inform whether the variance around items is the same across time.

```{r}
table_fit[7, ] <- c("Strict Model", round(fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:7, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

From here it goes downwards... CFI dropped more than 0.01, suggesting that the residuals vary between the waves. We could estimate partial invariance, to investigate where the problem is and subsequently update the model to fix it. We are going to do so by freeing the variances of item residuals, one at a time, to figure out which equality constaint(s) is/are causing the problem. We will use the following loop for this. 

```{r}
# write out partial codes
partial_syntax <- paste(colnames(sms12)[3:26], #all sms columns
                        "~~", #residuals
                        colnames(sms12)[3:26]) #all columns again

CFI_list <- 1:length(partial_syntax)
names(CFI_list) <- partial_syntax 

for (i in 1:length(partial_syntax)){
  
  temp <- cfa(model = motivation_model,
              data = sms13,
              meanstructure = TRUE,
              group = "Timepoint",
              group.equal = c("loadings", "intercepts", "residuals"),
              group.partial = partial_syntax[i])
  
  CFI_list[i] <- fitmeasures(temp, "cfi")
}


# now figure out which parameters to "free"
options(scipen = 999)
sort(CFI_list - fitmeasures(MG.model$convention.sem$LavaanOut$fit.strict.residuals, "cfi", decreasing = T))
```

Let's free up those parameters. Starting with the one that increases CFI to the greatest extent. We will re-run the whole model for this

```{r}
MG.model_2 <- eqMI.main(model = motivation_model, 
                      data = sms13, 
                      group = "Timepoint", #comparing wave 1 and wave 3
                      meanstructure = TRUE,
                      group.partial = c("M1_7~~M1_7"), #free this parameter
                      output = "both", #mean, covariance, both
                      equivalence.test = FALSE, 
                      adjRMSEA = TRUE,
                      projection = TRUE, 
                      bootstrap = FALSE,
                      quiet = TRUE)

# check summary to see if the equality constraint is gone.
# summary(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals,
#        standardized = TRUE, rsquare = TRUE, fit.measure = TRUE)


table_fit[8, ] <- c("Strict Model M1_7", round(fitmeasures(MG.model_2$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit[1:8, ] 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

CFI improved, but the difference with the baseline scalar model is still greater than .01. Thus, we still need to free (at least) one more, to achieve "partial" invariance. 

```{r}
MG.model_3 <- eqMI.main(model = motivation_model, 
                        data = sms13, 
                        group = "Timepoint", #comparing wave 1 and wave 3
                        meanstructure = TRUE,
                        group.partial = c("M1_7~~M1_7", "M3_5~~M3_5"), #free these parameters
                        output = "both", #mean, covariance, both
                        equivalence.test = FALSE, 
                        adjRMSEA = TRUE,
                        projection = TRUE, 
                        bootstrap = FALSE,
                        quiet = TRUE)

table_fit[9, ] <- c("Strict Model M1_7 + M3_5", round(fitmeasures(MG.model_3$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

Ditto

```{r}
MG.model_4 <- eqMI.main(model = motivation_model, 
                        data = sms13, 
                        group = "Timepoint", #comparing wave 1 and wave 3
                        meanstructure = TRUE,
                        group.partial = c("M1_7~~M1_7", "M3_5~~M3_5", "M1_5~~M1_5"), #free these parameters
                        output = "both", #mean, covariance, both
                        equivalence.test = FALSE, 
                        adjRMSEA = TRUE,
                        projection = TRUE, 
                        bootstrap = FALSE,
                        quiet = TRUE)

table_fit[9, ] <- c("Strict Model M1_7 + M3_5 + M1_5", round(fitmeasures(MG.model_4$convention.sem$LavaanOut$fit.strict.residuals, c("chisq", "df", "cfi", "rmsea", "srmr")),3))

input <- table_fit 
knitr::kable(input, digits=2, "html", caption="") %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```



<br>

### Conclusion

We can conclude that the SMS is mostly invariant - the structure, factor loadings, intercepts, and most of the error variances were equal across time.

<br>

### Weighted factor-scores
Now we use the invariant measurement model to generate (weighted) factor scores as input variables for the subsequent LPA. Weighted factor scores are computed by multiplying the factor loading of each item to the scaled score for each item before summing (see [DiStefano et al. (2009)](https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1226&context=pare)). 

We will first fit the CFA, fixing the loading of the first variable of each variable to 1. Then we will extract the loadings, and calculate the weighted sum scores. 

**Note**: we now assumed strict measurement invariance (instead of strong), so we may want to free some parameters...

```{r}
fit <- cfa(model = motivation_model, data = sms_long_nm,
           std.lv = FALSE) # default: not standardized but fixing the first loading on each latent variable to 1.
 
loading <- parameterEstimates(fit)$est[1:24] # extract factor loadings

# calculate weighted sum scores
sms_long_nm$amotivation <- rowMeans(cbind((sms_long_nm$M1_5*loading[1]), (sms_long_nm$M2_4*loading[2]), (sms_long_nm$M3_1*loading[3]), (sms_long_nm$M3_6*loading[4])))

sms_long_nm$external <- rowMeans(cbind((sms_long_nm$M1_4*loading[5]), (sms_long_nm$M2_3*loading[6]), (sms_long_nm$M3_3*loading[7]),   (sms_long_nm$M3_8*loading[8])))

sms_long_nm$introjected <- rowMeans(cbind((sms_long_nm$M1_7*loading[9]), (sms_long_nm$M2_2*loading[10]), (sms_long_nm$M2_8*loading[11]), (sms_long_nm$M3_7*loading[12])))

sms_long_nm$identified <- rowMeans(cbind((sms_long_nm$M1_3*loading[13]), (sms_long_nm$M1_8*loading[14]), (sms_long_nm$M2_7*loading[15]), (sms_long_nm$M3_4*loading[16])))

sms_long_nm$integrated <- rowMeans(cbind((sms_long_nm$M1_2*loading[17]), (sms_long_nm$M2_1*loading[18]), (sms_long_nm$M2_5*loading[19]), (sms_long_nm$M3_5*loading[20])))

sms_long_nm$intrinsic <- rowMeans(cbind((sms_long_nm$M1_1*loading[21]), (sms_long_nm$M1_6*loading[22]), (sms_long_nm$M2_6*loading[23]), (sms_long_nm$M3_2*loading[24])))
```

<br>

----

## 3. Descriptives

Let's describe our weighted factor scores over time. 

```{r}
library(crosstable)

input <- sms_long_nm %>% #get factor scores and timepoint as grouping variable
  select(27:32, 2)

crosstable(input, by=Timepoint,
           funs=c("Mean" = mean, "Std. dev." = sd, "Min" = min, "Max" = max), funs_arg=list(digits=3)) %>%
  as_flextable(by_header = "Wave")
```

And let's see how many respondents we have in each wave (**note-to-self**: integrate in previous table...).

```{r}
knitr::kable(table(sms_long_nm$Timepoint), "html", caption="Number of respondents in each wave", col.names = c("Wave", "N"), align = 'l' ) %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"))
```

At face value, respondents seem to be pretty high in all types of motivation (e.g., compared with the sample of [Emm-Collison and colleagues](https://www.sciencedirect.com/science/article/pii/S1469029219303851) - though these were sum scores).


<br>

----

# LPA  

## Step 1 

### {.tabset .tabset-fade}

As a first step for the LPA, we carefully select a measurement model that accurately captures the construct of motivational profile. We will fit a series of measurement models for each wave to determine which model provides the best fit at each wave (following recommendations of [Nylund et al. (2007)](https://srcd.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-8624.2007.01097.x?casa_token=0wyzjh9Ozk0AAAAA:iasgTYid_gJ5kGH42Jyys61DsBhEDl0zxVrukoJdaeX2e2MGOlm1nfyooEUc1v5SaB3lFYyX1wqVLGNOvQ) and similar to the article by [Martinent & Decret (2015)](https://www.tandfonline.com/doi/pdf/10.1080/10413200.2014.993485?casa_token=CsBgfG9lbtgAAAAA:CMEXxc96xNC-rF6Sowi7X2X0qvXlxI9MuODWtQ1Db92UyZUeLZcWJem1jhhympbi8dBboyrA282A5Ns)).

<br>

#### Wave 1

We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).

```{r}
sms_w1 <- sms_long_nm[sms_long_nm$Timepoint==1, ] %>%
  select(-Timepoint, -id) %>% # subset W1
  select(25:30) %>% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
```

We then compute the model-based clustering, and ask for a summary.
```{r}
library(mclust)
mc <- Mclust(sms_w1)
summary(mc)                 
```

For this wave, Mclust selected a model with 9 (!) profiles; the optimal selected model is EEV, i.e., the profiles are ellipsoidal with equal volume, shape and varying orientation (see [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/)). However, note that VEV, 9 is only slightly behind, and that for all solutions with fewer clusters, the VEV model fitted better.

Now we will access to the results and visualize the model. To visualize, we will use a new package (*factoextra*), to create nicer plots based on ggplot2.

```{r}
library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, "BIC", palette = "jco")
```

#### Wave 2

We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).

```{r}
sms_w2 <- sms_long_nm[sms_long_nm$Timepoint==2, ] %>%
  select(-Timepoint, -id) %>% # subset W2
  select(25:30) %>% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
```

We then compute the model-based clustering, and ask for a summary.
```{r}
library(mclust)
mc <- Mclust(sms_w2)
summary(mc)                 
```

For this wave, Mclust selected a model with 7 (!) profiles; the optimal selected model is VEV, i.e., the profiles are ellipsoidal with equal shape (see [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/)). 

Now we will access to the results and visualize the model. To visualize, we will use a new package (*factoextra*), to create nicer plots based on ggplot2.

```{r}
library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, "BIC", palette = "jco")
```

#### Wave 3

We start by subsetting the data for the respective waves, and standardizing the indicators to z-scores, meaning that resulting profile means reflect standard deviation (SD) units above or below the sample mean (which is set to 0).

```{r}
sms_w3 <- sms_long_nm[sms_long_nm$Timepoint==3, ] %>%
  select(-Timepoint, -id) %>% # subset W1
  select(25:30) %>% # subset weighted factor scores
  mutate_all(list(scale)) # standardize indicators
```

We then compute the model-based clustering, and ask for a summary.
```{r}
library(mclust)
mc <- Mclust(sms_w3)
summary(mc)                 
```

For this wave, Mclust selected a model with 9 (!) profiles; the optimal selected model is VEV, i.e., the profiles are ellipsoidal with equal shape (see [this article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5096736/)). 

```{r}
library(factoextra)
# BIC values used for choosing the number of clusters
fviz_mclust(mc, "BIC", palette = "jco")
```

### {.tabset .tabset-fade}

We will examine a sequence of models, with an increasing number of profiles from 2 to ..., to ascertain whether more complex (i.e. more profiles) or parsimonious (i.e. fewer profiles) models provided the best description of the data. We will use the VEV model (varying volume, equal shape, varying orientation).

We will plot the profile means, the clustering and the clustering uncertainty. If the data contain more than two variables (which is the case in our data), the *fviz_mclust()*-function will use PCA to reduce the dimensionality of the data. The first two principal components are used to produce a scatter plot of the data. If we want to plot the data using only two variables (e.g., *external regulation* and *intrinsic motivation*), we can specify that in the function using the argument *choose.vars = c("external", "intrinsic")*. Note that, in the uncertainty plot, larger symbols indicate the more uncertain observations.

<br>

#### Wave 1

##### {.tabset .tabset-fade}

###### 2 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1) 
m2 <- Mclust(sms_w1, modelNames = "VEV", G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m2, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m2, "uncertainty", palette = "jco")
```

###### 3 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1) 
m3 <- Mclust(sms_w1, modelNames = "VEV", G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m3, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m3, "uncertainty", palette = "jco")
```

###### 4 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1) 
m4 <- Mclust(sms_w1, modelNames = "VEV", G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m4, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m4, "uncertainty", palette = "jco")
```

###### 5 profiles
```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w1) 
m5 <- Mclust(sms_w1, modelNames = "VEV", G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m5, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m5, "uncertainty", palette = "jco")
```

#### Wave 2

##### {.tabset .tabset-fade}

###### 2 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2) 
m2 <- Mclust(sms_w2, modelNames = "VEV", G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m2, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m2, "uncertainty", palette = "jco")
```

###### 3 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2) 
m3 <- Mclust(sms_w2, modelNames = "VEV", G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m3, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m3, "uncertainty", palette = "jco")
```

###### 4 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2) 
m4 <- Mclust(sms_w2, modelNames = "VEV", G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m4, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m4, "uncertainty", palette = "jco")
```

###### 5 profiles
```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w2) 
m5 <- Mclust(sms_w2, modelNames = "VEV", G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m5, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m5, "uncertainty", palette = "jco")
```





#### Wave 3

##### {.tabset .tabset-fade}

###### 2 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3) 
m2 <- Mclust(sms_w3, modelNames = "VEV", G = 2, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m2$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m2, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m2, "uncertainty", palette = "jco")
```

###### 3 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3) 
m3 <- Mclust(sms_w3, modelNames = "VEV", G = 3, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m3$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m3, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m3, "uncertainty", palette = "jco")
```

###### 4 profiles

```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3) 
m4 <- Mclust(sms_w3, modelNames = "VEV", G = 4, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m4$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m4, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m4, "uncertainty", palette = "jco")
```

###### 5 profiles
```{r class.source = 'fold-hide'}
library(mclust)

BIC <- mclustBIC(sms_w3) 
m5 <- Mclust(sms_w3, modelNames = "VEV", G = 5, x = BIC)

# Extract mean weighted factor scores
library(reshape2)
means <- data.frame(m5$parameters$mean,
                    stringsAsFactors = F) %>%
  rownames_to_column() %>%
  rename(Motivation = rowname) %>%
  melt(id.vars = "Motivation", variable.name = "Profile", value.name = "Mean") %>%
  mutate(Mean = round(Mean, 2))

# Plot showing the standardized means
means %>%
  ggplot(aes(Motivation, Mean, group = Profile, color = Profile)) +
  geom_line() +
  geom_point() +
  scale_x_discrete(limits = c("amotivation", "external", "introjected", "identified", "integrated", "intrinsic")) +
  labs(x = NULL, y = "Standardized mean weighted factor-scores") +
  scale_colour_manual(values=c("#56B4E9", "#000000", "#E69F00", "#009E73", "#F0E442")) +
  theme_bw(base_size = 14) +
  geom_hline(yintercept = 0, linetype="dashed") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "top")

library(factoextra)

# Plot showing the clustering
fviz_mclust(m5, "classification", geom = "point",
            pointsize = 1.5, palette = "jco")

# Plot showing the clustering uncertainty
fviz_mclust(m5, "uncertainty", palette = "jco")
```
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("lpta.Rmd");
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
